{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 4D - no collapsing\n",
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization, Bidirectional, AdditiveAttention, LayerNormalization\n",
    "from functools import partial\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "# schizohrenia_id that satisfy t>90, 59 in total\n",
    "met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "    'A00006754', 'A00009280', 'A00012767', 'A00013216', 'A00014607', 'A00014719', 'A00014804',\n",
    "    'A00014830', 'A00015201', 'A00015648', 'A00016197', 'A00016720', 'A00016723', 'A00017147',\n",
    "    'A00018317', 'A00018403', 'A00018434', 'A00018979', 'A00019293', 'A00020414', 'A00020602', \n",
    "    'A00020787', 'A00021591', 'A00021598', 'A00023158', 'A00023246', 'A00023590', 'A00023750', \n",
    "    'A00024198', 'A00024228', 'A00024568', 'A00024684', 'A00024953', 'A00024959', 'A00027410', \n",
    "    'A00027537', 'A00028303', 'A00028404', 'A00028408', 'A00028805', 'A00028806', 'A00031186', \n",
    "    'A00031597', 'A00034273', 'A00035003', 'A00035485', 'A00037034', 'A00037224', 'A00037619', \n",
    "    'A00037649', 'A00038441', 'A00038624']\n",
    "\n",
    "full_control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "]\n",
    "\n",
    " # 82 controls that met requirement\n",
    "met_requirement_control_ids = [\n",
    "    'A00000300', 'A00002198', 'A00003150', 'A00004087', 'A00007409', 'A00010684', 'A00011265', 'A00011725',\n",
    "    'A00012995', 'A00013140', 'A00013816', 'A00014839', 'A00014898', 'A00015759', 'A00015826', 'A00018553',\n",
    "    'A00018716', 'A00019888', 'A00020805', 'A00020895', 'A00020968', 'A00020984', 'A00021058', 'A00021072',\n",
    "    'A00021081', 'A00021085', 'A00022400', 'A00022490', 'A00022509', 'A00022592', 'A00022619', 'A00022653',\n",
    "    'A00022687', 'A00022727', 'A00022729', 'A00022773', 'A00022810', 'A00022835', 'A00022837', 'A00022915',\n",
    "    'A00023095', 'A00023120', 'A00023131', 'A00023143', 'A00023330', 'A00023337', 'A00023730', 'A00023800',\n",
    "    'A00023848', 'A00023866', 'A00024160', 'A00024301', 'A00024372', 'A00024446', 'A00024535', 'A00024546', \n",
    "    'A00024663', 'A00024820', 'A00024932', 'A00024955', 'A00025969', 'A00026945', 'A00027487', 'A00027787', \n",
    "    'A00028052', 'A00028406', 'A00028409', 'A00029226', 'A00029452', 'A00031478', 'A00031764', 'A00033214', \n",
    "    'A00035751', 'A00036049', 'A00036555', 'A00036844', 'A00037007', 'A00037238', 'A00037318', 'A00037495', \n",
    "    'A00037564', 'A00037665'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nibabel as nib\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Directory containing your .nii.gz files\n",
    "# directory_path = '4D/'\n",
    "# file_pattern = '*.nii.gz'  # Adjust as needed for your file pattern\n",
    "\n",
    "# # Directory to move corrupt files, create if doesn't exist\n",
    "# corrupt_files_dir = os.path.join(directory_path, 'corrupt_files')\n",
    "# os.makedirs(corrupt_files_dir, exist_ok=True)\n",
    "\n",
    "# # List to store paths of corrupt files\n",
    "# corrupt_files = []\n",
    "\n",
    "# # Iterate over all files in the directory\n",
    "# for root, _, files in os.walk(directory_path):\n",
    "#     for file in files:\n",
    "#         if file.endswith('.nii.gz'):\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             try:\n",
    "#                 # Attempt to load the file\n",
    "#                 t1_img = nib.load(file_path)\n",
    "#                 # Attempt to read the data to ensure it's not corrupt\n",
    "#                 t1_data = t1_img.get_fdata()\n",
    "\n",
    "#             except (EOFError, OSError, nib.filebasedimages.ImageFileError) as e:\n",
    "#                 # Log the corrupt file and the error message\n",
    "#                 print(f\"Corrupt file detected: {file_path} | Error: {e}\")\n",
    "#                 corrupt_files.append(file_path)\n",
    "\n",
    "#                 # Optionally, move the corrupt file to a separate directory\n",
    "#                 shutil.move(file_path, os.path.join(corrupt_files_dir, file))\n",
    "#                 continue\n",
    "\n",
    "# # Output the list of corrupt files\n",
    "# if corrupt_files:\n",
    "#     print(f\"\\nTotal corrupt files found: {len(corrupt_files)}\")\n",
    "#     for corrupt_file in corrupt_files:\n",
    "#         print(corrupt_file)\n",
    "# else:\n",
    "#     print(\"No corrupt files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GAN control loaded: 50\n",
      "Total GAN schiz loaded: 50\n",
      "shape after normalization and padding (91, 109, 91, 146)\n"
     ]
    }
   ],
   "source": [
    "# GAN Training Data Selection\n",
    "gan_train_ids_schiz = random.sample(met_requirement_schizophrenia_ids, 50)\n",
    "gan_test_ids_schiz = [id for id in met_requirement_schizophrenia_ids if id not in gan_train_ids_schiz]\n",
    "\n",
    "gan_train_ids_control = random.sample(met_requirement_control_ids, 50)\n",
    "gan_test_ids_control = [id for id in met_requirement_control_ids if id not in gan_train_ids_control]\n",
    "gan_test_ids_control = random.sample(gan_test_ids_control,9)\n",
    "\n",
    "''' data training for classifier '''\n",
    "''' just use the same train set as GAN above '''\n",
    "\n",
    "# Classifier Test Data Selection\n",
    "classifier_test_ids = gan_test_ids_schiz + gan_test_ids_control\n",
    "\n",
    "''' File loading '''\n",
    "# Specify the directory and file pattern\n",
    "directory_path = '4D/'\n",
    "file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "# Construct the full path pattern\n",
    "path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "matching_files = glob.glob(path_pattern)\n",
    "\n",
    "''' File loading for GAN Training and classifer '''\n",
    "''' But this time we have 2 separate GANs, 1 train on schizoprenia and 1 train on control'''\n",
    "\n",
    "#classifier_image_data = []\n",
    "#classifier_labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "gan_image_data_schiz = []\n",
    "gan_image_data_control = []\n",
    "\n",
    "for file_path in matching_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    if file_id in gan_train_ids_schiz:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "        \n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "\n",
    "        #t1_data = np.sum(t1_data, axis=1)\n",
    "        #print('shape of image: ', t1_data.shape)\n",
    "        gan_image_data_schiz.append(t1_data)\n",
    "\n",
    "    if file_id in gan_train_ids_control:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "\n",
    "        #t1_data = np.sum(t1_data, axis=1)\n",
    "        gan_image_data_control.append(t1_data)\n",
    "\n",
    "\n",
    "print(f\"Total GAN control loaded: {len(gan_image_data_control)}\")\n",
    "print(f\"Total GAN schiz loaded: {len(gan_image_data_schiz)}\")\n",
    "\n",
    "\n",
    "\n",
    "'''Determine the maximum time-dimension size '''\n",
    "max_z_size_schiz = max(img.shape[3] for img in gan_image_data_schiz)\n",
    "max_z_size_control = max(img.shape[3] for img in gan_image_data_control)\n",
    "max_t_size = max(max_z_size_schiz,max_z_size_control)\n",
    "\n",
    "\n",
    "# Normalize and pad the data\n",
    "def normalize_and_pad(data, max_t):\n",
    "    normalized = (data - np.min(data)) / (np.max(data) - np.min(data)) * 2 - 1\n",
    "    padded = np.pad(normalized, ((0, 0), (0, 0), (0, 0), (0, max_t - data.shape[3])), mode='constant')\n",
    "    return padded\n",
    "\n",
    "padded_data_schiz = [normalize_and_pad(img, max_t_size) for img in gan_image_data_schiz]\n",
    "padded_data_control = [normalize_and_pad(img, max_t_size) for img in gan_image_data_control]\n",
    "\n",
    "padded_data_array_schiz = padded_data_schiz\n",
    "padded_data_array_control = padded_data_control\n",
    "print(\"shape after normalization and padding\", padded_data_array_control[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach is too naive\n",
    "\n",
    "# batch_size = 10\n",
    "# # Flatten each 3D volume for each time step\n",
    "# def flatten_3d_data(data):\n",
    "#     return np.reshape(data, (data.shape[3], data.shape[0] * data.shape[1] * data.shape[2]))  # (t, x*y*z)\n",
    "\n",
    "# # Prepare the data for the LSTM model\n",
    "# flattened_data_schiz = [flatten_3d_data(img) for img in padded_data_array_schiz]\n",
    "# flattened_data_control = [flatten_3d_data(img) for img in padded_data_array_control]\n",
    "# print(\"shape after flattening\", flattened_data_schiz[0].shape)\n",
    "\n",
    "# # Convert to numpy arrays\n",
    "# train_images_schiz = np.array(flattened_data_schiz)\n",
    "# train_images_control = np.array(flattened_data_control)\n",
    "\n",
    "\n",
    "# # Create labels\n",
    "# labels_schiz = np.ones(len(padded_data_array_schiz))\n",
    "# labels_control = np.zeros(len(padded_data_array_control))\n",
    "\n",
    "# # Combine the datasets\n",
    "# train_images = np.concatenate((train_images_schiz, train_images_control), axis=0)\n",
    "# train_labels = np.concatenate((labels_schiz, labels_control), axis=0)\n",
    "\n",
    "# # Shuffle the dataset\n",
    "# indices = np.arange(train_images.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# train_images = train_images[indices]\n",
    "# train_labels = train_labels[indices]\n",
    "\n",
    "# # Create TensorFlow dataset\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after flattening: (146, 902629)\n",
      "Batch image shape: (10, 146, 902629)\n",
      "Batch labels shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Function to flatten 3D volumes for each time step (t, x*y*z)\n",
    "def flatten_3d_data(data):\n",
    "    return np.reshape(data, (data.shape[3], data.shape[0] * data.shape[1] * data.shape[2]))  # (t, x*y*z)\n",
    "\n",
    "# Flatten each 3D volume for each time step\n",
    "flattened_data_schiz = [flatten_3d_data(img) for img in padded_data_array_schiz]\n",
    "flattened_data_control = [flatten_3d_data(img) for img in padded_data_array_control]\n",
    "print(\"Shape after flattening:\", flattened_data_schiz[0].shape)  # Check the shape after flattening\n",
    "\n",
    "# Create labels\n",
    "labels_schiz = np.ones(len(flattened_data_schiz))\n",
    "labels_control = np.zeros(len(flattened_data_control))\n",
    "\n",
    "# Combine images and labels\n",
    "train_images = flattened_data_schiz + flattened_data_control\n",
    "train_labels = np.concatenate((labels_schiz, labels_control), axis=0)\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(len(train_images))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Shuffle data based on indices\n",
    "train_images = [train_images[i] for i in indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "# Define a generator function to yield data batches\n",
    "def data_generator(images, labels, batch_size):\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i + batch_size]\n",
    "        batch_labels = labels[i:i + batch_size]\n",
    "        yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "# Create TensorFlow Dataset from the generator\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(train_images, train_labels, batch_size),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, max_t_size, 91 * 109 * 91), dtype=tf.float32),  # Adjust shape if needed\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Prefetch for performance improvement\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Debug: Test the generator\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Batch image shape: {images.shape}\")\n",
    "    print(f\"Batch labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 146, 128)          462212096 \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 462261569 (1.72 GB)\n",
      "Trainable params: 462261569 (1.72 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_rnn_model():\n",
    "    \n",
    "    # Define input shape: (time_steps, flattened_features)\n",
    "    time_steps = max_t_size  # Number of time points\n",
    "    features_per_volume = 91 * 109 * 91  # Flattened size of each 3D volume\n",
    "\n",
    "    # Input shape for LSTM\n",
    "    input_shape = (time_steps, features_per_volume)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    # LSTM layers to process the sequence\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    model.add(layers.LSTM(64))\n",
    "    #model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "rnn_model = build_rnn_model()\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fdb0e0cf2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fdb0e0cf2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 1, Loss: 0.9121697545051575, Training Accuracy: 0.5400000214576721\n",
      "Epoch 2, Loss: 0.7190192341804504, Training Accuracy: 0.47999998927116394\n",
      "Epoch 3, Loss: 0.6927342414855957, Training Accuracy: 0.5099999904632568\n",
      "Epoch 4, Loss: 0.6929518580436707, Training Accuracy: 0.5400000214576721\n",
      "Epoch 5, Loss: 0.6923525333404541, Training Accuracy: 0.5400000214576721\n",
      "Epoch 6, Loss: 0.6914445161819458, Training Accuracy: 0.550000011920929\n",
      "Epoch 7, Loss: 0.6916589736938477, Training Accuracy: 0.5400000214576721\n",
      "Epoch 8, Loss: 0.6912298202514648, Training Accuracy: 0.5400000214576721\n",
      "Epoch 9, Loss: 0.6909211874008179, Training Accuracy: 0.5400000214576721\n",
      "Epoch 10, Loss: 0.6912838220596313, Training Accuracy: 0.5400000214576721\n",
      "Epoch 11, Loss: 0.6909537315368652, Training Accuracy: 0.5400000214576721\n",
      "Epoch 12, Loss: 0.6914007067680359, Training Accuracy: 0.550000011920929\n",
      "Epoch 13, Loss: 0.6913293600082397, Training Accuracy: 0.550000011920929\n",
      "Epoch 14, Loss: 0.6909869909286499, Training Accuracy: 0.550000011920929\n",
      "Epoch 15, Loss: 0.6907510161399841, Training Accuracy: 0.550000011920929\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "# Define number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        #images = tf.transpose(images, perm=[0, 4, 1, 2, 3, 5])  # (batch, t, x, y, z, channels)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = rnn_model(images, training=True)\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels, tf.squeeze(predictions, axis=1))\n",
    "        \n",
    "        gradients = tape.gradient(loss, rnn_model.trainable_variables)\n",
    "        rnn_model.optimizer.apply_gradients(zip(gradients, rnn_model.trainable_variables))\n",
    "        \n",
    "        # Update the metrics\n",
    "        train_loss.update_state(loss)\n",
    "        train_accuracy.update_state(labels, tf.squeeze(predictions, axis=1))\n",
    "    \n",
    "    # Print the loss and accuracy for the current epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_loss.result().numpy()}, Training Accuracy: {train_accuracy.result().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0] / image.shape[0],\n",
    "        new_shape[1] / image.shape[1],\n",
    "        new_shape[2] / image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation\n",
    "\n",
    "\n",
    "test_image_data = []\n",
    "test_labels = []\n",
    "\n",
    "test_ids = classifier_test_ids  # List of IDs to filter test data\n",
    "\n",
    "for file_path in matching_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    if file_id in test_ids:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # Normalize the processed image\n",
    "        processed_image_normalized = (t1_data - np.min(t1_data)) / (np.max(t1_data) - np.min(t1_data)) * 2 - 1\n",
    "\n",
    "        \n",
    "        # Pad or truncate the time dimension to match the expected size (max_t_size)\n",
    "        current_t_size = processed_image_normalized.shape[3]\n",
    "        \n",
    "        if current_t_size < max_t_size:\n",
    "            # Pad to max_t_size time steps if the current time dimension is smaller\n",
    "            pad_size = max_t_size - current_t_size\n",
    "            #pad_size = max_t_size\n",
    "            processed_image_padded = np.pad(processed_image_normalized, ((0, 0), (0, 0), (0, 0), (0, pad_size)), mode='constant')\n",
    "        elif current_t_size > max_t_size:\n",
    "            # Truncate to max_t_size time steps if the current time dimension is larger\n",
    "            processed_image_padded = processed_image_normalized[:, :, :, :max_t_size]\n",
    "        else:\n",
    "            processed_image_padded = processed_image_normalized  # No padding needed\n",
    "\n",
    "        # Check final shape before flattening\n",
    "        #print(f\"Processed image padded shape: {processed_image_padded.shape}\")\n",
    "\n",
    "        # Flatten each 3D volume (91, 109, 91) for each time step (t)\n",
    "        flattened_shape = (processed_image_padded.shape[3], processed_image_padded.shape[0] * processed_image_padded.shape[1] * processed_image_padded.shape[2])\n",
    "        processed_image_flattened = np.reshape(processed_image_padded, flattened_shape)  # (t, x*y*z)\n",
    "\n",
    "        # Verify the shape after flattening\n",
    "        #print(f\"Flattened image shape: {processed_image_flattened.shape}\")\n",
    "\n",
    "        test_image_data.append(processed_image_flattened)\n",
    "        \n",
    "        label = 1 if file_id in met_requirement_schizophrenia_ids else 0\n",
    "        test_labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays for easier handling in TensorFlow\n",
    "test_images_array = np.array(test_image_data)\n",
    "test_labels_array = np.array(test_labels)\n",
    "\n",
    "# Check the final shape of test images\n",
    "#print(\"Final shape of test_images_array:\", test_images_array.shape)\n",
    "#print(\"Final shape of test_labels_array:\", test_labels_array.shape)\n",
    "\n",
    "#batch_size=1\n",
    "\n",
    "# Create a TensorFlow dataset from the numpy arrays\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images_array, test_labels_array)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 45s 3s/step - loss: 0.6855 - accuracy: 0.5556\n",
      "Test loss: 0.685500979423523, Test accuracy: 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = rnn_model.evaluate(test_dataset)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 18s 8s/step\n",
      "[[7 2]\n",
      " [6 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.78      0.64         9\n",
      "           1       0.60      0.33      0.43         9\n",
      "\n",
      "    accuracy                           0.56        18\n",
      "   macro avg       0.57      0.56      0.53        18\n",
      "weighted avg       0.57      0.56      0.53        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the probabilities\n",
    "predictions = rnn_model.predict(test_dataset)\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Assuming test_labels_array contains your actual labels\n",
    "actual_labels = test_labels_array\n",
    "\n",
    "# Now you might want to compare these predicted_labels with the actual labels (test_labels)\n",
    "# to compute the confusion matrix, classification report, etc.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(actual_labels, predicted_labels.flatten()))\n",
    "print(classification_report(actual_labels, predicted_labels.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1, Predicted: [1]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 0, Predicted: [1]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 0, Predicted: [1]\n",
      "Actual: 1, Predicted: [1]\n"
     ]
    }
   ],
   "source": [
    "for actual, predicted in zip(actual_labels, predicted_labels):\n",
    "    print(f'Actual: {actual}, Predicted: {predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
