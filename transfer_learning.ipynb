{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try transfer learning using cGAN discriminator\n",
    "\n",
    "adapt from here https://github.com/ck44liu/gans-on-image-classification/blob/main/report%20gan%20assignment.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 05:00:04.610027: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-03 05:00:04.772359: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-03 05:00:04.772426: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-03 05:00:04.795846: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-03 05:00:04.850342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-03 05:00:05.676779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  The discriminator's output layer is designed to output a single value indicating real or fake. \n",
    " # For classification, we need an output layer that can categorize images into the 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 05:00:07.591979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46639 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved discriminator model\n",
    "discriminator = load_model('cgan_discriminator_model_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our cGAN input has 2 inputs: the image and the label\n",
    "# To repurpose the discriminator for classification, we need to reconstruct the model.\n",
    "# We modify the classification model to accept only the image input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To modify discrimnator for classification:\n",
    "\n",
    "# Redefine the input layer to match the shape of 4D data, ie. Input(shape=(84, 84, 72, 1)).\n",
    "\n",
    "# Remove the Embedding Layer: Since this is image data, the embedding layer should be removed.\n",
    "\n",
    "# Modify the Network Architecture: Utilize the convolutional and pooling layers from the original discriminator for feature extraction, and append a few dense layers at the end for classification. The final layer should be a dense layer with one neuron (for binary classification) and a sigmoid activation function.\n",
    "\n",
    "# Recompile the Model: After making these modifications, recompile the model with a suitable optimizer and loss function (e.g., binary cross-entropy for binary classification).\n",
    "\n",
    "# The index of the last conv3D layer is determined based on the sequential addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1, 508032)            1016064   ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 508032)               0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 84, 84, 72, 1)        0         ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 508032)               0         ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  6502822   ['flatten[0][0]']             \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   8256      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 84, 84, 72, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    65        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66052609 (251.97 MB)\n",
      "Trainable params: 65036545 (248.09 MB)\n",
      "Non-trainable params: 1016064 (3.88 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a new model up to the last convolutional layer of the discriminator\n",
    "base_model = Model(inputs=discriminator.input, outputs=discriminator.layers[-3].output)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the new classification model\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "classification_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since we have only one dataset, split it into training and evaluation parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files successfully processed: 141\n",
      "Total number of schizophrenia files: 59\n",
      "Schizophrenia files: ['A00031597_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020602_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00038624_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015648_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035003_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00009280_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018979_0020_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024568_0008_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018434_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014830_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037224_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000368_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000541_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023246_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016197_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024953_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028806_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024198_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00034273_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014607_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031186_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023750_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00019293_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016723_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037649_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00038441_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014719_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000456_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021591_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015201_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014804_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001452_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020787_0017_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028805_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013216_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037034_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00012767_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035485_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00017147_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024684_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028404_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018317_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024228_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023590_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001251_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024959_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00004507_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027410_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021598_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037619_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023158_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018403_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000838_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020414_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00006754_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028303_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027537_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028408_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016720_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n",
      "Total number of non-schizophrenia files: 82\n",
      "Non-Schizophrenia files: ['A00022400_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023143_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024301_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00010684_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023848_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00036555_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022727_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020968_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022490_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024955_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023120_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024535_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028409_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024932_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020805_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013140_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037564_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020895_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023330_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021081_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00007409_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024820_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022837_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00026945_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020984_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021058_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00003150_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00012995_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022653_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037318_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00011725_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00019888_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027487_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022687_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022592_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018716_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015826_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037238_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023131_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023800_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023866_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00036844_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022773_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021085_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037495_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037665_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022509_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022619_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022810_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013816_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00025969_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022729_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031478_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00036049_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014898_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031764_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022835_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028406_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00002198_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023337_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015759_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023095_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024446_0009_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024160_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000300_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00004087_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028052_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018553_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037007_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00033214_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00022915_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024372_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014839_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024546_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00011265_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021072_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023730_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00029452_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024663_0016_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035751_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00029226_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027787_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n",
      "Total number of files with insufficient time dimension: 28\n",
      "Files with insufficient time dimension: ['A00033994_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023243_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000909_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00036897_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014225_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014175_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014636_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001243_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00019349_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00033648_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00029486_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001181_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00017294_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035183_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014590_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00026907_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013363_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031271_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014120_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037854_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027755_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00002480_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027391_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00010150_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028405_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015518_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00036916_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00033812_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n",
      "IDs of files with insufficient time dimension: ['A00033994', 'A00023243', 'A00000909', 'A00036897', 'A00014225', 'A00014175', 'A00014636', 'A00001243', 'A00019349', 'A00033648', 'A00029486', 'A00001181', 'A00017294', 'A00035183', 'A00014590', 'A00026907', 'A00013363', 'A00031271', 'A00014120', 'A00037854', 'A00027755', 'A00002480', 'A00027391', 'A00010150', 'A00028405', 'A00015518', 'A00036916', 'A00033812']\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory and file pattern\n",
    "directory_path = '../4D'\n",
    "file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "# Construct the full path pattern\n",
    "path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "matching_files = glob.glob(path_pattern)\n",
    "\n",
    "# Define the list of schizophrenia IDs\n",
    "\n",
    "\n",
    "\n",
    "schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ] \n",
    "\n",
    "\n",
    "# Define the list of IDs of individuals with non-schizophrenia - control only\n",
    "\n",
    "\n",
    "\n",
    "control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "] \n",
    "\n",
    "# Initialize lists to store the processed image data, corresponding labels, and filenames\n",
    "image_data = []\n",
    "labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "schizophrenia_files = []\n",
    "non_schizophrenia_files = []\n",
    "\n",
    "# Lists for files with insufficient time dimensions\n",
    "insufficient_time_files = []\n",
    "insufficient_time_ids = []\n",
    "\n",
    "# Counters for each category\n",
    "schizophrenia_count = 0\n",
    "non_schizophrenia_count = 0\n",
    "processed_files_count = 0\n",
    "\n",
    "# Loop through the matching files\n",
    "for file_path in matching_files:\n",
    "    # Extract the filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract the ID from the filename\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    # Load the file\n",
    "    t1_img = nib.load(file_path)\n",
    "    t1_data = t1_img.get_fdata()\n",
    "\n",
    "    # Check if the time dimension is at least 90\n",
    "    if t1_data.shape[3] < 90:\n",
    "        insufficient_time_files.append(filename)\n",
    "        insufficient_time_ids.append(file_id)\n",
    "        continue  # Skip this file\n",
    "\n",
    "    # Determine the label based on the ID and increment counters\n",
    "    if file_id in schizophrenia_ids:\n",
    "        label = 1  # Schizophrenia\n",
    "        schizophrenia_count += 1\n",
    "        schizophrenia_files.append(filename)\n",
    "    elif file_id in control_ids:\n",
    "        label = 0  # Non-Schizophrenia\n",
    "        non_schizophrenia_count += 1\n",
    "        non_schizophrenia_files.append(filename)\n",
    "    else:\n",
    "        continue  # Skip files with IDs not in the provided lists\n",
    "    \n",
    "    # Collapse one of the axes by summing\n",
    "    t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "    \n",
    "    # Append the collapsed image data and label to the respective lists\n",
    "    image_data.append(t1_data_collapsed)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Increment the counter\n",
    "    processed_files_count += 1\n",
    "\n",
    "# Print the total number of files processed for each category and their filenames\n",
    "print(f\"Total number of files successfully processed: {processed_files_count}\")\n",
    "print(f\"Total number of schizophrenia files: {schizophrenia_count}\")\n",
    "print(\"Schizophrenia files:\", schizophrenia_files)\n",
    "print(f\"Total number of non-schizophrenia files: {non_schizophrenia_count}\")\n",
    "print(\"Non-Schizophrenia files:\", non_schizophrenia_files)\n",
    "\n",
    "# Print files with insufficient time dimension\n",
    "print(f\"Total number of files with insufficient time dimension: {len(insufficient_time_files)}\")\n",
    "print(\"Files with insufficient time dimension:\", insufficient_time_files)\n",
    "print(\"IDs of files with insufficient time dimension:\", insufficient_time_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0] / image.shape[0],\n",
    "        new_shape[1] / image.shape[1],\n",
    "        new_shape[2] / image.shape[2]\n",
    "    )\n",
    "    # Reshape and add a channel dimension\n",
    "    resized_image = scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation\n",
    "    return np.expand_dims(resized_image, axis=-1)  # Add channel dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# during classification training, we are providing only the image data without the corresponding labels input (as part of the input tensor).\n",
    "\n",
    "# Modify Data Input:\n",
    "# keep the current model architecture, adjust the dataset to include a dummy label input. This could be done by including an array of zeros (or any placeholder values) with the same batch size as the images. These values won't actually be used in classification but are necessary to satisfy the model's input requirements. This is because of our cGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum z-dimension size\n",
    "max_z_size = max(img.shape[2] for img in image_data)\n",
    "image_data_normalized = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in image_data]\n",
    "# Pad each image to have a consistent z-dimension size\n",
    "padded_data = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized]\n",
    "\n",
    "# Resize each image in the padded data array\n",
    "resized_images = [resize_image(img, (84, 84, 72)) for img in padded_data]\n",
    "\n",
    "# Convert the resized data to a numpy array\n",
    "resized_images_array = np.array(resized_images)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "\n",
    "# Convert labels list to a numpy array\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Split the data into training and evaluation sets (80% train, 20% eval)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(resized_images_array, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a dummy array for the label input\n",
    "dummy_label_input_train = np.zeros((len(X_train), 1))\n",
    "dummy_label_input_eval = np.zeros((len(X_eval), 1))\n",
    "\n",
    "# Convert to TensorFlow datasets without extra nesting\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, dummy_label_input_train, y_train)).map(\n",
    "    lambda image, dummy_label, label: ((image, dummy_label), label)\n",
    ").shuffle(len(X_train)).batch(batch_size)\n",
    "\n",
    "eval_dataset = tf.data.Dataset.from_tensor_slices((X_eval, dummy_label_input_eval, y_eval)).map(\n",
    "    lambda image, dummy_label, label: ((image, dummy_label), label)\n",
    ").batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of image data: 141\n",
      "Length of labels: 141\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of image data: {len(resized_images_array)}\")\n",
    "print(f\"Length of labels: {len(labels_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (10, 84, 84, 72, 1)\n",
      "Dummy label shape: (10, 1)\n",
      "Label shape: (10,)\n",
      "Model output shape: (10, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the dataset\n",
    "for (image, dummy_label), label in train_dataset.take(1):\n",
    "    print(\"Image batch shape:\", image.shape)\n",
    "    print(\"Dummy label shape:\", dummy_label.shape)\n",
    "    print(\"Label shape:\", label.shape)\n",
    "\n",
    "    # Test the model with this sample batch\n",
    "    try:\n",
    "        output = classification_model((image, dummy_label))\n",
    "        print(\"Model output shape:\", output.shape)\n",
    "    except Exception as e:\n",
    "        print(\"Error testing model:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(2):  # Example for 2 epochs\\n    print(f\"Epoch {epoch+1}\")\\n    for (images, dummy_labels), labels in train_dataset:\\n        with tf.GradientTape() as tape:\\n            predictions = classification_model((images, dummy_labels), training=True)\\n            predictions = tf.squeeze(predictions, axis=-1)  # Squeeze predictions to match label shape\\n            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\\n\\n        gradients = tape.gradient(loss, classification_model.trainable_variables)\\n        classification_model.optimizer.apply_gradients(zip(gradients, classification_model.trainable_variables))\\n\\n    print(f\"Epoch {epoch+1} completed\")\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual training loop for  debugging\n",
    "'''\n",
    "for epoch in range(2):  # Example for 2 epochs\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for (images, dummy_labels), labels in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = classification_model((images, dummy_labels), training=True)\n",
    "            predictions = tf.squeeze(predictions, axis=-1)  # Squeeze predictions to match label shape\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, classification_model.trainable_variables)\n",
    "        classification_model.optimizer.apply_gradients(zip(gradients, classification_model.trainable_variables))\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define the number of epochs\\nepochs = 10000\\n\\n# Metrics to monitor\\ntrain_loss_metric = tf.keras.metrics.BinaryCrossentropy(name=\\'train_loss\\')\\ntrain_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name=\\'train_accuracy\\')\\nval_loss_metric = tf.keras.metrics.BinaryCrossentropy(name=\\'val_loss\\')\\nval_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name=\\'val_accuracy\\')\\n\\nfor epoch in range(epochs):\\n    print(f\"Epoch {epoch+1}/{epochs}\")\\n\\n    # Training loop\\n    for (images, dummy_labels), labels in train_dataset:\\n        with tf.GradientTape() as tape:\\n            predictions = classification_model((images, dummy_labels), training=True)\\n            predictions = tf.squeeze(predictions, axis=-1)  # Squeeze predictions to match label shape\\n            loss = tf.keras.losses.binary_crossentropy(labels, predictions, from_logits=True)\\n        gradients = tape.gradient(loss, classification_model.trainable_variables)\\n        classification_model.optimizer.apply_gradients(zip(gradients, classification_model.trainable_variables))\\n        \\n        # Update training metrics\\n        train_loss_metric.update_state(labels, predictions)\\n        train_accuracy_metric.update_state(labels, predictions)\\n\\n    # Validation loop\\n    for (images, dummy_labels), labels in eval_dataset:\\n        predictions = classification_model((images, dummy_labels), training=False)\\n        val_loss_metric.update_state(labels, predictions)\\n        val_accuracy_metric.update_state(labels, predictions)\\n\\n    # Display metrics at the end of each epoch\\n    train_loss = train_loss_metric.result()\\n    train_accuracy = train_accuracy_metric.result()\\n    val_loss = val_loss_metric.result()\\n    val_accuracy = val_accuracy_metric.result()\\n\\n    print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\\n    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\\n\\n    # Reset metrics at the end of each epoch\\n    #train_loss_metric.reset_states()\\n    #train_accuracy_metric.reset_states()\\n    #val_loss_metric.reset_states()\\n    #val_accuracy_metric.reset_states() '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Define the number of epochs\n",
    "epochs = 10000\n",
    "\n",
    "# Metrics to monitor\n",
    "train_loss_metric = tf.keras.metrics.BinaryCrossentropy(name='train_loss')\n",
    "train_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "val_loss_metric = tf.keras.metrics.BinaryCrossentropy(name='val_loss')\n",
    "val_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    # Training loop\n",
    "    for (images, dummy_labels), labels in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = classification_model((images, dummy_labels), training=True)\n",
    "            predictions = tf.squeeze(predictions, axis=-1)  # Squeeze predictions to match label shape\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels, predictions, from_logits=True)\n",
    "        gradients = tape.gradient(loss, classification_model.trainable_variables)\n",
    "        classification_model.optimizer.apply_gradients(zip(gradients, classification_model.trainable_variables))\n",
    "        \n",
    "        # Update training metrics\n",
    "        train_loss_metric.update_state(labels, predictions)\n",
    "        train_accuracy_metric.update_state(labels, predictions)\n",
    "\n",
    "    # Validation loop\n",
    "    for (images, dummy_labels), labels in eval_dataset:\n",
    "        predictions = classification_model((images, dummy_labels), training=False)\n",
    "        val_loss_metric.update_state(labels, predictions)\n",
    "        val_accuracy_metric.update_state(labels, predictions)\n",
    "\n",
    "    # Display metrics at the end of each epoch\n",
    "    train_loss = train_loss_metric.result()\n",
    "    train_accuracy = train_accuracy_metric.result()\n",
    "    val_loss = val_loss_metric.result()\n",
    "    val_accuracy = val_accuracy_metric.result()\n",
    "\n",
    "    print(f\"Train loss: {train_loss}, Train accuracy: {train_accuracy}\")\n",
    "    print(f\"Validation loss: {val_loss}, Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "    # Reset metrics at the end of each epoch\n",
    "    #train_loss_metric.reset_states()\n",
    "    #train_accuracy_metric.reset_states()\n",
    "    #val_loss_metric.reset_states()\n",
    "    #val_accuracy_metric.reset_states() '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 05:04:53.919155: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f81d4059f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-03 05:04:53.919183: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-01-03 05:04:53.926884: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-03 05:04:53.949450: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1704258294.029346   11540 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 18ms/step - loss: 8.0165 - accuracy: 0.4911 - val_loss: 7.2862 - val_accuracy: 0.2759\n",
      "Epoch 2/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.8425 - accuracy: 0.5089 - val_loss: 8.1631 - val_accuracy: 0.2759\n",
      "Epoch 3/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1198 - accuracy: 0.5268 - val_loss: 3.1080 - val_accuracy: 0.2759\n",
      "Epoch 4/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0907 - accuracy: 0.5268 - val_loss: 0.7028 - val_accuracy: 0.7241\n",
      "Epoch 5/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8035 - accuracy: 0.4375 - val_loss: 0.5930 - val_accuracy: 0.7241\n",
      "Epoch 6/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9496 - accuracy: 0.4196 - val_loss: 0.6013 - val_accuracy: 0.7241\n",
      "Epoch 7/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7881 - accuracy: 0.4911 - val_loss: 0.9825 - val_accuracy: 0.2759\n",
      "Epoch 8/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8634 - accuracy: 0.5089 - val_loss: 0.6719 - val_accuracy: 0.7241\n",
      "Epoch 9/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8908 - accuracy: 0.4375 - val_loss: 0.5891 - val_accuracy: 0.7241\n",
      "Epoch 10/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7339 - accuracy: 0.4911 - val_loss: 1.0722 - val_accuracy: 0.2759\n",
      "Epoch 11/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9059 - accuracy: 0.4375 - val_loss: 0.6684 - val_accuracy: 0.7241\n",
      "Epoch 12/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7646 - accuracy: 0.4911 - val_loss: 0.5926 - val_accuracy: 0.7241\n",
      "Epoch 13/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7877 - accuracy: 0.4911 - val_loss: 0.8467 - val_accuracy: 0.2759\n",
      "Epoch 14/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.8823 - accuracy: 0.5089 - val_loss: 0.6115 - val_accuracy: 0.7241\n",
      "Epoch 15/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8412 - accuracy: 0.4911 - val_loss: 0.6026 - val_accuracy: 0.7241\n",
      "Epoch 16/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7875 - accuracy: 0.4732 - val_loss: 0.8165 - val_accuracy: 0.2759\n",
      "Epoch 17/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8632 - accuracy: 0.5089 - val_loss: 0.7808 - val_accuracy: 0.7241\n",
      "Epoch 18/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2380 - accuracy: 0.5446 - val_loss: 0.6024 - val_accuracy: 0.7241\n",
      "Epoch 19/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.9173 - accuracy: 0.4732 - val_loss: 0.6966 - val_accuracy: 0.2759\n",
      "Epoch 20/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.8151 - accuracy: 0.4732 - val_loss: 0.6650 - val_accuracy: 0.7241\n",
      "Epoch 21/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.9544 - accuracy: 0.4911 - val_loss: 0.8421 - val_accuracy: 0.7241\n",
      "Epoch 22/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5565 - accuracy: 0.5268 - val_loss: 1.0300 - val_accuracy: 0.7241\n",
      "Epoch 23/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0444 - accuracy: 0.4375 - val_loss: 0.7407 - val_accuracy: 0.2759\n",
      "Epoch 24/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7849 - accuracy: 0.4554 - val_loss: 0.5975 - val_accuracy: 0.7241\n",
      "Epoch 25/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7223 - accuracy: 0.5089 - val_loss: 0.5900 - val_accuracy: 0.7241\n",
      "Epoch 26/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8705 - accuracy: 0.4732 - val_loss: 0.6375 - val_accuracy: 0.7241\n",
      "Epoch 27/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0122 - accuracy: 0.5625 - val_loss: 0.5970 - val_accuracy: 0.7241\n",
      "Epoch 28/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.8006 - accuracy: 0.4732 - val_loss: 1.1682 - val_accuracy: 0.2759\n",
      "Epoch 29/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9655 - accuracy: 0.4911 - val_loss: 0.6702 - val_accuracy: 0.7241\n",
      "Epoch 30/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.9628 - accuracy: 0.4375 - val_loss: 0.5896 - val_accuracy: 0.7241\n",
      "Epoch 31/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7798 - accuracy: 0.4911 - val_loss: 0.7849 - val_accuracy: 0.2759\n",
      "Epoch 32/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7525 - accuracy: 0.5446 - val_loss: 1.7403 - val_accuracy: 0.2759\n",
      "Epoch 33/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0222 - accuracy: 0.4554 - val_loss: 0.8029 - val_accuracy: 0.2759\n",
      "Epoch 34/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8306 - accuracy: 0.5089 - val_loss: 0.5897 - val_accuracy: 0.7241\n",
      "Epoch 35/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7396 - accuracy: 0.4911 - val_loss: 0.5898 - val_accuracy: 0.7241\n",
      "Epoch 36/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.0295 - accuracy: 0.4911 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 37/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.8348 - accuracy: 0.4196 - val_loss: 0.6052 - val_accuracy: 0.7241\n",
      "Epoch 38/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7965 - accuracy: 0.4732 - val_loss: 0.6658 - val_accuracy: 0.7241\n",
      "Epoch 39/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7464 - accuracy: 0.5089 - val_loss: 0.8014 - val_accuracy: 0.2759\n",
      "Epoch 40/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7513 - accuracy: 0.4911 - val_loss: 0.7867 - val_accuracy: 0.2759\n",
      "Epoch 41/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7313 - accuracy: 0.4732 - val_loss: 0.5960 - val_accuracy: 0.7241\n",
      "Epoch 42/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7259 - accuracy: 0.5446 - val_loss: 0.6728 - val_accuracy: 0.7241\n",
      "Epoch 43/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7026 - accuracy: 0.4732 - val_loss: 0.6698 - val_accuracy: 0.7241\n",
      "Epoch 44/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6987 - accuracy: 0.4554 - val_loss: 0.6474 - val_accuracy: 0.7241\n",
      "Epoch 45/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6958 - accuracy: 0.5446 - val_loss: 0.7066 - val_accuracy: 0.2759\n",
      "Epoch 46/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6960 - accuracy: 0.4911 - val_loss: 0.6312 - val_accuracy: 0.7241\n",
      "Epoch 47/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7181 - accuracy: 0.4911 - val_loss: 0.6027 - val_accuracy: 0.7241\n",
      "Epoch 48/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7216 - accuracy: 0.5625 - val_loss: 0.7779 - val_accuracy: 0.2759\n",
      "Epoch 49/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7151 - accuracy: 0.4375 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 50/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.5446 - val_loss: 0.6429 - val_accuracy: 0.7241\n",
      "Epoch 51/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7103 - accuracy: 0.5446 - val_loss: 0.6798 - val_accuracy: 0.7241\n",
      "Epoch 52/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7050 - accuracy: 0.4554 - val_loss: 0.6159 - val_accuracy: 0.7241\n",
      "Epoch 53/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7188 - accuracy: 0.4911 - val_loss: 0.7308 - val_accuracy: 0.2759\n",
      "Epoch 54/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7151 - accuracy: 0.5089 - val_loss: 0.6251 - val_accuracy: 0.7241\n",
      "Epoch 55/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6998 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 56/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7060 - accuracy: 0.5446 - val_loss: 0.6380 - val_accuracy: 0.7241\n",
      "Epoch 57/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7115 - accuracy: 0.4375 - val_loss: 0.6898 - val_accuracy: 0.7241\n",
      "Epoch 58/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.4554 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 59/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6968 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 60/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6938 - accuracy: 0.4554 - val_loss: 0.6869 - val_accuracy: 0.7241\n",
      "Epoch 61/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7089 - accuracy: 0.5446 - val_loss: 0.6363 - val_accuracy: 0.7241\n",
      "Epoch 62/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6980 - accuracy: 0.4554 - val_loss: 0.6849 - val_accuracy: 0.7241\n",
      "Epoch 63/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 64/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6936 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 65/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6968 - accuracy: 0.5446 - val_loss: 0.6495 - val_accuracy: 0.7241\n",
      "Epoch 66/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5446 - val_loss: 0.6484 - val_accuracy: 0.7241\n",
      "Epoch 67/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6967 - accuracy: 0.5446 - val_loss: 0.6406 - val_accuracy: 0.7241\n",
      "Epoch 68/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6982 - accuracy: 0.5446 - val_loss: 0.6501 - val_accuracy: 0.7241\n",
      "Epoch 69/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6908 - accuracy: 0.5089 - val_loss: 0.6461 - val_accuracy: 0.7241\n",
      "Epoch 70/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.7134 - accuracy: 0.4196 - val_loss: 0.6824 - val_accuracy: 0.7241\n",
      "Epoch 71/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7024 - accuracy: 0.5446 - val_loss: 0.5922 - val_accuracy: 0.7241\n",
      "Epoch 72/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7285 - accuracy: 0.5446 - val_loss: 0.5984 - val_accuracy: 0.7241\n",
      "Epoch 73/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6934 - accuracy: 0.5089 - val_loss: 0.7087 - val_accuracy: 0.2759\n",
      "Epoch 74/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6937 - accuracy: 0.5268 - val_loss: 0.6136 - val_accuracy: 0.7241\n",
      "Epoch 75/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7011 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 76/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6943 - accuracy: 0.5089 - val_loss: 0.6947 - val_accuracy: 0.2759\n",
      "Epoch 77/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6949 - accuracy: 0.5625 - val_loss: 0.6229 - val_accuracy: 0.7241\n",
      "Epoch 78/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6936 - accuracy: 0.5446 - val_loss: 0.6506 - val_accuracy: 0.7241\n",
      "Epoch 79/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6887 - accuracy: 0.5446 - val_loss: 0.6753 - val_accuracy: 0.7241\n",
      "Epoch 80/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 81/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6952 - accuracy: 0.5446 - val_loss: 0.6415 - val_accuracy: 0.7241\n",
      "Epoch 82/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.5446 - val_loss: 0.6773 - val_accuracy: 0.7241\n",
      "Epoch 83/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6924 - accuracy: 0.5446 - val_loss: 0.6732 - val_accuracy: 0.7241\n",
      "Epoch 84/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6910 - accuracy: 0.5446 - val_loss: 0.6340 - val_accuracy: 0.7241\n",
      "Epoch 85/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6922 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 86/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6929 - accuracy: 0.5089 - val_loss: 0.7094 - val_accuracy: 0.2759\n",
      "Epoch 87/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.5089 - val_loss: 0.5992 - val_accuracy: 0.7241\n",
      "Epoch 88/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7807 - accuracy: 0.4375 - val_loss: 0.6926 - val_accuracy: 0.7241\n",
      "Epoch 89/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7013 - accuracy: 0.4732 - val_loss: 0.6774 - val_accuracy: 0.7241\n",
      "Epoch 90/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7173 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 91/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6955 - accuracy: 0.5268 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 92/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7037 - accuracy: 0.5446 - val_loss: 0.6493 - val_accuracy: 0.7241\n",
      "Epoch 93/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7007 - accuracy: 0.4732 - val_loss: 0.6770 - val_accuracy: 0.7241\n",
      "Epoch 94/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7131 - accuracy: 0.4911 - val_loss: 0.7301 - val_accuracy: 0.2759\n",
      "Epoch 95/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7235 - accuracy: 0.4911 - val_loss: 0.6909 - val_accuracy: 0.7241\n",
      "Epoch 96/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 97/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6951 - accuracy: 0.4732 - val_loss: 0.6875 - val_accuracy: 0.7241\n",
      "Epoch 98/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7313 - accuracy: 0.4375 - val_loss: 0.6837 - val_accuracy: 0.7241\n",
      "Epoch 99/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6976 - accuracy: 0.5446 - val_loss: 0.6178 - val_accuracy: 0.7241\n",
      "Epoch 100/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7018 - accuracy: 0.5446 - val_loss: 0.6708 - val_accuracy: 0.7241\n",
      "Epoch 101/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5446 - val_loss: 0.6660 - val_accuracy: 0.7241\n",
      "Epoch 102/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6914 - accuracy: 0.5446 - val_loss: 0.6494 - val_accuracy: 0.7241\n",
      "Epoch 103/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5446 - val_loss: 0.6860 - val_accuracy: 0.7241\n",
      "Epoch 104/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.4196 - val_loss: 0.6797 - val_accuracy: 0.7241\n",
      "Epoch 105/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6980 - accuracy: 0.5446 - val_loss: 0.6292 - val_accuracy: 0.7241\n",
      "Epoch 106/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5446 - val_loss: 0.6348 - val_accuracy: 0.7241\n",
      "Epoch 107/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5446 - val_loss: 0.6695 - val_accuracy: 0.7241\n",
      "Epoch 108/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6882 - accuracy: 0.5446 - val_loss: 0.5899 - val_accuracy: 0.7241\n",
      "Epoch 109/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7142 - accuracy: 0.5268 - val_loss: 0.7149 - val_accuracy: 0.2759\n",
      "Epoch 110/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7012 - accuracy: 0.4375 - val_loss: 0.6956 - val_accuracy: 0.2759\n",
      "Epoch 111/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.4732 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 112/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6946 - accuracy: 0.5446 - val_loss: 0.6229 - val_accuracy: 0.7241\n",
      "Epoch 113/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 114/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 115/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5446 - val_loss: 0.6856 - val_accuracy: 0.7241\n",
      "Epoch 116/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.4375 - val_loss: 0.6786 - val_accuracy: 0.7241\n",
      "Epoch 117/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.5446 - val_loss: 0.6201 - val_accuracy: 0.7241\n",
      "Epoch 118/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6976 - accuracy: 0.5446 - val_loss: 0.6291 - val_accuracy: 0.7241\n",
      "Epoch 119/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6881 - accuracy: 0.5446 - val_loss: 0.6660 - val_accuracy: 0.7241\n",
      "Epoch 120/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6771 - val_accuracy: 0.7241\n",
      "Epoch 121/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6908 - accuracy: 0.5446 - val_loss: 0.6687 - val_accuracy: 0.7241\n",
      "Epoch 122/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 123/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5446 - val_loss: 0.6360 - val_accuracy: 0.7241\n",
      "Epoch 124/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6921 - accuracy: 0.5446 - val_loss: 0.6400 - val_accuracy: 0.7241\n",
      "Epoch 125/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 126/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6974 - accuracy: 0.4554 - val_loss: 0.6954 - val_accuracy: 0.2759\n",
      "Epoch 127/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6929 - accuracy: 0.5268 - val_loss: 0.6412 - val_accuracy: 0.7241\n",
      "Epoch 128/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 129/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.5446 - val_loss: 0.6468 - val_accuracy: 0.7241\n",
      "Epoch 130/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6883 - accuracy: 0.5446 - val_loss: 0.6818 - val_accuracy: 0.7241\n",
      "Epoch 131/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6926 - accuracy: 0.4732 - val_loss: 0.6982 - val_accuracy: 0.2759\n",
      "Epoch 132/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6937 - accuracy: 0.4732 - val_loss: 0.6869 - val_accuracy: 0.7241\n",
      "Epoch 133/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5446 - val_loss: 0.6668 - val_accuracy: 0.7241\n",
      "Epoch 134/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6934 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 135/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5446 - val_loss: 0.6663 - val_accuracy: 0.7241\n",
      "Epoch 136/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6909 - accuracy: 0.5446 - val_loss: 0.6756 - val_accuracy: 0.7241\n",
      "Epoch 137/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.5446 - val_loss: 0.6912 - val_accuracy: 0.7241\n",
      "Epoch 138/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6926 - accuracy: 0.5446 - val_loss: 0.6838 - val_accuracy: 0.7241\n",
      "Epoch 139/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6926 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 140/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6708 - val_accuracy: 0.7241\n",
      "Epoch 141/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 142/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.5446 - val_loss: 0.6858 - val_accuracy: 0.7241\n",
      "Epoch 143/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6920 - accuracy: 0.5446 - val_loss: 0.6812 - val_accuracy: 0.7241\n",
      "Epoch 144/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.5446 - val_loss: 0.6745 - val_accuracy: 0.7241\n",
      "Epoch 145/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6887 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 146/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6375 - val_accuracy: 0.7241\n",
      "Epoch 147/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6973 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 148/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.5446 - val_loss: 0.6636 - val_accuracy: 0.7241\n",
      "Epoch 149/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 150/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6718 - val_accuracy: 0.7241\n",
      "Epoch 151/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.5446 - val_loss: 0.6700 - val_accuracy: 0.7241\n",
      "Epoch 152/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6695 - val_accuracy: 0.7241\n",
      "Epoch 153/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6662 - val_accuracy: 0.7241\n",
      "Epoch 154/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6673 - val_accuracy: 0.7241\n",
      "Epoch 155/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6904 - accuracy: 0.5446 - val_loss: 0.6688 - val_accuracy: 0.7241\n",
      "Epoch 156/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6705 - val_accuracy: 0.7241\n",
      "Epoch 157/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6903 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 158/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6913 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 159/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6483 - val_accuracy: 0.7241\n",
      "Epoch 160/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6945 - accuracy: 0.5446 - val_loss: 0.6696 - val_accuracy: 0.7241\n",
      "Epoch 161/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6695 - val_accuracy: 0.7241\n",
      "Epoch 162/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 163/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7014 - accuracy: 0.5446 - val_loss: 0.6497 - val_accuracy: 0.7241\n",
      "Epoch 164/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6695 - val_accuracy: 0.7241\n",
      "Epoch 165/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6682 - val_accuracy: 0.7241\n",
      "Epoch 166/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6688 - val_accuracy: 0.7241\n",
      "Epoch 167/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6690 - val_accuracy: 0.7241\n",
      "Epoch 168/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.5446 - val_loss: 0.6668 - val_accuracy: 0.7241\n",
      "Epoch 169/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6660 - val_accuracy: 0.7241\n",
      "Epoch 170/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6919 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 171/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6928 - accuracy: 0.5446 - val_loss: 0.6480 - val_accuracy: 0.7241\n",
      "Epoch 172/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5089 - val_loss: 0.6912 - val_accuracy: 0.7241\n",
      "Epoch 173/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6923 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 174/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6903 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 175/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6906 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 176/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6652 - val_accuracy: 0.7241\n",
      "Epoch 177/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6998 - accuracy: 0.4732 - val_loss: 0.6650 - val_accuracy: 0.7241\n",
      "Epoch 178/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7068 - accuracy: 0.5446 - val_loss: 0.6953 - val_accuracy: 0.2759\n",
      "Epoch 179/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.7217 - accuracy: 0.4554 - val_loss: 0.5968 - val_accuracy: 0.7241\n",
      "Epoch 180/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5268 - val_loss: 0.7426 - val_accuracy: 0.2759\n",
      "Epoch 181/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6983 - accuracy: 0.4732 - val_loss: 0.6655 - val_accuracy: 0.7241\n",
      "Epoch 182/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 183/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.5446 - val_loss: 0.6696 - val_accuracy: 0.7241\n",
      "Epoch 184/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6692 - val_accuracy: 0.7241\n",
      "Epoch 185/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6677 - val_accuracy: 0.7241\n",
      "Epoch 186/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6657 - val_accuracy: 0.7241\n",
      "Epoch 187/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 188/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 189/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 190/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 191/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 192/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 193/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 194/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 195/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 196/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6632 - val_accuracy: 0.7241\n",
      "Epoch 197/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6647 - val_accuracy: 0.7241\n",
      "Epoch 198/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 199/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 200/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6652 - val_accuracy: 0.7241\n",
      "Epoch 201/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 202/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6649 - val_accuracy: 0.7241\n",
      "Epoch 203/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6650 - val_accuracy: 0.7241\n",
      "Epoch 204/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 205/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 206/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 207/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 208/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 209/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6638 - val_accuracy: 0.7241\n",
      "Epoch 210/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 211/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 212/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6633 - val_accuracy: 0.7241\n",
      "Epoch 213/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 214/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 215/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 216/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 217/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 218/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 219/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 220/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 221/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 222/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 223/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 224/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 225/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 226/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 227/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 228/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 229/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 230/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 231/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 232/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 233/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 234/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 235/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 236/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 237/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 238/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 239/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 240/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 241/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 242/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 243/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 244/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 245/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 246/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 247/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6503 - val_accuracy: 0.7241\n",
      "Epoch 248/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 249/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 250/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 251/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 252/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 253/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 254/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 255/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 256/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 257/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 258/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 259/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 260/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 261/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 262/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 263/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 264/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 265/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 266/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 267/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 268/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 269/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 270/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 271/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 272/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 273/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 274/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 275/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 276/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 277/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 278/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 279/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 280/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 281/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 282/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 283/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 284/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 285/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 286/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 287/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 288/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 289/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 290/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 291/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 292/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 293/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 294/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 295/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 296/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 297/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 298/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 299/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 300/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 301/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 302/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 303/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 304/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 305/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 306/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 307/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 308/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 309/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 310/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 311/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 312/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 313/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 314/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 315/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 316/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 317/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 318/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 319/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 320/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 321/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 322/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 323/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 324/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 325/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 326/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 327/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 328/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 329/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 330/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 331/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 332/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6636 - val_accuracy: 0.7241\n",
      "Epoch 333/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6644 - val_accuracy: 0.7241\n",
      "Epoch 334/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6656 - val_accuracy: 0.7241\n",
      "Epoch 335/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6658 - val_accuracy: 0.7241\n",
      "Epoch 336/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6656 - val_accuracy: 0.7241\n",
      "Epoch 337/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6650 - val_accuracy: 0.7241\n",
      "Epoch 338/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 339/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 340/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 341/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 342/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 343/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 344/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 345/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 346/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 347/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 348/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 349/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 350/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 351/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 352/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 353/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 354/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 355/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 356/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 357/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 358/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 359/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 360/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 361/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 362/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 363/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 364/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 365/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 366/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 367/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 368/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 369/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 370/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 371/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 372/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 373/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 374/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 375/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 376/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 377/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 378/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 379/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 380/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 381/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 382/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 383/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 384/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 385/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 386/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 387/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 388/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 389/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 390/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 391/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 392/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 393/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 394/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 395/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 396/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 397/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 398/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 399/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 400/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 401/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 402/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 403/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 404/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 405/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 406/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 407/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 408/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 409/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 410/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 411/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 412/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 413/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 414/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 415/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 416/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 417/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 418/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 419/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 420/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 421/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 422/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 423/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 424/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 425/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 426/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 427/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 428/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 429/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 430/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 431/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 432/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 433/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 434/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 435/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 436/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 437/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 438/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 439/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 440/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 441/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 442/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 443/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 444/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 445/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 446/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 447/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 448/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 449/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 450/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 451/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 452/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 453/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 454/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 455/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 456/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 457/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 458/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 459/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 460/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 461/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 462/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 463/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 464/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 465/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 466/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 467/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 468/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 469/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 470/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 471/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 472/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 473/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 474/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 475/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 476/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 477/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 478/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 479/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 480/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 481/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 482/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 483/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 484/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 485/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 486/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 487/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 488/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 489/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 490/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 491/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 492/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 493/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 494/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 495/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 496/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 497/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 498/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 499/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 500/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 501/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 502/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 503/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 504/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 505/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 506/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 507/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 508/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 509/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 510/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 511/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 512/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 513/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 514/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 515/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 516/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 517/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 518/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 519/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 520/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 521/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 522/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 523/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 524/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 525/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 526/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 527/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 528/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 529/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 530/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 531/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 532/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 533/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 534/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 535/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 536/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 537/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 538/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 539/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 540/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 541/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 542/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 543/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 544/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 545/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 546/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 547/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 548/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 549/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 550/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 551/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 552/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 553/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 554/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 555/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 556/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 557/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 558/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 559/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 560/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 561/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 562/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 563/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 564/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 565/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 566/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 567/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 568/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 569/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 570/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 571/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 572/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 573/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 574/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 575/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 576/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 577/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 578/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 579/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 580/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 581/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 582/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 583/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 584/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 585/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 586/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 587/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 588/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 589/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 590/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 591/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 592/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 593/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 594/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 595/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 596/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 597/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 598/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 599/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 600/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 601/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 602/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 603/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 604/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 605/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 606/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 607/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6647 - val_accuracy: 0.7241\n",
      "Epoch 608/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6650 - val_accuracy: 0.7241\n",
      "Epoch 609/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6662 - val_accuracy: 0.7241\n",
      "Epoch 610/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6649 - val_accuracy: 0.7241\n",
      "Epoch 611/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 612/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 613/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6644 - val_accuracy: 0.7241\n",
      "Epoch 614/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 615/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 616/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 617/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 618/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 619/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 620/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 621/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 622/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 623/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 624/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 625/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 626/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 627/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 628/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 629/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 630/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 631/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 632/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 633/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 634/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 635/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 636/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 637/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 638/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 639/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 640/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 641/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 642/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 643/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 644/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 645/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 646/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 647/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 648/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 649/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 650/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 651/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 652/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 653/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 654/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 655/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 656/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6632 - val_accuracy: 0.7241\n",
      "Epoch 657/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 658/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 659/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 660/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 661/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 662/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 663/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 664/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 665/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 666/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6647 - val_accuracy: 0.7241\n",
      "Epoch 667/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 668/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 669/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6652 - val_accuracy: 0.7241\n",
      "Epoch 670/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6646 - val_accuracy: 0.7241\n",
      "Epoch 671/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6662 - val_accuracy: 0.7241\n",
      "Epoch 672/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6647 - val_accuracy: 0.7241\n",
      "Epoch 673/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 674/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 675/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 676/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 677/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 678/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 679/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 680/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 681/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 682/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 683/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 684/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 685/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 686/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 687/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 688/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 689/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 690/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 691/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 692/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 693/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 694/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 695/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 696/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 697/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6515 - val_accuracy: 0.7241\n",
      "Epoch 698/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 699/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 700/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 701/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 702/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 703/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 704/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 705/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 706/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 707/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 708/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 709/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 710/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 711/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 712/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 713/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 714/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 715/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 716/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 717/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 718/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 719/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 720/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 721/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 722/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 723/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 724/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 725/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 726/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 727/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 728/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 729/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 730/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 731/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 732/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 733/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 734/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 735/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 736/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 737/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 738/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 739/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 740/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 741/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 742/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 743/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 744/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 745/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 746/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 747/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 748/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 749/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 750/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 751/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 752/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 753/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 754/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 755/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 756/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 757/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 758/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 759/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 760/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 761/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 762/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 763/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 764/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 765/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 766/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 767/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 768/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 769/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 770/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 771/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 772/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 773/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 774/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 775/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 776/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 777/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 778/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 779/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 780/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 781/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 782/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 783/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 784/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 785/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 786/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 787/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 788/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 789/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 790/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 791/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 792/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6633 - val_accuracy: 0.7241\n",
      "Epoch 793/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 794/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 795/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 796/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 797/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 798/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6645 - val_accuracy: 0.7241\n",
      "Epoch 799/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6644 - val_accuracy: 0.7241\n",
      "Epoch 800/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 801/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6646 - val_accuracy: 0.7241\n",
      "Epoch 802/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 803/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 804/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6638 - val_accuracy: 0.7241\n",
      "Epoch 805/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 806/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 807/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 808/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6651 - val_accuracy: 0.7241\n",
      "Epoch 809/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 810/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 811/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 812/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 813/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 814/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 815/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 816/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 817/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 818/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 819/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 820/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 821/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 822/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 823/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 824/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 825/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 826/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 827/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 828/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 829/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 830/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 831/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 832/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 833/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 834/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 835/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 836/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 837/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 838/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 839/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 840/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 841/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 842/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 843/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 844/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 845/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 846/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 847/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 848/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 849/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 850/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 851/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 852/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 853/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 854/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 855/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 856/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 857/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 858/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 859/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 860/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 861/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 862/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 863/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 864/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 865/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 866/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 867/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 868/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 869/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 870/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 871/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 872/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 873/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 874/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 875/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 876/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 877/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 878/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 879/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 880/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 881/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 882/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 883/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 884/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 885/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 886/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 887/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 888/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 889/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 890/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 891/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 892/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 893/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 894/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 895/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 896/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 897/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 898/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 899/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 900/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 901/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 902/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6512 - val_accuracy: 0.7241\n",
      "Epoch 903/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 904/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 905/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 906/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 907/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 908/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 909/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 910/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 911/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 912/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 913/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 914/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 915/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 916/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 917/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 918/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 919/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 920/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 921/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 922/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 923/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 924/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 925/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 926/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 927/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 928/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 929/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 930/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 931/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 932/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 933/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 934/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 935/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 936/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 937/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 938/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 939/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 940/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 941/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 942/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 943/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6503 - val_accuracy: 0.7241\n",
      "Epoch 944/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6504 - val_accuracy: 0.7241\n",
      "Epoch 945/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6504 - val_accuracy: 0.7241\n",
      "Epoch 946/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 947/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6513 - val_accuracy: 0.7241\n",
      "Epoch 948/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6505 - val_accuracy: 0.7241\n",
      "Epoch 949/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6507 - val_accuracy: 0.7241\n",
      "Epoch 950/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6509 - val_accuracy: 0.7241\n",
      "Epoch 951/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 952/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 953/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 954/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 955/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 956/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 957/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 958/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 959/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 960/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 961/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 962/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 963/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 964/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 965/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 966/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 967/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 968/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 969/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 970/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 971/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 972/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 973/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 974/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 975/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 976/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 977/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 978/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 979/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 980/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 981/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 982/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 983/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 984/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 985/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 986/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 987/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 988/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 989/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 990/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 991/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 992/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 993/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 994/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 995/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 996/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 997/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 998/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 999/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1000/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1001/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 1002/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 1003/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 1004/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1005/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 1006/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1007/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1008/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1009/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1010/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1011/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1012/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1013/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1014/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1015/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1016/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1017/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1018/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1019/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1020/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1021/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1022/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1023/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1024/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1025/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1026/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1027/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1028/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1029/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1030/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1031/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1032/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1033/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1034/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1035/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 1036/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1037/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1038/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1039/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1040/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1041/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1042/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1043/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1044/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1045/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1046/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1047/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1048/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1049/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1050/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1051/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1052/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1053/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1054/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1055/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1056/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1057/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1058/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1059/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1060/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1061/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1062/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1063/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1064/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1065/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1066/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1067/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1068/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1069/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1070/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1071/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1072/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1073/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1074/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1075/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 1076/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1077/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 1078/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1079/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1080/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1081/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1082/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1083/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1084/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1085/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1086/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1087/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1088/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1089/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1090/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1091/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 1092/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6645 - val_accuracy: 0.7241\n",
      "Epoch 1093/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 1094/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 1095/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1096/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 1097/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1098/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1099/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1100/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1101/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1102/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1103/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1104/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 1105/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 1106/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1107/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 1108/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1109/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 1110/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1111/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1112/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1113/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1114/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 1115/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 1116/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 1117/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 1118/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 1119/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 1120/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 1121/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 1122/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1123/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1124/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1125/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1126/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1127/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1128/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1129/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 1130/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1131/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1132/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1133/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1134/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1135/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1136/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1137/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1138/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1139/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1140/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1141/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1142/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1143/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1144/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1145/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1146/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1147/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1148/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1149/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1150/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1151/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1152/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1153/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 1154/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1155/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1156/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1157/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1158/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1159/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1160/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1161/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1162/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1163/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1164/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1165/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1166/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1167/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1168/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1169/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1170/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1171/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1172/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1173/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1174/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1175/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 1176/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1177/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 1178/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6514 - val_accuracy: 0.7241\n",
      "Epoch 1179/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6508 - val_accuracy: 0.7241\n",
      "Epoch 1180/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 1181/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6506 - val_accuracy: 0.7241\n",
      "Epoch 1182/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 1183/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6502 - val_accuracy: 0.7241\n",
      "Epoch 1184/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6514 - val_accuracy: 0.7241\n",
      "Epoch 1185/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 1186/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6504 - val_accuracy: 0.7241\n",
      "Epoch 1187/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6502 - val_accuracy: 0.7241\n",
      "Epoch 1188/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1189/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1190/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 1191/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 1192/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 1193/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 1194/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6501 - val_accuracy: 0.7241\n",
      "Epoch 1195/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6514 - val_accuracy: 0.7241\n",
      "Epoch 1196/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1197/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1198/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1199/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1200/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 1201/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1202/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1203/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1204/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1205/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1206/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1207/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1208/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1209/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1210/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1211/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1212/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1213/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1214/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1215/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1216/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1217/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1218/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1219/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 1220/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1221/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 1222/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1223/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1224/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1225/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1226/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1227/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1228/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1229/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1230/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1231/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1232/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1233/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1234/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1235/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 1236/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 1237/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1238/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 1239/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1240/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1241/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6633 - val_accuracy: 0.7241\n",
      "Epoch 1242/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6636 - val_accuracy: 0.7241\n",
      "Epoch 1243/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1244/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1245/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1246/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1247/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1248/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1249/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1250/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1251/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1252/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1253/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1254/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1255/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1256/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1257/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1258/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1259/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1260/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1261/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1262/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 1263/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1264/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1265/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1266/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1267/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1268/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 1269/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 1270/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1271/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1272/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1273/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1274/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 1275/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1276/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1277/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1278/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1279/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1280/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1281/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1282/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1283/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1284/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 1285/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6504 - val_accuracy: 0.7241\n",
      "Epoch 1286/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6494 - val_accuracy: 0.7241\n",
      "Epoch 1287/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6497 - val_accuracy: 0.7241\n",
      "Epoch 1288/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6494 - val_accuracy: 0.7241\n",
      "Epoch 1289/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6492 - val_accuracy: 0.7241\n",
      "Epoch 1290/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6495 - val_accuracy: 0.7241\n",
      "Epoch 1291/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 1292/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 1293/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 1294/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 1295/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1296/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1297/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1298/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1299/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1300/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1301/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1302/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1303/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 1304/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1305/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1306/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1307/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1308/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 1309/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 1310/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 1311/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1312/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 1313/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1314/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1315/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 1316/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1317/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1318/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 1319/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1320/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1321/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1322/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1323/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 1324/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 1325/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 1326/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1327/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1328/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1329/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1330/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1331/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1332/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1333/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1334/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1335/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1336/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 1337/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 1338/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 1339/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 1340/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 1341/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 1342/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1343/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1344/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1345/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1346/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1347/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1348/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1349/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1350/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1351/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1352/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1353/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1354/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1355/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 1356/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1357/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1358/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1359/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1360/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1361/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1362/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1363/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1364/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1365/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1366/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1367/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1368/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1369/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1370/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1371/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1372/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1373/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1374/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1375/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1376/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1377/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1378/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1379/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 1380/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 1381/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 1382/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 1383/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6508 - val_accuracy: 0.7241\n",
      "Epoch 1384/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6515 - val_accuracy: 0.7241\n",
      "Epoch 1385/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1386/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1387/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1388/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1389/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1390/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1391/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 1392/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 1393/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 1394/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1395/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1396/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1397/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1398/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1399/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1400/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1401/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1402/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1403/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1404/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1405/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1406/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1407/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1408/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1409/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1410/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1411/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1412/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1413/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1414/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1415/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1416/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1417/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1418/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1419/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1420/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1421/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1422/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1423/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1424/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1425/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1426/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1427/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1428/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1429/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 1430/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1431/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 1432/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 1433/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1434/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1435/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1436/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1437/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1438/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1439/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1440/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1441/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1442/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1443/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1444/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1445/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1446/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1447/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1448/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1449/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1450/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1451/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1452/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1453/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1454/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1455/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1456/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 1457/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1458/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 1459/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 1460/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6633 - val_accuracy: 0.7241\n",
      "Epoch 1461/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 1462/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6652 - val_accuracy: 0.7241\n",
      "Epoch 1463/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 1464/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 1465/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6632 - val_accuracy: 0.7241\n",
      "Epoch 1466/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 1467/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 1468/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1469/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1470/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 1471/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 1472/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1473/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1474/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1475/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1476/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1477/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1478/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1479/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1480/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 1481/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6633 - val_accuracy: 0.7241\n",
      "Epoch 1482/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6646 - val_accuracy: 0.7241\n",
      "Epoch 1483/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6649 - val_accuracy: 0.7241\n",
      "Epoch 1484/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6652 - val_accuracy: 0.7241\n",
      "Epoch 1485/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 1486/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 1487/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 1488/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1489/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 1490/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 1491/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1492/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1493/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1494/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1495/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1496/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1497/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1498/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1499/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1500/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1501/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1502/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1503/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1504/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1505/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1506/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1507/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1508/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1509/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1510/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1511/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1512/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1513/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 1514/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1515/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1516/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1517/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 1518/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1519/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1520/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1521/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1522/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 1523/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6518 - val_accuracy: 0.7241\n",
      "Epoch 1524/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 1525/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 1526/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6514 - val_accuracy: 0.7241\n",
      "Epoch 1527/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 1528/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6513 - val_accuracy: 0.7241\n",
      "Epoch 1529/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1530/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1531/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 1532/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1533/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1534/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1535/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1536/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1537/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1538/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1539/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1540/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1541/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1542/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1543/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1544/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1545/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1546/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1547/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1548/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1549/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1550/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1551/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1552/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 1553/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 1554/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 1555/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 1556/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 1557/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 1558/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1559/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1560/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1561/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1562/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1563/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1564/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1565/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1566/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1567/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1568/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1569/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1570/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1571/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1572/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1573/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1574/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1575/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1576/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 1577/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 1578/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1579/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1580/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1581/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1582/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1583/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1584/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1585/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1586/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1587/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1588/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1589/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 1590/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1591/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1592/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1593/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1594/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1595/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1596/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1597/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1598/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1599/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1600/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1601/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1602/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1603/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 1604/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1605/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1606/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1607/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1608/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1609/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1610/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1611/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1612/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1613/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1614/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1615/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1616/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1617/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1618/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1619/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 1620/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6902 - accuracy: 0.5446 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 1621/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 1622/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1623/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 1624/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1625/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 1626/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 1627/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1628/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1629/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 1630/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 1631/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1632/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1633/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1634/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1635/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1636/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 1637/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1638/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1639/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1640/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1641/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1642/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1643/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1644/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1645/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1646/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1647/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1648/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1649/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1650/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1651/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1652/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1653/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1654/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 1655/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1656/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 1657/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1658/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 1659/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1660/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1661/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1662/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1663/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1664/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1665/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1666/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1667/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1668/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1669/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1670/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1671/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1672/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1673/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1674/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1675/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1676/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1677/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1678/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 1679/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1680/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 1681/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1682/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1683/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1684/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1685/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1686/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1687/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1688/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1689/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1690/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1691/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1692/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1693/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1694/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1695/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1696/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1697/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1698/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1699/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1700/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1701/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1702/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1703/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1704/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1705/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1706/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1707/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1708/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1709/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1710/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1711/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1712/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1713/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1714/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1715/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1716/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1717/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1718/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1719/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 1720/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6636 - val_accuracy: 0.7241\n",
      "Epoch 1721/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6639 - val_accuracy: 0.7241\n",
      "Epoch 1722/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 1723/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 1724/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1725/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1726/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1727/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1728/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1729/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1730/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1731/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1732/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1733/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1734/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1735/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1736/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1737/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1738/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1739/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1740/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1741/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1742/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1743/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 1744/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1745/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1746/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1747/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 1748/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1749/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 1750/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 1751/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 1752/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 1753/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1754/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 1755/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1756/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1757/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 1758/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1759/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1760/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1761/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1762/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1763/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1764/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1765/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1766/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1767/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1768/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1769/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1770/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1771/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1772/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1773/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1774/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 1775/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1776/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1777/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1778/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1779/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1780/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1781/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1782/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1783/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1784/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1785/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1786/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1787/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1788/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1789/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1790/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1791/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1792/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1793/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1794/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1795/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1796/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1797/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1798/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1799/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1800/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1801/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 1802/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1803/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1804/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1805/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1806/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 1807/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1808/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1809/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 1810/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1811/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1812/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1813/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1814/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 1815/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1816/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1817/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1818/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 1819/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1820/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1821/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1822/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1823/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1824/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1825/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1826/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1827/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1828/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1829/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1830/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1831/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1832/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1833/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1834/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1835/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1836/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1837/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1838/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1839/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1840/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1841/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1842/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1843/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1844/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 1845/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1846/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1847/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1848/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 1849/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1850/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1851/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1852/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 1853/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1854/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1855/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 1856/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1857/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 1858/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1859/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1860/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1861/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1862/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1863/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 1864/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 1865/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 1866/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 1867/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1868/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1869/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1870/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 1871/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1872/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1873/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1874/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 1875/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1876/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 1877/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 1878/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 1879/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1880/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 1881/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 1882/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1883/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1884/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 1885/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 1886/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 1887/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1888/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 1889/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1890/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1891/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1892/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1893/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 1894/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 1895/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 1896/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1897/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1898/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1899/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1900/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1901/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 1902/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 1903/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 1904/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1905/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 1906/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 1907/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1908/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1909/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 1910/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 1911/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 1912/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 1913/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6512 - val_accuracy: 0.7241\n",
      "Epoch 1914/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 1915/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 1916/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 1917/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6512 - val_accuracy: 0.7241\n",
      "Epoch 1918/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 1919/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6504 - val_accuracy: 0.7241\n",
      "Epoch 1920/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6496 - val_accuracy: 0.7241\n",
      "Epoch 1921/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6490 - val_accuracy: 0.7241\n",
      "Epoch 1922/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6479 - val_accuracy: 0.7241\n",
      "Epoch 1923/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6474 - val_accuracy: 0.7241\n",
      "Epoch 1924/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6476 - val_accuracy: 0.7241\n",
      "Epoch 1925/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6467 - val_accuracy: 0.7241\n",
      "Epoch 1926/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6465 - val_accuracy: 0.7241\n",
      "Epoch 1927/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6901 - accuracy: 0.5446 - val_loss: 0.6451 - val_accuracy: 0.7241\n",
      "Epoch 1928/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6454 - val_accuracy: 0.7241\n",
      "Epoch 1929/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6472 - val_accuracy: 0.7241\n",
      "Epoch 1930/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6481 - val_accuracy: 0.7241\n",
      "Epoch 1931/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6491 - val_accuracy: 0.7241\n",
      "Epoch 1932/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 1933/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 1934/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1935/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 1936/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 1937/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 1938/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1939/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 1940/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 1941/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1942/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 1943/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1944/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1945/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1946/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1947/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 1948/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1949/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1950/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1951/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1952/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 1953/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1954/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 1955/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 1956/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 1957/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 1958/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 1959/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1960/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 1961/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 1962/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 1963/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 1964/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 1965/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 1966/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 1967/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 1968/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1969/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 1970/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1971/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 1972/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1973/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 1974/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 1975/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 1976/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 1977/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 1978/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 1979/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1980/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1981/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 1982/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1983/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1984/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 1985/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1986/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 1987/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 1988/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 1989/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 1990/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 1991/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 1992/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 1993/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 1994/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 1995/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 1996/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1997/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 1998/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 1999/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2000/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2001/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2002/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2003/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2004/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2005/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2006/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2007/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2008/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 2009/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6508 - val_accuracy: 0.7241\n",
      "Epoch 2010/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2011/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6512 - val_accuracy: 0.7241\n",
      "Epoch 2012/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 2013/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 2014/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 2015/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 2016/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 2017/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2018/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 2019/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2020/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 2021/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6513 - val_accuracy: 0.7241\n",
      "Epoch 2022/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 2023/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2024/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 2025/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 2026/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2027/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2028/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2029/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 2030/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2031/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2032/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 2033/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2034/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2035/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2036/3000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2037/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2038/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2039/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2040/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2041/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2042/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2043/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2044/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2045/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2046/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2047/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2048/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2049/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2050/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2051/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2052/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2053/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2054/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2055/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2056/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2057/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2058/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2059/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2060/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2061/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2062/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2063/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2064/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2065/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 2066/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 2067/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2068/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2069/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2070/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 2071/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 2072/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 2073/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2074/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2075/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2076/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2077/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2078/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2079/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2080/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2081/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2082/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2083/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2084/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2085/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2086/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2087/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2088/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2089/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2090/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2091/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2092/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2093/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2094/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2095/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2096/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2097/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2098/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2099/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2100/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 2101/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 2102/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2103/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2104/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2105/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2106/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2107/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2108/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2109/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2110/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2111/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2112/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2113/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2114/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2115/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2116/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 2117/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2118/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2119/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2120/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2121/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2122/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2123/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2124/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2125/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2126/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2127/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2128/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2129/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2130/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 2131/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2132/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2133/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 2134/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2135/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2136/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 2137/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2138/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2139/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 2140/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2141/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 2142/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2143/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6502 - val_accuracy: 0.7241\n",
      "Epoch 2144/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6500 - val_accuracy: 0.7241\n",
      "Epoch 2145/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6509 - val_accuracy: 0.7241\n",
      "Epoch 2146/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2147/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6522 - val_accuracy: 0.7241\n",
      "Epoch 2148/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 2149/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 2150/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 2151/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6509 - val_accuracy: 0.7241\n",
      "Epoch 2152/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 2153/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 2154/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2155/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2156/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 2157/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 2158/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 2159/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 2160/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 2161/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2162/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 2163/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2164/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2165/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2166/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2167/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2168/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2169/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2170/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2171/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2172/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2173/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 2174/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 2175/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2176/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 2177/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6533 - val_accuracy: 0.7241\n",
      "Epoch 2178/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2179/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2180/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 2181/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2182/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2183/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2184/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2185/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2186/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2187/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2188/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 2189/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2190/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2191/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 2192/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 2193/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2194/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2195/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2196/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2197/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2198/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2199/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2200/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2201/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2202/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2203/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2204/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2205/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2206/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2207/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2208/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2209/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2210/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2211/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2212/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2213/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2214/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2215/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2216/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2217/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2218/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2219/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2220/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2221/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2222/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2223/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2224/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2225/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2226/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2227/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2228/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2229/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2230/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2231/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2232/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2233/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2234/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2235/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2236/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2237/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2238/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2239/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2240/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2241/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2242/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2243/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2244/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2245/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2246/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2247/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2248/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2249/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2250/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2251/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2252/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2253/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2254/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2255/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2256/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2257/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2258/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2259/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2260/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2261/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2262/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2263/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2264/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2265/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 2266/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2267/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2268/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 2269/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2270/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2271/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2272/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2273/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2274/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2275/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2276/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2277/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2278/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2279/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2280/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2281/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2282/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2283/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2284/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2285/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2286/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2287/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2288/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2289/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2290/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2291/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2292/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2293/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2294/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2295/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2296/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2297/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2298/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2299/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2300/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2301/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2302/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2303/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2304/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2305/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2306/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2307/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2308/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2309/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2310/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2311/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2312/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2313/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2314/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2315/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2316/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2317/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2318/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2319/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2320/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2321/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2322/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2323/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2324/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2325/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2326/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2327/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2328/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2329/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2330/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2331/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2332/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2333/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2334/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2335/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2336/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2337/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2338/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2339/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2340/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2341/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2342/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2343/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2344/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2345/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2346/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2347/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 2348/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2349/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2350/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2351/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 2352/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2353/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2354/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 2355/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2356/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2357/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2358/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2359/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2360/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 2361/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2362/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2363/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2364/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2365/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2366/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2367/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2368/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2369/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2370/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2371/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2372/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2373/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2374/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2375/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2376/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2377/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2378/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2379/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2380/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2381/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2382/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2383/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2384/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2385/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2386/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2387/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2388/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2389/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2390/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2391/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2392/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2393/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2394/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2395/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2396/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2397/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2398/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2399/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2400/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2401/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 2402/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2403/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2404/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2405/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2406/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2407/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2408/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2409/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2410/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2411/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2412/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2413/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2414/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2415/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2416/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2417/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2418/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2419/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2420/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2421/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2422/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2423/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2424/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2425/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2426/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2427/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2428/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2429/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2430/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2431/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2432/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 2433/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 2434/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2435/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2436/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2437/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2438/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2439/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2440/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2441/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2442/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2443/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2444/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2445/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 2446/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2447/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 2448/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2449/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2450/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2451/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2452/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2453/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2454/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2455/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2456/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2457/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2458/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2459/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2460/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2461/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2462/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2463/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2464/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2465/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2466/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2467/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2468/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2469/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2470/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2471/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2472/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2473/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2474/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2475/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2476/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2477/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2478/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2479/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2480/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2481/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2482/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2483/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2484/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2485/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2486/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2487/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2488/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2489/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2490/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2491/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2492/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2493/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2494/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2495/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2496/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2497/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2498/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2499/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2500/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 2501/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2502/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2503/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2504/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2505/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2506/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2507/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 2508/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2509/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6516 - val_accuracy: 0.7241\n",
      "Epoch 2510/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6513 - val_accuracy: 0.7241\n",
      "Epoch 2511/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6506 - val_accuracy: 0.7241\n",
      "Epoch 2512/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6508 - val_accuracy: 0.7241\n",
      "Epoch 2513/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2514/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 2515/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2516/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6528 - val_accuracy: 0.7241\n",
      "Epoch 2517/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 2518/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6524 - val_accuracy: 0.7241\n",
      "Epoch 2519/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 2520/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6515 - val_accuracy: 0.7241\n",
      "Epoch 2521/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 2522/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2523/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2524/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 2525/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 2526/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 2527/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 2528/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 2529/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2530/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2531/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2532/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2533/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2534/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 2535/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2536/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6531 - val_accuracy: 0.7241\n",
      "Epoch 2537/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6519 - val_accuracy: 0.7241\n",
      "Epoch 2538/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 2539/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6502 - val_accuracy: 0.7241\n",
      "Epoch 2540/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6509 - val_accuracy: 0.7241\n",
      "Epoch 2541/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2542/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6506 - val_accuracy: 0.7241\n",
      "Epoch 2543/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6497 - val_accuracy: 0.7241\n",
      "Epoch 2544/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6482 - val_accuracy: 0.7241\n",
      "Epoch 2545/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6505 - val_accuracy: 0.7241\n",
      "Epoch 2546/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6517 - val_accuracy: 0.7241\n",
      "Epoch 2547/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 2548/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 2549/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 2550/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2551/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2552/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2553/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2554/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 2555/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2556/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2557/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2558/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2559/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2560/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2561/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2562/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2563/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2564/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2565/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 2566/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2567/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2568/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2569/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2570/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2571/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2572/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2573/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2574/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2575/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2576/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2577/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2578/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2579/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2580/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2581/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 2582/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2583/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2584/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2585/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 2586/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2587/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2588/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2589/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 2590/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2591/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 2592/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2593/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2594/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 2595/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2596/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2597/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 2598/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2599/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2600/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2601/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 2602/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2603/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2604/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2605/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2606/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 2607/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 2608/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6637 - val_accuracy: 0.7241\n",
      "Epoch 2609/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6654 - val_accuracy: 0.7241\n",
      "Epoch 2610/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6899 - accuracy: 0.5446 - val_loss: 0.6636 - val_accuracy: 0.7241\n",
      "Epoch 2611/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 2612/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 2613/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6643 - val_accuracy: 0.7241\n",
      "Epoch 2614/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6651 - val_accuracy: 0.7241\n",
      "Epoch 2615/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6647 - val_accuracy: 0.7241\n",
      "Epoch 2616/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6642 - val_accuracy: 0.7241\n",
      "Epoch 2617/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 2618/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2619/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 2620/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 2621/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6637 - val_accuracy: 0.7241\n",
      "Epoch 2622/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6631 - val_accuracy: 0.7241\n",
      "Epoch 2623/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 2624/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 2625/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6625 - val_accuracy: 0.7241\n",
      "Epoch 2626/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 2627/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 2628/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 2629/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2630/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2631/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2632/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2633/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2634/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2635/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2636/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2637/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2638/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2639/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2640/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2641/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2642/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2643/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2644/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2645/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 2646/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2647/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2648/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2649/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2650/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2651/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2652/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2653/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2654/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2655/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2656/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2657/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2658/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2659/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2660/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2661/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2662/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2663/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2664/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2665/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6544 - val_accuracy: 0.7241\n",
      "Epoch 2666/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2667/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 2668/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2669/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6527 - val_accuracy: 0.7241\n",
      "Epoch 2670/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2671/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2672/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2673/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6545 - val_accuracy: 0.7241\n",
      "Epoch 2674/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 2675/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 2676/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2677/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6553 - val_accuracy: 0.7241\n",
      "Epoch 2678/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2679/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2680/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2681/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2682/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2683/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2684/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2685/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2686/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2687/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2688/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2689/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2690/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2691/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2692/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2693/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2694/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2695/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2696/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2697/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2698/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2699/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2700/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2701/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2702/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2703/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2704/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 2705/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2706/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 2707/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2708/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6535 - val_accuracy: 0.7241\n",
      "Epoch 2709/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 2710/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2711/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2712/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2713/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 2714/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6507 - val_accuracy: 0.7241\n",
      "Epoch 2715/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6507 - val_accuracy: 0.7241\n",
      "Epoch 2716/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2717/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6505 - val_accuracy: 0.7241\n",
      "Epoch 2718/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 2719/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6507 - val_accuracy: 0.7241\n",
      "Epoch 2720/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6503 - val_accuracy: 0.7241\n",
      "Epoch 2721/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 2722/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6490 - val_accuracy: 0.7241\n",
      "Epoch 2723/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6483 - val_accuracy: 0.7241\n",
      "Epoch 2724/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6479 - val_accuracy: 0.7241\n",
      "Epoch 2725/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6474 - val_accuracy: 0.7241\n",
      "Epoch 2726/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5446 - val_loss: 0.6469 - val_accuracy: 0.7241\n",
      "Epoch 2727/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6474 - val_accuracy: 0.7241\n",
      "Epoch 2728/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5446 - val_loss: 0.6481 - val_accuracy: 0.7241\n",
      "Epoch 2729/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 2730/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6503 - val_accuracy: 0.7241\n",
      "Epoch 2731/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6515 - val_accuracy: 0.7241\n",
      "Epoch 2732/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6520 - val_accuracy: 0.7241\n",
      "Epoch 2733/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 2734/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 2735/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 2736/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2737/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2738/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 2739/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 2740/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2741/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2742/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2743/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 2744/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2745/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2746/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2747/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2748/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2749/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2750/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2751/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2752/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2753/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2754/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2755/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2756/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2757/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2758/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 2759/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2760/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2761/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2762/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2763/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2764/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2765/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2766/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2767/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2768/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2769/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 2770/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 2771/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2772/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6619 - val_accuracy: 0.7241\n",
      "Epoch 2773/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2774/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 2775/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 2776/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2777/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2778/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 2779/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6620 - val_accuracy: 0.7241\n",
      "Epoch 2780/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6622 - val_accuracy: 0.7241\n",
      "Epoch 2781/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 2782/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 2783/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 2784/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 2785/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6627 - val_accuracy: 0.7241\n",
      "Epoch 2786/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6621 - val_accuracy: 0.7241\n",
      "Epoch 2787/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6617 - val_accuracy: 0.7241\n",
      "Epoch 2788/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2789/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2790/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2791/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2792/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2793/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2794/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2795/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2796/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2797/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2798/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2799/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2800/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2801/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2802/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2803/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2804/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2805/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 2806/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2807/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2808/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2809/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2810/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2811/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2812/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6573 - val_accuracy: 0.7241\n",
      "Epoch 2813/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2814/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2815/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2816/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2817/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2818/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2819/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2820/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2821/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2822/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2823/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2824/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2825/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2826/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2827/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2828/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2829/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2830/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6610 - val_accuracy: 0.7241\n",
      "Epoch 2831/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2832/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2833/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2834/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2835/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2836/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2837/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2838/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2839/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2840/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.7241\n",
      "Epoch 2841/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2842/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6578 - val_accuracy: 0.7241\n",
      "Epoch 2843/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2844/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2845/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2846/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2847/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2848/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5446 - val_loss: 0.6561 - val_accuracy: 0.7241\n",
      "Epoch 2849/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2850/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2851/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 2852/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2853/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2854/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2855/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2856/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2857/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2858/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2859/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6595 - val_accuracy: 0.7241\n",
      "Epoch 2860/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2861/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2862/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6596 - val_accuracy: 0.7241\n",
      "Epoch 2863/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2864/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 2865/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 2866/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 2867/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6599 - val_accuracy: 0.7241\n",
      "Epoch 2868/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2869/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2870/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2871/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2872/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2873/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2874/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6547 - val_accuracy: 0.7241\n",
      "Epoch 2875/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2876/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 2877/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6529 - val_accuracy: 0.7241\n",
      "Epoch 2878/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6532 - val_accuracy: 0.7241\n",
      "Epoch 2879/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6538 - val_accuracy: 0.7241\n",
      "Epoch 2880/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2881/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2882/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 2883/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2884/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6556 - val_accuracy: 0.7241\n",
      "Epoch 2885/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6890 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2886/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6586 - val_accuracy: 0.7241\n",
      "Epoch 2887/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2888/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2889/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 2890/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2891/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2892/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2893/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2894/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2895/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2896/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 2897/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 2898/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6614 - val_accuracy: 0.7241\n",
      "Epoch 2899/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 2900/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 2901/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6611 - val_accuracy: 0.7241\n",
      "Epoch 2902/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6612 - val_accuracy: 0.7241\n",
      "Epoch 2903/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 2904/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2905/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2906/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2907/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2908/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 2909/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2910/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 2911/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6609 - val_accuracy: 0.7241\n",
      "Epoch 2912/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6598 - val_accuracy: 0.7241\n",
      "Epoch 2913/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2914/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 2915/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2916/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2917/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2918/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2919/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2920/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6594 - val_accuracy: 0.7241\n",
      "Epoch 2921/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2922/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 2923/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 2924/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2925/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6574 - val_accuracy: 0.7241\n",
      "Epoch 2926/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 2927/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2928/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2929/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6572 - val_accuracy: 0.7241\n",
      "Epoch 2930/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6567 - val_accuracy: 0.7241\n",
      "Epoch 2931/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6557 - val_accuracy: 0.7241\n",
      "Epoch 2932/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2933/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2934/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6558 - val_accuracy: 0.7241\n",
      "Epoch 2935/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6552 - val_accuracy: 0.7241\n",
      "Epoch 2936/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2937/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 2938/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2939/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2940/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6559 - val_accuracy: 0.7241\n",
      "Epoch 2941/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2942/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2943/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6566 - val_accuracy: 0.7241\n",
      "Epoch 2944/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6565 - val_accuracy: 0.7241\n",
      "Epoch 2945/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2946/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2947/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2948/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2949/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6593 - val_accuracy: 0.7241\n",
      "Epoch 2950/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2951/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2952/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2953/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2954/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6604 - val_accuracy: 0.7241\n",
      "Epoch 2955/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6606 - val_accuracy: 0.7241\n",
      "Epoch 2956/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2957/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 2958/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6576 - val_accuracy: 0.7241\n",
      "Epoch 2959/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2960/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2961/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2962/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6585 - val_accuracy: 0.7241\n",
      "Epoch 2963/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2964/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 2965/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2966/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6589 - val_accuracy: 0.7241\n",
      "Epoch 2967/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6580 - val_accuracy: 0.7241\n",
      "Epoch 2968/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2969/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 2970/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6575 - val_accuracy: 0.7241\n",
      "Epoch 2971/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6579 - val_accuracy: 0.7241\n",
      "Epoch 2972/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2973/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2974/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 2975/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6597 - val_accuracy: 0.7241\n",
      "Epoch 2976/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 2977/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2978/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 2979/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6577 - val_accuracy: 0.7241\n",
      "Epoch 2980/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2981/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2982/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6554 - val_accuracy: 0.7241\n",
      "Epoch 2983/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2984/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6546 - val_accuracy: 0.7241\n",
      "Epoch 2985/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 2986/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6540 - val_accuracy: 0.7241\n",
      "Epoch 2987/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6536 - val_accuracy: 0.7241\n",
      "Epoch 2988/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6549 - val_accuracy: 0.7241\n",
      "Epoch 2989/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6542 - val_accuracy: 0.7241\n",
      "Epoch 2990/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2991/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5446 - val_loss: 0.6539 - val_accuracy: 0.7241\n",
      "Epoch 2992/3000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6543 - val_accuracy: 0.7241\n",
      "Epoch 2993/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6891 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 2994/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2995/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6562 - val_accuracy: 0.7241\n",
      "Epoch 2996/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6569 - val_accuracy: 0.7241\n",
      "Epoch 2997/3000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 2998/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6893 - accuracy: 0.5446 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 2999/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 3000/3000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.6892 - accuracy: 0.5446 - val_loss: 0.6564 - val_accuracy: 0.7241\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "classification_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = classification_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3000,\n",
    "    validation_data=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test dataset\n",
    "\n",
    "# Select 5 control and 5 schizophrenia IDs for the test set\n",
    "control_test_ids = ['A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663']  \n",
    "schizophrenia_test_ids = ['A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186'] \n",
    "\n",
    "# Load and preprocess the images\n",
    "test_image_data = []\n",
    "test_labels = []\n",
    "\n",
    "# Combine all test IDs\n",
    "test_ids = control_test_ids + schizophrenia_test_ids\n",
    "\n",
    "# Loop through the matching files and filter based on test IDs\n",
    "for file_path in matching_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_id = filename.split('_')[0]\n",
    "\n",
    "    # Process only if the ID is in the test set\n",
    "    if file_id in test_ids:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        # Ensure sufficient time dimension\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "\n",
    "        # Collapse one of the axes by summing\n",
    "        t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "\n",
    "        # Resize, normalize, and add dimension as done in the training data preparation\n",
    "        processed_image = resize_image(t1_data_collapsed, (84, 84, 72))\n",
    "        processed_image_normalized = (processed_image - np.min(processed_image)) / (np.max(processed_image) - np.min(processed_image)) * 2 - 1\n",
    "        processed_image_final = np.expand_dims(processed_image_normalized, axis=-1)\n",
    "\n",
    "        test_image_data.append(processed_image_final)\n",
    "        label = 1 if file_id in schizophrenia_test_ids else 0\n",
    "        test_labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "test_images_array = np.array(test_image_data)\n",
    "test_labels_array = np.array(test_labels)\n",
    "\n",
    "# Create a dummy array for the label input for the test dataset\n",
    "dummy_label_input_test = np.zeros((test_images_array.shape[0], 1))\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images_array, dummy_label_input_test, test_labels_array)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "Test Loss: 0.684270441532135, Test Accuracy: 0.5714285969734192\n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics\n",
    "test_loss = 0\n",
    "test_accuracy = 0\n",
    "num_batches = 0\n",
    "\n",
    "# Manually iterate over the test dataset\n",
    "for batch in test_dataset:\n",
    "    images, dummy_labels, labels = batch\n",
    "\n",
    "    # Ensure that we're sending two separate inputs (images and dummy labels)\n",
    "    predictions = classification_model.predict([images, dummy_labels])\n",
    "\n",
    "    # Calculate loss for the batch\n",
    "    loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n",
    "    test_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Round predictions and cast to integer to match the label's type\n",
    "    predicted_labels = tf.cast(tf.round(predictions), dtype=labels.dtype)\n",
    "\n",
    "    # Calculate accuracy for the batch\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(labels, predicted_labels), dtype=tf.float32))\n",
    "    test_accuracy += accuracy.numpy()\n",
    "\n",
    "    num_batches += 1\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "test_loss /= num_batches\n",
    "test_accuracy /= num_batches\n",
    "\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
