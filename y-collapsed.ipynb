{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN version v3 training + testing all in one file\n",
    "\n",
    "## only schizophrenia, but pick only 50 random for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 01:04:04.152576: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 01:04:04.188853: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 01:04:04.188884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 01:04:04.189864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 01:04:04.196963: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 01:04:04.979951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices of type 'GPU'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f'Number of GPUs available: {len(gpus)}')\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f'GPU {i}: {gpu}')\n",
    "else:\n",
    "    print('No GPU detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2220a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full list of all schizophrenia IDs from csv, 86 in total but not all satisfy have t>90\n",
    "\n",
    "full_schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "# schizohrenia_id that satisfy t>90, 59 in total\n",
    "'''met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "    'A00006754', 'A00009280', 'A00012767', 'A00013216', 'A00014607', 'A00014719', 'A00014804',\n",
    "    'A00014830', 'A00015201', 'A00015648', 'A00016197', 'A00016720', 'A00016723', 'A00017147',\n",
    "    'A00018317', 'A00018403', 'A00018434', 'A00018979', 'A00019293', 'A00020414', 'A00020602', \n",
    "    'A00020787', 'A00021591', 'A00021598', 'A00023158', 'A00023246', 'A00023590', 'A00023750', \n",
    "    'A00024198', 'A00024228', 'A00024568', 'A00024684', 'A00024953', 'A00024959', 'A00027410', \n",
    "    'A00027537', 'A00028303', 'A00028404', 'A00028408', 'A00028805', 'A00028806', 'A00031186', \n",
    "    'A00031597', 'A00034273', 'A00035003', 'A00035485', 'A00037034', 'A00037224', 'A00037619', \n",
    "    'A00037649', 'A00038441', 'A00038624'] '''\n",
    "\n",
    "met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "   ]\n",
    "\n",
    "full_control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "]\n",
    "\n",
    "'''met_requirement_control_ids = [\n",
    "    'A00000300', 'A00002198', 'A00003150', 'A00004087', 'A00007409', 'A00010684', 'A00011265', 'A00011725',\n",
    "    'A00012995', 'A00013140', 'A00013816', 'A00014839', 'A00014898', 'A00015759', 'A00015826', 'A00018553',\n",
    "    'A00018716', 'A00019888', 'A00020805', 'A00020895', 'A00020968', 'A00020984', 'A00021058', 'A00021072',\n",
    "    'A00021081', 'A00021085', 'A00022400', 'A00022490', 'A00022509', 'A00022592', 'A00022619', 'A00022653',\n",
    "    'A00022687', 'A00022727', 'A00022729', 'A00022773', 'A00022810', 'A00022835', 'A00022837', 'A00022915',\n",
    "    'A00023095', 'A00023120', 'A00023131', 'A00023143', 'A00023330', 'A00023337', 'A00023730', 'A00023800',\n",
    "    'A00023848', 'A00023866', 'A00024160', 'A00024301', 'A00024372', 'A00024446', 'A00024535', 'A00024546', \n",
    "    'A00024663', 'A00024820', 'A00024932', 'A00024955', 'A00025969', 'A00026945', 'A00027487', 'A00027787', \n",
    "    'A00028052', 'A00028406', 'A00028409', 'A00029226', 'A00029452', 'A00031478', 'A00031764', 'A00033214', \n",
    "    'A00035751', 'A00036049', 'A00036555', 'A00036844', 'A00037007', 'A00037238', 'A00037318', 'A00037495', \n",
    "    'A00037564', 'A00037665'\n",
    "]'''\n",
    "\n",
    "met_requirement_control_ids = [\n",
    "    'A00000300', 'A00002198', 'A00003150', 'A00004087', 'A00007409', 'A00010684', 'A00011265', 'A00011725',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0daa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_generator(z_dim):\n",
    "    # Noise input\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Generator network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Start with a Dense layer to an initial shape that's smaller than the final target\n",
    "    model.add(Dense(128 * 7 * 7 * 9, input_dim=z_dim))  # Adjust to match an initial volume\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Reshape((7, 7, 9, 128)))  # This is the initial volume\n",
    "    \n",
    "    # Begin upsampling to the desired size\n",
    "    model.add(Conv3DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Continue upsampling\n",
    "    model.add(Conv3DTranspose(32, kernel_size=3, strides=(3, 3, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Final upsampling step to reach just under the target size\n",
    "    model.add(Conv3DTranspose(1, kernel_size=3, strides=(2, 2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    # Output tensor\n",
    "    output = model(z_input)\n",
    "\n",
    "    return Model(z_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "222b1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_critic(img_shape):\n",
    "    # Image input\n",
    "    img_input = Input(shape=img_shape)\n",
    "\n",
    "    # Critic network\n",
    "    x = Conv3D(64, kernel_size=3, strides=2, padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "    x = Conv3D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    # Output a score for realness (no sigmoid activation)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    return Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97746e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_images, fake_images, critic):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "    # Alpha for interpolation - shape: (batch_size, 1, 1, 1, 1)\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0., 1.)\n",
    "\n",
    "    # Interpolated images - shape: (batch_size, 84, 84, 72, 1)\n",
    "    interpolated_images = (real_images * alpha) + (fake_images * (1 - alpha))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        # Critic now only takes the images as input\n",
    "        predictions = critic(interpolated_images, training=True)\n",
    "\n",
    "    # Calculate the gradients with respect to the interpolated images\n",
    "    gradients = tape.gradient(predictions, [interpolated_images])[0]\n",
    "\n",
    "    # Compute the norm of the gradients - reduce over all dimensions except the batch dimension\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3, 4]))\n",
    "\n",
    "    # Penalize the gradient norm deviation from 1\n",
    "    gp = tf.reduce_mean((gradients_norm - 1.) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d228f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0]/image.shape[0],\n",
    "        new_shape[1]/image.shape[1],\n",
    "        new_shape[2]/image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5858de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_gp(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer):\n",
    "    # Lists to keep track of losses\n",
    "    critic_losses = []\n",
    "    generator_losses = []\n",
    "\n",
    "    # Directory for saving checkpoints\n",
    "    checkpoint_dir = \"wgan_gp_checkpoints\"\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_critic_loss = 0.0\n",
    "        epoch_generator_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in dataset:\n",
    "            # Assuming dataset yields only images\n",
    "            real_imgs = batch[0]\n",
    "\n",
    "            num_batches += 1\n",
    "            batch_size = real_imgs.shape[0]\n",
    "\n",
    "            # Resize real images to match the expected dimensions of the critic\n",
    "            real_imgs_resized = np.array([resize_image(img, (84, 84, 72)) for img in real_imgs])\n",
    "            real_imgs_resized = np.expand_dims(real_imgs_resized, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Train the critic\n",
    "            for _ in range(5):  # Critic is often trained more frequently\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generate fake images\n",
    "                    z = tf.random.normal([batch_size, z_dim])\n",
    "                    fake_imgs = generator(z, training=True)\n",
    "\n",
    "                    # Get critic scores for real and fake images\n",
    "                    real_output = critic(real_imgs_resized, training=True)\n",
    "                    fake_output = critic(fake_imgs, training=True)\n",
    "\n",
    "                    # Calculate critic loss\n",
    "                    critic_cost = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "                    gp = gradient_penalty(real_imgs_resized, fake_imgs, critic)\n",
    "                    critic_loss = critic_cost + lambda_gp * gp\n",
    "\n",
    "                # Update critic weights\n",
    "                critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "                critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "                epoch_critic_loss += critic_loss\n",
    "\n",
    "            # Train the generator\n",
    "            z = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_imgs = generator(z, training=True)\n",
    "                fake_output = critic(fake_imgs, training=True)\n",
    "                generator_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "            # Update generator weights\n",
    "            generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "            epoch_generator_loss += generator_loss\n",
    "\n",
    "            # print the losses for each batch\n",
    "            print(f'Epoch: {epoch}, Batch: {num_batches}, Critic Loss: {critic_loss}, Generator Loss: {generator_loss}')\n",
    "\n",
    "        # Checkpointing every n epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            generator.save_weights(os.path.join(checkpoint_dir, f\"generator_epoch_{epoch+1}.h5\"))\n",
    "            critic.save_weights(os.path.join(checkpoint_dir, f\"critic_epoch_{epoch+1}.h5\"))\n",
    "            print(f\"Checkpoint: Saved model weights at epoch {epoch+1}\")\n",
    "            \n",
    "        # Record the average losses for this epoch\n",
    "        critic_losses.append(epoch_critic_loss / num_batches)\n",
    "        generator_losses.append(epoch_generator_loss / num_batches)\n",
    "\n",
    "    return critic_losses, generator_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc05a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266d0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files successfully processed: 5\n",
      "Total number of schizophrenia files: 5\n",
      "Schizophrenia files: ['A00000456_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001452_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001251_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00004507_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000838_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n",
      "Epoch: 0, Batch: 1, Critic Loss: -20.439830780029297, Generator Loss: -0.33459481596946716\n",
      "Epoch: 1, Batch: 1, Critic Loss: -120.14432525634766, Generator Loss: -1.4736920595169067\n",
      "Checkpoint: Saved model weights at epoch 2\n",
      "Epoch: 2, Batch: 1, Critic Loss: -242.5237274169922, Generator Loss: -2.842027187347412\n",
      "Epoch: 3, Batch: 1, Critic Loss: -321.0494384765625, Generator Loss: -3.6108181476593018\n",
      "Checkpoint: Saved model weights at epoch 4\n",
      "Epoch: 4, Batch: 1, Critic Loss: -363.6291198730469, Generator Loss: -4.629116535186768\n",
      "Epoch: 5, Batch: 1, Critic Loss: -377.0566711425781, Generator Loss: -6.6499834060668945\n",
      "Checkpoint: Saved model weights at epoch 6\n",
      "Epoch: 6, Batch: 1, Critic Loss: -387.0450439453125, Generator Loss: -7.320067405700684\n",
      "Epoch: 7, Batch: 1, Critic Loss: -394.36956787109375, Generator Loss: -7.768134117126465\n",
      "Checkpoint: Saved model weights at epoch 8\n",
      "Epoch: 8, Batch: 1, Critic Loss: -398.02484130859375, Generator Loss: -7.776984214782715\n",
      "Epoch: 9, Batch: 1, Critic Loss: -396.7515869140625, Generator Loss: -6.206465721130371\n",
      "Checkpoint: Saved model weights at epoch 10\n",
      "Epoch 1/14\n",
      "1/1 [==============================] - 0s 386ms/step - loss: 70.0398 - accuracy: 0.0000e+00 - val_loss: 52.4135 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 115.1478 - accuracy: 0.2500 - val_loss: 46.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 83.2005 - accuracy: 0.0000e+00 - val_loss: 40.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 68.4824 - accuracy: 0.2500 - val_loss: 34.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 39.8988 - accuracy: 0.2500 - val_loss: 28.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 69.1876 - accuracy: 0.5000 - val_loss: 22.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/14\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.8773 - accuracy: 0.5000 - val_loss: 17.3698 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 105.0049 - accuracy: 0.5000 - val_loss: 11.8584 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/14\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 58.5033 - accuracy: 0.2500 - val_loss: 6.2471 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.7112 - accuracy: 0.5000 - val_loss: 1.1636 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 25.5750 - accuracy: 0.5000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 12/14\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.6232 - accuracy: 0.7500 - val_loss: 7.7678e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 56.9284 - accuracy: 0.0000e+00 - val_loss: 3.9924e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/14\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 19.5788 - accuracy: 0.2500 - val_loss: 1.7334e-09 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Test Loss: 10.99232006072998, Test Accuracy: 0.20000000298023224\n",
      "Actual labels vs. Predicted labels:\n",
      "Image 1: Actual: 0, Predicted: 1\n",
      "Image 2: Actual: 0, Predicted: 1\n",
      "Image 3: Actual: 1, Predicted: 1\n",
      "Image 4: Actual: 1, Predicted: 1\n",
      "Image 5: Actual: 0, Predicted: 1\n",
      "Image 6: Actual: 0, Predicted: 1\n",
      "Image 7: Actual: 0, Predicted: 1\n",
      "Image 8: Actual: 0, Predicted: 1\n",
      "Image 9: Actual: 0, Predicted: 1\n",
      "Image 10: Actual: 0, Predicted: 1\n",
      "\n",
      "Average Test Loss over 1 iterations: 10.99232006072998\n",
      "Average Test Accuracy over 1 iterations: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = 0\n",
    "total_loss = 0\n",
    "num_iterations = 1\n",
    "\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    ''' Choosing random training samples and store remaining 9 test'''\n",
    "    train_ids = random.sample(met_requirement_schizophrenia_ids, 5)\n",
    "    test_ids = [id for id in met_requirement_schizophrenia_ids if id not in train_ids]\n",
    "\n",
    "    ''' File loading '''\n",
    "    # Specify the directory and file pattern\n",
    "    directory_path = '../4D'\n",
    "    file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "    # Construct the full path pattern\n",
    "    path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "    # Use glob to find all matching files\n",
    "    matching_files = glob.glob(path_pattern)\n",
    "\n",
    "    # Initialize lists to store the processed image data, corresponding labels, and filenames\n",
    "    image_data = []\n",
    "    labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "    schizophrenia_files = []\n",
    "\n",
    "    # Lists for files with insufficient time dimensions\n",
    "    insufficient_time_files = []\n",
    "    insufficient_time_ids = []\n",
    "\n",
    "    # Counters for each category\n",
    "    schizophrenia_count = 0\n",
    "    processed_files_count = 0\n",
    "\n",
    "    # Loop through the matching files\n",
    "    for file_path in matching_files:\n",
    "        # Extract the filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Extract the ID from the filename\n",
    "        file_id = filename.split('_')[0]\n",
    "        \n",
    "        # Load the file\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        # Check if the time dimension is at least 90\n",
    "        if t1_data.shape[3] < 90:\n",
    "            insufficient_time_files.append(filename)\n",
    "            insufficient_time_ids.append(file_id)\n",
    "            continue  # Skip this file\n",
    "\n",
    "        # Determine the label based on the ID and increment counters\n",
    "        if file_id in train_ids:\n",
    "            label = 1  # Schizophrenia\n",
    "            schizophrenia_count += 1\n",
    "            schizophrenia_files.append(filename)\n",
    "        else:\n",
    "            continue  # Skip files with IDs not in the provided lists\n",
    "        \n",
    "        # Collapse one of the axes by summing\n",
    "        t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "        \n",
    "        # Append the collapsed image data and label to the respective lists\n",
    "        image_data.append(t1_data_collapsed)\n",
    "        labels.append(label)\n",
    "\n",
    "        # Increment the counter\n",
    "        processed_files_count += 1\n",
    "\n",
    "    # Print the total number of files processed for each category and their filenames\n",
    "    print(f\"Total number of files successfully processed: {processed_files_count}\")\n",
    "    print(f\"Total number of schizophrenia files: {schizophrenia_count}\")\n",
    "    print(\"Schizophrenia files:\", schizophrenia_files)\n",
    "\n",
    "    '''Determine the maximum z-dimension size '''\n",
    "    max_z_size = max(img.shape[2] for img in image_data)\n",
    "\n",
    "    ''' normalization '''\n",
    "    image_data_normalized = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in image_data]\n",
    "\n",
    "    ''' padding of images data '''\n",
    "    # Pad each image to have a consistent z-dimension size\n",
    "    padded_data = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized]\n",
    "\n",
    "    # Now convert the padded data list to a numpy array\n",
    "    padded_data_array = np.array(padded_data)\n",
    "\n",
    "    ''' loading the data for training '''\n",
    "    train_images = padded_data_array\n",
    "    # Define batch size\n",
    "    batch_size = 10\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, labels)).shuffle(len(train_images)).batch(batch_size)\n",
    "\n",
    "    \n",
    "    ''' setting up parameters'''\n",
    "    # Image shape and other parameters\n",
    "    img_shape = (84, 84, 72, 1)\n",
    "    z_dim = 100\n",
    "\n",
    "    # Create the generator and critic\n",
    "    generator = build_wgan_generator(z_dim)\n",
    "    critic = build_wgan_critic(img_shape)\n",
    "\n",
    "    critic_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "    generator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    epochs = 10\n",
    "    lambda_gp = 10  # Gradient penalty coefficient\n",
    "\n",
    "    '''Train the WGAN-GP '''\n",
    "\n",
    "    critic_losses, generator_losses = train_wgan_gp(\n",
    "        generator, \n",
    "        critic, \n",
    "        train_dataset, \n",
    "        epochs, \n",
    "        z_dim,\n",
    "        lambda_gp, \n",
    "        critic_optimizer, \n",
    "        generator_optimizer\n",
    "    )\n",
    "    \n",
    "    ''' after training, retrieve the weights of the critic'''\n",
    "\n",
    "    checkpoint_dir = '/wgan_gp_checkpoints'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                    discriminator_optimizer=critic_optimizer,\n",
    "                                    generator=generator,\n",
    "                                    discriminator=critic)\n",
    "    \n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    ''' transfer learning '''\n",
    "    \n",
    "    ''' adding classification layers'''\n",
    "    new_model = Sequential()\n",
    "    for i in range(len(critic.layers)-1):  # Excluding the last layer\n",
    "        layer = critic.layers[i]\n",
    "        layer.trainable = False  # Freeze the layer\n",
    "        new_model.add(layer)\n",
    "\n",
    "    # Adding additional layers\n",
    "    new_model.add(Dropout(0.3))\n",
    "    new_model.add(Dense(1, activation='sigmoid', name = 'dense_6'))  # Sigmoid for binary classification\n",
    "\n",
    "    ''' Prepare data before training the classifer model '''\n",
    "    # Resize each image in the padded data array\n",
    "    resized_images = [resize_image(img, (84, 84, 72)) for img in padded_data]\n",
    "\n",
    "    # Convert the resized data to a numpy array\n",
    "    resized_images_array = np.array(resized_images)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 10\n",
    "\n",
    "    # labels array corresponding to the images\n",
    "    labels_array = np.array(labels)\n",
    "    \n",
    "    ''' train classifier normally like in transfer-learning v2'''\n",
    "    # Split the data into training and evaluation sets (80% train, 20% eval)\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(resized_images_array, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert to TensorFlow datasets with labels\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "    eval_dataset = tf.data.Dataset.from_tensor_slices((X_eval, y_eval)).batch(batch_size)\n",
    "\n",
    "    # Compile the model (if using a new instance of the model for each fold)\n",
    "    new_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = new_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=14,\n",
    "        validation_data=eval_dataset\n",
    "    )\n",
    "\n",
    "    ''' make test set'''\n",
    "    schizophrenia_test_ids = test_ids\n",
    "    control_test_ids = random.sample(met_requirement_control_ids, 8)\n",
    "\n",
    "    ''' load test images to make test set'''\n",
    "    # Now proceed with loading and preprocessing the images for these IDs\n",
    "    test_image_data = []\n",
    "    test_labels = []\n",
    "    # Load and preprocess the images\n",
    "    test_image_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Combine all test IDs\n",
    "    test_ids = control_test_ids + schizophrenia_test_ids\n",
    "\n",
    "    # Loop through the matching files and filter based on test IDs\n",
    "    for file_path in matching_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        file_id = filename.split('_')[0]\n",
    "\n",
    "        # Process only if the ID is in the test set\n",
    "        if file_id in test_ids:\n",
    "            t1_img = nib.load(file_path)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "\n",
    "            # Ensure sufficient time dimension\n",
    "            if t1_data.shape[3] < 90:\n",
    "                continue\n",
    "\n",
    "            # Collapse one of the axes by summing\n",
    "            t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "\n",
    "            # Resize, normalize, and add dimension as done in the training data preparation\n",
    "            processed_image = resize_image(t1_data_collapsed, (84, 84, 72))\n",
    "            processed_image_normalized = (processed_image - np.min(processed_image)) / (np.max(processed_image) - np.min(processed_image)) * 2 - 1\n",
    "            processed_image_final = np.expand_dims(processed_image_normalized, axis=-1)\n",
    "\n",
    "            test_image_data.append(processed_image_final)\n",
    "            label = 1 if file_id in schizophrenia_test_ids else 0\n",
    "            test_labels.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    test_images_array = np.array(test_image_data)\n",
    "    test_labels_array = np.array(test_labels)\n",
    "\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images_array, test_labels_array)).batch(batch_size)\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    num_batches = 0\n",
    "    actual_labels = []\n",
    "    predicted_labels_list = []\n",
    "    # Manually iterate over the test dataset\n",
    "    for images, labels in test_dataset:\n",
    "        # Make predictions\n",
    "        predictions = new_model.predict(images)\n",
    "\n",
    "        # Calculate loss for the batch\n",
    "        loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n",
    "        test_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "        # Process predictions\n",
    "        predicted_labels_batch = tf.cast(tf.round(predictions), dtype=tf.int64)\n",
    "        predicted_labels_list.extend(predicted_labels_batch.numpy().flatten())\n",
    "        actual_labels.extend(labels.numpy().flatten())\n",
    "\n",
    "        # Calculate accuracy for the batch\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(labels, predicted_labels_batch), dtype=tf.float32))\n",
    "        test_accuracy += accuracy.numpy()\n",
    "\n",
    "        num_batches += 1\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    total_loss += test_loss\n",
    "    total_accuracy += test_accuracy\n",
    "    \n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "    print(\"Actual labels vs. Predicted labels:\")\n",
    "    for i in range(len(actual_labels)):\n",
    "        print(f\"Image {i+1}: Actual: {actual_labels[i]}, Predicted: {predicted_labels_list[i]}\")\n",
    "\n",
    "# Calculate and print the average loss and accuracy over all iterations\n",
    "average_test_loss = total_loss / num_iterations\n",
    "average_test_accuracy = total_accuracy / num_iterations\n",
    "print(f\"\\nAverage Test Loss over {num_iterations} iterations: {average_test_loss}\")\n",
    "print(f\"Average Test Accuracy over {num_iterations} iterations: {average_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Generate a single fake image\n",
    "z = np.random.normal(0, 1, (1, z_dim))\n",
    "generated_image = generator.predict(z)[0]  # [0] to get the single image from the batch\n",
    "\n",
    "# Get a single real image from the dataset\n",
    "real_images = next(iter(train_dataset))[0]  # Assuming the dataset yields only images\n",
    "\n",
    "# Take the first real image from the batch for comparison\n",
    "real_image = real_images[0]\n",
    "\n",
    "# Plot the real and fake images side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot real image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(real_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Real Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot fake image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Generated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863005fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.save('wgan_generator_model_v3.h5')\n",
    "#critic.save('wgan_critic_model_v3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
