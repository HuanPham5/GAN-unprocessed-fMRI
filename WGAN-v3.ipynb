{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN version v3\n",
    "\n",
    "## only schizophrenia, but pick only 50 random for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices of type 'GPU'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f'Number of GPUs available: {len(gpus)}')\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f'GPU {i}: {gpu}')\n",
    "else:\n",
    "    print('No GPU detected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0df35",
   "metadata": {},
   "source": [
    "# Matching fMRI files with IDs from demographic csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077ff26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory and file pattern\n",
    "directory_path = '4D'\n",
    "file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "# Construct the full path pattern\n",
    "path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "matching_files = glob.glob(path_pattern)\n",
    "\n",
    "# full list of all schizophrenia IDs from csv, 86 intoal but not all satisfy have t>90\n",
    "\n",
    "full_schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "# schizohrenia_id that satisfy t>90\n",
    "met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "    'A00006754', 'A00009280', 'A00012767', 'A00013216', 'A00014607', 'A00014719', 'A00014804',\n",
    "    'A00014830', 'A00015201', 'A00015648', 'A00016197', 'A00016720', 'A00016723', 'A00017147',\n",
    "    'A00018317', 'A00018403', 'A00018434', 'A00018979', 'A00019293', 'A00020414', 'A00020602', \n",
    "    'A00020787', 'A00021591', 'A00021598', 'A00023158', 'A00023246', 'A00023590', 'A00023750', \n",
    "    'A00024198', 'A00024228', 'A00024568', 'A00024684', 'A00024953', 'A00024959', 'A00027410', \n",
    "    'A00027537', 'A00028303', 'A00028404', 'A00028408', 'A00028805', 'A00028806', 'A00031186', \n",
    "    'A00031597', 'A00034273', 'A00035003', 'A00035485', 'A00037034', 'A00037224', 'A00037619', \n",
    "    'A00037649', 'A00038441', 'A00038624']\n",
    "\n",
    "# Randomly select 50 schizophrenia IDs for training\n",
    "schizophrenia_ids = random.sample(met_requirement_schizophrenia_ids, 50)\n",
    "#schizophrenia_ids = full_schizophrenia_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files successfully processed: 50\n",
      "Total number of schizophrenia files: 50\n",
      "Schizophrenia files: ['A00000368_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000456_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000541_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000838_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001251_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001452_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00004507_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00006754_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00009280_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00012767_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013216_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014607_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014719_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014804_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014830_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015201_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015648_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016197_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016723_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00017147_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018403_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018434_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00019293_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020602_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020787_0017_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021598_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023158_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023246_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023590_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023750_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024198_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024568_0008_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024684_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024953_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024959_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027410_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027537_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028303_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028404_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028408_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028805_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028806_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031186_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031597_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00034273_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035003_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035485_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037034_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037619_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037649_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the processed image data, corresponding labels, and filenames\n",
    "image_data = []\n",
    "labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "schizophrenia_files = []\n",
    "#non_schizophrenia_files = []\n",
    "\n",
    "# Lists for files with insufficient time dimensions\n",
    "insufficient_time_files = []\n",
    "insufficient_time_ids = []\n",
    "\n",
    "# Counters for each category\n",
    "schizophrenia_count = 0\n",
    "#non_schizophrenia_count = 0\n",
    "processed_files_count = 0\n",
    "\n",
    "# Loop through the matching files\n",
    "for file_path in matching_files:\n",
    "    # Extract the filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract the ID from the filename\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    # Load the file\n",
    "    t1_img = nib.load(file_path)\n",
    "    t1_data = t1_img.get_fdata()\n",
    "\n",
    "    # Check if the time dimension is at least 90\n",
    "    if t1_data.shape[3] < 90:\n",
    "        insufficient_time_files.append(filename)\n",
    "        insufficient_time_ids.append(file_id)\n",
    "        continue  # Skip this file\n",
    "\n",
    "    # Determine the label based on the ID and increment counters\n",
    "    if file_id in schizophrenia_ids:\n",
    "        label = 1  # Schizophrenia\n",
    "        schizophrenia_count += 1\n",
    "        schizophrenia_files.append(filename)\n",
    "    else:\n",
    "        continue  # Skip files with IDs not in the provided lists\n",
    "    \n",
    "    # Collapse one of the axes by summing\n",
    "    t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "    \n",
    "    # Append the collapsed image data and label to the respective lists\n",
    "    image_data.append(t1_data_collapsed)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Increment the counter\n",
    "    processed_files_count += 1\n",
    "\n",
    "# Print the total number of files processed for each category and their filenames\n",
    "print(f\"Total number of files successfully processed: {processed_files_count}\")\n",
    "print(f\"Total number of schizophrenia files: {schizophrenia_count}\")\n",
    "print(\"Schizophrenia files:\", schizophrenia_files)\n",
    "#print(f\"Total number of non-schizophrenia files: {non_schizophrenia_count}\")\n",
    "#print(\"Non-Schizophrenia files:\", non_schizophrenia_files)\n",
    "\n",
    "# Print files with insufficient time dimension\n",
    "#print(f\"Total number of files with insufficient time dimension: {len(insufficient_time_files)}\")\n",
    "#print(\"Files with insufficient time dimension:\", insufficient_time_files)\n",
    "#print(\"IDs of files with insufficient time dimension:\", insufficient_time_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e63949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the maximum z-dimension size\n",
    "max_z_size = max(img.shape[2] for img in image_data)\n",
    "max_z_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98267a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_normalized = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in image_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679d20c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7939a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each image to have a consistent z-dimension size\n",
    "padded_data = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized]\n",
    "\n",
    "# Now convert the padded data list to a numpy array\n",
    "padded_data_array = np.array(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596fee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf3cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = padded_data_array\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, labels)).shuffle(len(train_images)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bbda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_generator(z_dim):\n",
    "    # Noise input\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Generator network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Start with a Dense layer to an initial shape that's smaller than the final target\n",
    "    model.add(Dense(128 * 7 * 7 * 9, input_dim=z_dim))  # Adjust to match an initial volume\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Reshape((7, 7, 9, 128)))  # This is the initial volume\n",
    "    \n",
    "    # Begin upsampling to the desired size\n",
    "    model.add(Conv3DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Continue upsampling\n",
    "    model.add(Conv3DTranspose(32, kernel_size=3, strides=(3, 3, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Final upsampling step to reach just under the target size\n",
    "    model.add(Conv3DTranspose(1, kernel_size=3, strides=(2, 2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    # Output tensor\n",
    "    output = model(z_input)\n",
    "\n",
    "    return Model(z_input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac89dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_critic(img_shape):\n",
    "    # Image input\n",
    "    img_input = Input(shape=img_shape)\n",
    "\n",
    "    # Critic network\n",
    "    x = Conv3D(64, kernel_size=3, strides=2, padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "    x = Conv3D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    # Output a score for realness (no sigmoid activation)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    return Model(img_input, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e906057",
   "metadata": {},
   "source": [
    "### GP is calculated by\n",
    "### Interpolating between real and fake images.\n",
    "### Computing the gradient of the critic's scores with respect to this interpolation.\n",
    "### Penalizing the deviation of these gradients from the norm value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a7ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_images, fake_images, critic):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "    # Alpha for interpolation - shape: (batch_size, 1, 1, 1, 1)\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0., 1.)\n",
    "\n",
    "    # Interpolated images - shape: (batch_size, 84, 84, 72, 1)\n",
    "    interpolated_images = (real_images * alpha) + (fake_images * (1 - alpha))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        # Critic now only takes the images as input\n",
    "        predictions = critic(interpolated_images, training=True)\n",
    "\n",
    "    # Calculate the gradients with respect to the interpolated images\n",
    "    gradients = tape.gradient(predictions, [interpolated_images])[0]\n",
    "\n",
    "    # Compute the norm of the gradients - reduce over all dimensions except the batch dimension\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3, 4]))\n",
    "\n",
    "    # Penalize the gradient norm deviation from 1\n",
    "    gp = tf.reduce_mean((gradients_norm - 1.) ** 2)\n",
    "    return gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbecdc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape and other parameters\n",
    "img_shape = (84, 84, 72, 1)\n",
    "z_dim = 100\n",
    "\n",
    "# Create the generator and critic\n",
    "generator = build_wgan_generator(z_dim)\n",
    "critic = build_wgan_critic(img_shape)\n",
    "\n",
    "# RMSprop optimizers, from the paper, but we might try Adam optimizer?\n",
    "\n",
    "#critic_optimizer = RMSprop(learning_rate=0.00005)\n",
    "#generator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "\n",
    "# from paper as well\n",
    "critic_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "generator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "# Note: No need to compile the models with loss functions here\n",
    "# as the loss will be calculated manually during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1b65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0]/image.shape[0],\n",
    "        new_shape[1]/image.shape[1],\n",
    "        new_shape[2]/image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147cc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_gp(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer):\n",
    "    # Lists to keep track of losses\n",
    "    critic_losses = []\n",
    "    generator_losses = []\n",
    "\n",
    "    # Directory for saving checkpoints\n",
    "    checkpoint_dir = \"wgan_gp_checkpoints\"\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_critic_loss = 0.0\n",
    "        epoch_generator_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in dataset:\n",
    "            # Assuming dataset yields only images\n",
    "            real_imgs = batch[0]\n",
    "\n",
    "            num_batches += 1\n",
    "            batch_size = real_imgs.shape[0]\n",
    "\n",
    "            # Resize real images to match the expected dimensions of the critic\n",
    "            real_imgs_resized = np.array([resize_image(img, (84, 84, 72)) for img in real_imgs])\n",
    "            real_imgs_resized = np.expand_dims(real_imgs_resized, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Train the critic\n",
    "            for _ in range(5):  # Critic is often trained more frequently\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generate fake images\n",
    "                    z = tf.random.normal([batch_size, z_dim])\n",
    "                    fake_imgs = generator(z, training=True)\n",
    "\n",
    "                    # Get critic scores for real and fake images\n",
    "                    real_output = critic(real_imgs_resized, training=True)\n",
    "                    fake_output = critic(fake_imgs, training=True)\n",
    "\n",
    "                    # Calculate critic loss\n",
    "                    critic_cost = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "                    gp = gradient_penalty(real_imgs_resized, fake_imgs, critic)\n",
    "                    critic_loss = critic_cost + lambda_gp * gp\n",
    "\n",
    "                # Update critic weights\n",
    "                critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "                critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "                epoch_critic_loss += critic_loss\n",
    "\n",
    "            # Train the generator\n",
    "            z = tf.random.normal([batch_size, z_dim])\n",
    "            misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_imgs = generator(z, training=True)\n",
    "                fake_output = critic(fake_imgs, training=True)\n",
    "                generator_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "            # Update generator weights\n",
    "            generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "            epoch_generator_loss += generator_loss\n",
    "\n",
    "            # print the losses for each batch\n",
    "            print(f'Epoch: {epoch}, Batch: {num_batches}, Critic Loss: {critic_loss}, Generator Loss: {generator_loss}')\n",
    "\n",
    "        # Checkpointing every n epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            generator.save_weights(os.path.join(checkpoint_dir, f\"generator_epoch_{epoch+1}.h5\"))\n",
    "            critic.save_weights(os.path.join(checkpoint_dir, f\"critic_epoch_{epoch+1}.h5\"))\n",
    "            print(f\"Checkpoint: Saved model weights at epoch {epoch+1}\")\n",
    "            \n",
    "        # Record the average losses for this epoch\n",
    "        critic_losses.append(epoch_critic_loss / num_batches)\n",
    "        generator_losses.append(epoch_generator_loss / num_batches)\n",
    "\n",
    "    return critic_losses, generator_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1016064,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m lambda_gp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Gradient penalty coefficient\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the WGAN-GP\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m critic_losses, generator_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_wgan_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritic_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 44\u001b[0m, in \u001b[0;36mtrain_wgan_gp\u001b[1;34m(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer)\u001b[0m\n\u001b[0;32m     41\u001b[0m     critic_loss \u001b[38;5;241m=\u001b[39m critic_cost \u001b[38;5;241m+\u001b[39m lambda_gp \u001b[38;5;241m*\u001b[39m gp\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Update critic weights\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m critic_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcritic_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m critic_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(critic_grads, critic\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m     46\u001b[0m epoch_critic_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m critic_loss\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1737\u001b[0m, in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[0;32m   1736\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(grad, b, transpose_b\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1737\u001b[0m   grad_b \u001b[38;5;241m=\u001b[39m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n\u001b[0;32m   1739\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(grad, b)\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6017\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 6017\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   6019\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1016064,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "z_dim = 100\n",
    "epochs = 10\n",
    "lambda_gp = 10  # Gradient penalty coefficient\n",
    "\n",
    "# Train the WGAN-GP\n",
    "critic_losses, generator_losses = train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_dataset, \n",
    "    epochs, \n",
    "    z_dim,\n",
    "    lambda_gp, \n",
    "    critic_optimizer, \n",
    "    generator_optimizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single fake image\n",
    "z = np.random.normal(0, 1, (1, z_dim))\n",
    "generated_image = generator.predict(z)[0]  # [0] to get the single image from the batch\n",
    "\n",
    "# Get a single real image from the dataset\n",
    "real_images = next(iter(train_dataset))[0]  # Assuming the dataset yields only images\n",
    "\n",
    "# Take the first real image from the batch for comparison\n",
    "real_image = real_images[0]\n",
    "\n",
    "# Plot the real and fake images side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot real image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(real_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Real Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot fake image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Generated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863005fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('wgan_generator_model_v3.h5')\n",
    "critic.save('wgan_critic_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b815ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
