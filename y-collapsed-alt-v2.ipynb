{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN layers transfer of control and schizphrenia into 1 classifier\n",
    "\n",
    "### WGAN version v4 training + testing all in one file\n",
    "\n",
    "### 1 WGAN for schizoprenia and 1 WGAN for control\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices of type 'GPU'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f'Number of GPUs available: {len(gpus)}')\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f'GPU {i}: {gpu}')\n",
    "else:\n",
    "    print('No GPU detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2220a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full list of all schizophrenia IDs from csv, 86 in total but not all satisfy have t>90\n",
    "\n",
    "full_schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "# schizohrenia_id that satisfy t>90, 59 in total\n",
    "met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "    'A00006754', 'A00009280', 'A00012767', 'A00013216', 'A00014607', 'A00014719', 'A00014804',\n",
    "    'A00014830', 'A00015201', 'A00015648', 'A00016197', 'A00016720', 'A00016723', 'A00017147',\n",
    "    'A00018317', 'A00018403', 'A00018434', 'A00018979', 'A00019293', 'A00020414', 'A00020602', \n",
    "    'A00020787', 'A00021591', 'A00021598', 'A00023158', 'A00023246', 'A00023590', 'A00023750', \n",
    "    'A00024198', 'A00024228', 'A00024568', 'A00024684', 'A00024953', 'A00024959', 'A00027410', \n",
    "    'A00027537', 'A00028303', 'A00028404', 'A00028408', 'A00028805', 'A00028806', 'A00031186', \n",
    "    'A00031597', 'A00034273', 'A00035003', 'A00035485', 'A00037034', 'A00037224', 'A00037619', \n",
    "    'A00037649', 'A00038441', 'A00038624']\n",
    "\n",
    "full_control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "]\n",
    "\n",
    " # 82 controls that met requirement\n",
    "met_requirement_control_ids = [\n",
    "    'A00000300', 'A00002198', 'A00003150', 'A00004087', 'A00007409', 'A00010684', 'A00011265', 'A00011725',\n",
    "    'A00012995', 'A00013140', 'A00013816', 'A00014839', 'A00014898', 'A00015759', 'A00015826', 'A00018553',\n",
    "    'A00018716', 'A00019888', 'A00020805', 'A00020895', 'A00020968', 'A00020984', 'A00021058', 'A00021072',\n",
    "    'A00021081', 'A00021085', 'A00022400', 'A00022490', 'A00022509', 'A00022592', 'A00022619', 'A00022653',\n",
    "    'A00022687', 'A00022727', 'A00022729', 'A00022773', 'A00022810', 'A00022835', 'A00022837', 'A00022915',\n",
    "    'A00023095', 'A00023120', 'A00023131', 'A00023143', 'A00023330', 'A00023337', 'A00023730', 'A00023800',\n",
    "    'A00023848', 'A00023866', 'A00024160', 'A00024301', 'A00024372', 'A00024446', 'A00024535', 'A00024546', \n",
    "    'A00024663', 'A00024820', 'A00024932', 'A00024955', 'A00025969', 'A00026945', 'A00027487', 'A00027787', \n",
    "    'A00028052', 'A00028406', 'A00028409', 'A00029226', 'A00029452', 'A00031478', 'A00031764', 'A00033214', \n",
    "    'A00035751', 'A00036049', 'A00036555', 'A00036844', 'A00037007', 'A00037238', 'A00037318', 'A00037495', \n",
    "    'A00037564', 'A00037665'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0daa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_generator(z_dim):\n",
    "    # Noise input\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Generator network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Start with a Dense layer to an initial shape that's smaller than the final target\n",
    "    model.add(Dense(128 * 7 * 7 * 9, input_dim=z_dim))  # Adjust to match an initial volume\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Reshape((7, 7, 9, 128)))  # This is the initial volume\n",
    "    \n",
    "    # Begin upsampling to the desired size\n",
    "    model.add(Conv3DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Continue upsampling\n",
    "    model.add(Conv3DTranspose(32, kernel_size=3, strides=(3, 3, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Final upsampling step to reach just under the target size\n",
    "    model.add(Conv3DTranspose(1, kernel_size=3, strides=(2, 2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    # Output tensor\n",
    "    output = model(z_input)\n",
    "\n",
    "    return Model(z_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "222b1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_critic(img_shape):\n",
    "    # Image input\n",
    "    img_input = Input(shape=img_shape)\n",
    "\n",
    "    # Critic network\n",
    "    x = Conv3D(64, kernel_size=3, strides=2, padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "    x = Conv3D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    # Output a score for realness (no sigmoid activation)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    return Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97746e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_images, fake_images, critic):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "    # Alpha for interpolation - shape: (batch_size, 1, 1, 1, 1)\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0., 1.)\n",
    "\n",
    "    # Interpolated images - shape: (batch_size, 84, 84, 72, 1)\n",
    "    interpolated_images = (real_images * alpha) + (fake_images * (1 - alpha))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        # Critic now only takes the images as input\n",
    "        predictions = critic(interpolated_images, training=True)\n",
    "\n",
    "    # Calculate the gradients with respect to the interpolated images\n",
    "    gradients = tape.gradient(predictions, [interpolated_images])[0]\n",
    "\n",
    "    # Compute the norm of the gradients - reduce over all dimensions except the batch dimension\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3, 4]))\n",
    "\n",
    "    # Penalize the gradient norm deviation from 1\n",
    "    gp = tf.reduce_mean((gradients_norm - 1.) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d228f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0]/image.shape[0],\n",
    "        new_shape[1]/image.shape[1],\n",
    "        new_shape[2]/image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5858de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_gp(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer,type):\n",
    "    # Lists to keep track of losses\n",
    "    critic_losses = []\n",
    "    generator_losses = []\n",
    "\n",
    "    # Directory for saving checkpoints\n",
    "    checkpoint_dir_schiz = \"wgan_gp_checkpoints_schiz\"\n",
    "    checkpoint_dir_control = \"wgan_gp_checkpoints_control\"\n",
    "    if not os.path.exists(checkpoint_dir_schiz):\n",
    "        os.makedirs(checkpoint_dir_schiz)\n",
    "    \n",
    "    if not os.path.exists(checkpoint_dir_control):\n",
    "        os.makedirs(checkpoint_dir_control)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_critic_loss = 0.0\n",
    "        epoch_generator_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for real_imgs in dataset:\n",
    "            \n",
    "            num_batches += 1\n",
    "            # Ensure real_imgs converts to numpy array\n",
    "            real_imgs_numpy = real_imgs.numpy() if isinstance(real_imgs, tf.Tensor) else real_imgs\n",
    "\n",
    "            batch_size = real_imgs_numpy.shape[0]\n",
    "            print(real_imgs.shape)\n",
    "            \n",
    "            # Resize real images to match the expected dimensions of the critic\n",
    "            real_imgs_resized = np.array([resize_image(img, (84, 84, 72)) for img in real_imgs.numpy()])\n",
    "            real_imgs_resized = np.expand_dims(real_imgs_resized, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Train the critic\n",
    "            for _ in range(5):  # Critic is often trained more frequently\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generate fake images\n",
    "                    z = tf.random.normal([batch_size, z_dim])\n",
    "                    fake_imgs = generator(z, training=True)\n",
    "\n",
    "                    # Get critic scores for real and fake images\n",
    "                    real_output = critic(real_imgs_resized, training=True)\n",
    "                    fake_output = critic(fake_imgs, training=True)\n",
    "\n",
    "                    # Calculate critic loss\n",
    "                    critic_cost = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "                    gp = gradient_penalty(real_imgs_resized, fake_imgs, critic)\n",
    "                    critic_loss = critic_cost + lambda_gp * gp\n",
    "\n",
    "                # Update critic weights\n",
    "                critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "                critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "                epoch_critic_loss += critic_loss\n",
    "\n",
    "            # Train the generator\n",
    "            z = tf.random.normal([batch_size, z_dim])\n",
    "            \n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_imgs = generator(z, training=True)\n",
    "                fake_output = critic(fake_imgs, training=True)\n",
    "                generator_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "            # Update generator weights\n",
    "            generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "            epoch_generator_loss += generator_loss\n",
    "\n",
    "            # print the losses for each batch\n",
    "            print(f'Epoch: {epoch}, Batch: {num_batches}, Critic Loss: {critic_loss}, Generator Loss: {generator_loss}')\n",
    "\n",
    "        # Checkpointing every n epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            if type == 0: # 0 is schizophrenic\n",
    "                generator.save_weights(os.path.join(checkpoint_dir_schiz, f\"generator_epoch_{epoch+1}.h5\"))\n",
    "                critic.save_weights(os.path.join(checkpoint_dir_schiz, f\"critic_epoch_{epoch+1}.h5\"))\n",
    "                print(f\"Checkpoint: Saved model weights at epoch {epoch+1}\")\n",
    "            else:\n",
    "                generator.save_weights(os.path.join(checkpoint_dir_control, f\"generator_epoch_{epoch+1}.h5\"))\n",
    "                critic.save_weights(os.path.join(checkpoint_dir_control, f\"critic_epoch_{epoch+1}.h5\"))\n",
    "                print(f\"Checkpoint: Saved model weights at epoch {epoch+1}\")\n",
    "            \n",
    "        # Record the average losses for this epoch\n",
    "        critic_losses.append(epoch_critic_loss / num_batches)\n",
    "        generator_losses.append(epoch_generator_loss / num_batches)\n",
    "\n",
    "    return critic_losses, generator_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc05a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266d0e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GAN training files processed: 10\n",
      "Total classifier training/testing files processed: 141\n",
      "Total labels processed: 141\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 0, Batch: 1, Critic Loss: -19.622882843017578, Generator Loss: -0.2855619490146637\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 1, Batch: 1, Critic Loss: -123.9722671508789, Generator Loss: -1.4005396366119385\n",
      "Checkpoint: Saved model weights at epoch 2\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 2, Batch: 1, Critic Loss: -298.4011535644531, Generator Loss: -6.354146480560303\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 3, Batch: 1, Critic Loss: -421.84771728515625, Generator Loss: -9.927774429321289\n",
      "Checkpoint: Saved model weights at epoch 4\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 4, Batch: 1, Critic Loss: -489.3810729980469, Generator Loss: -10.478137016296387\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 5, Batch: 1, Critic Loss: -530.0557250976562, Generator Loss: -10.108405113220215\n",
      "Checkpoint: Saved model weights at epoch 6\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 6, Batch: 1, Critic Loss: -566.651123046875, Generator Loss: -8.657323837280273\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 7, Batch: 1, Critic Loss: -580.7032470703125, Generator Loss: -7.407375335693359\n",
      "Checkpoint: Saved model weights at epoch 8\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 8, Batch: 1, Critic Loss: -603.6699829101562, Generator Loss: -5.576348781585693\n",
      "(5, 91, 91, 143)\n",
      "Epoch: 9, Batch: 1, Critic Loss: -609.7499389648438, Generator Loss: -2.7998573780059814\n",
      "Checkpoint: Saved model weights at epoch 10\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 0, Batch: 1, Critic Loss: -115.59768676757812, Generator Loss: 18.901479721069336\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 1, Batch: 1, Critic Loss: -134.98870849609375, Generator Loss: 33.359825134277344\n",
      "Checkpoint: Saved model weights at epoch 2\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 2, Batch: 1, Critic Loss: -156.17625427246094, Generator Loss: 23.534374237060547\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 3, Batch: 1, Critic Loss: -156.3775634765625, Generator Loss: 19.28812599182129\n",
      "Checkpoint: Saved model weights at epoch 4\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 4, Batch: 1, Critic Loss: -160.24998474121094, Generator Loss: 16.967647552490234\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 5, Batch: 1, Critic Loss: -162.59356689453125, Generator Loss: 14.123537063598633\n",
      "Checkpoint: Saved model weights at epoch 6\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 6, Batch: 1, Critic Loss: -163.04139709472656, Generator Loss: 12.303632736206055\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 7, Batch: 1, Critic Loss: -160.4272003173828, Generator Loss: 12.591055870056152\n",
      "Checkpoint: Saved model weights at epoch 8\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 8, Batch: 1, Critic Loss: -161.97459411621094, Generator Loss: 12.935086250305176\n",
      "(5, 91, 91, 146)\n",
      "Epoch: 9, Batch: 1, Critic Loss: -163.03231811523438, Generator Loss: 12.317405700683594\n",
      "Checkpoint: Saved model weights at epoch 10\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 36ms/step - loss: 27.0104 - accuracy: 0.5804 - val_loss: 7.4809 - val_accuracy: 0.7241\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 31.8721 - accuracy: 0.5446 - val_loss: 44.8819 - val_accuracy: 0.2759\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 29.9938 - accuracy: 0.4375 - val_loss: 11.8495 - val_accuracy: 0.2759\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 22.7728 - accuracy: 0.3929 - val_loss: 9.7349 - val_accuracy: 0.2759\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 21.2021 - accuracy: 0.4375 - val_loss: 1.1512 - val_accuracy: 0.4138\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 12.5818 - accuracy: 0.5357 - val_loss: 12.3633 - val_accuracy: 0.2759\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 16.4313 - accuracy: 0.4554 - val_loss: 8.2374 - val_accuracy: 0.2759\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 12.6330 - accuracy: 0.4643 - val_loss: 7.6562 - val_accuracy: 0.2759\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 11.7620 - accuracy: 0.5625 - val_loss: 5.5020 - val_accuracy: 0.3103\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.9691 - accuracy: 0.5357 - val_loss: 6.9941 - val_accuracy: 0.3103\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 9.3390 - accuracy: 0.5357 - val_loss: 8.0652 - val_accuracy: 0.2759\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 9.1792 - accuracy: 0.4821 - val_loss: 6.0970 - val_accuracy: 0.3103\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 7.2436 - accuracy: 0.4464 - val_loss: 9.0540 - val_accuracy: 0.2759\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 7.0970 - accuracy: 0.3750 - val_loss: 0.6525 - val_accuracy: 0.6897\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 3.2336 - accuracy: 0.5268 - val_loss: 1.1256 - val_accuracy: 0.7241\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 3.1300 - accuracy: 0.5714 - val_loss: 1.8025 - val_accuracy: 0.3103\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 2.6603 - accuracy: 0.4821 - val_loss: 2.3294 - val_accuracy: 0.2759\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.2882 - accuracy: 0.3929 - val_loss: 0.9429 - val_accuracy: 0.7241\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.4183 - accuracy: 0.5089 - val_loss: 0.6701 - val_accuracy: 0.7241\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.8938 - accuracy: 0.5357 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.8610 - accuracy: 0.4911 - val_loss: 0.8080 - val_accuracy: 0.3103\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.8287 - accuracy: 0.4107 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.7296 - accuracy: 0.5179 - val_loss: 0.6457 - val_accuracy: 0.7241\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.7056 - accuracy: 0.5357 - val_loss: 0.6811 - val_accuracy: 0.6207\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.7090 - accuracy: 0.5000 - val_loss: 0.6608 - val_accuracy: 0.7241\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6963 - accuracy: 0.5714 - val_loss: 0.6541 - val_accuracy: 0.7241\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6923 - accuracy: 0.5089 - val_loss: 0.6613 - val_accuracy: 0.7241\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6771 - accuracy: 0.6071 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.7047 - accuracy: 0.5446 - val_loss: 0.6514 - val_accuracy: 0.7241\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6856 - accuracy: 0.5446 - val_loss: 0.6534 - val_accuracy: 0.7241\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6913 - accuracy: 0.5357 - val_loss: 0.6526 - val_accuracy: 0.7241\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6946 - accuracy: 0.5179 - val_loss: 0.6590 - val_accuracy: 0.7241\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6884 - accuracy: 0.5446 - val_loss: 0.6658 - val_accuracy: 0.7241\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6904 - accuracy: 0.5625 - val_loss: 0.6635 - val_accuracy: 0.7241\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6882 - accuracy: 0.5536 - val_loss: 0.6560 - val_accuracy: 0.7241\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6917 - accuracy: 0.5000 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6878 - accuracy: 0.5179 - val_loss: 0.6602 - val_accuracy: 0.7241\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6945 - accuracy: 0.5000 - val_loss: 0.6713 - val_accuracy: 0.7241\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6884 - accuracy: 0.5089 - val_loss: 0.6710 - val_accuracy: 0.7241\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6945 - accuracy: 0.5268 - val_loss: 0.6626 - val_accuracy: 0.7241\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6906 - accuracy: 0.5179 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6797 - accuracy: 0.5357 - val_loss: 0.6491 - val_accuracy: 0.7241\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6835 - accuracy: 0.5536 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6831 - accuracy: 0.5446 - val_loss: 0.6537 - val_accuracy: 0.7241\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6867 - accuracy: 0.5625 - val_loss: 0.6563 - val_accuracy: 0.7241\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6853 - accuracy: 0.5446 - val_loss: 0.6555 - val_accuracy: 0.7241\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6834 - accuracy: 0.5625 - val_loss: 0.6551 - val_accuracy: 0.7241\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6963 - accuracy: 0.5446 - val_loss: 0.6530 - val_accuracy: 0.7241\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6771 - accuracy: 0.5536 - val_loss: 0.6587 - val_accuracy: 0.7241\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6864 - accuracy: 0.5714 - val_loss: 0.6490 - val_accuracy: 0.7241\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6961 - accuracy: 0.5446 - val_loss: 0.6584 - val_accuracy: 0.7241\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6828 - accuracy: 0.5536 - val_loss: 0.6674 - val_accuracy: 0.7241\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6982 - accuracy: 0.4821 - val_loss: 0.6707 - val_accuracy: 0.7241\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6855 - accuracy: 0.5446 - val_loss: 0.6691 - val_accuracy: 0.7241\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6581 - val_accuracy: 0.7241\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6998 - accuracy: 0.5536 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6856 - accuracy: 0.5446 - val_loss: 0.6600 - val_accuracy: 0.7241\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6949 - accuracy: 0.4911 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6973 - accuracy: 0.4554 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6935 - accuracy: 0.5179 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6914 - accuracy: 0.5089 - val_loss: 0.6640 - val_accuracy: 0.7241\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6929 - accuracy: 0.5268 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6877 - accuracy: 0.5446 - val_loss: 0.6521 - val_accuracy: 0.7241\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.7027 - accuracy: 0.4375 - val_loss: 0.6713 - val_accuracy: 0.7241\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6908 - accuracy: 0.4911 - val_loss: 0.6669 - val_accuracy: 0.7241\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6841 - accuracy: 0.5536 - val_loss: 0.6568 - val_accuracy: 0.7241\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.7136 - accuracy: 0.4732 - val_loss: 0.6624 - val_accuracy: 0.7241\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6854 - accuracy: 0.5625 - val_loss: 0.6730 - val_accuracy: 0.7241\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6893 - accuracy: 0.5893 - val_loss: 0.6651 - val_accuracy: 0.7241\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6981 - accuracy: 0.4732 - val_loss: 0.6564 - val_accuracy: 0.7241\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6908 - accuracy: 0.5536 - val_loss: 0.6607 - val_accuracy: 0.7241\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6881 - accuracy: 0.5268 - val_loss: 0.6641 - val_accuracy: 0.7241\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6915 - accuracy: 0.5000 - val_loss: 0.6682 - val_accuracy: 0.7241\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6913 - accuracy: 0.5714 - val_loss: 0.6663 - val_accuracy: 0.7241\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6924 - accuracy: 0.5625 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6985 - accuracy: 0.5536 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6876 - accuracy: 0.5446 - val_loss: 0.6629 - val_accuracy: 0.7241\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6872 - accuracy: 0.5089 - val_loss: 0.6670 - val_accuracy: 0.7241\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6898 - accuracy: 0.5536 - val_loss: 0.6645 - val_accuracy: 0.7241\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6992 - accuracy: 0.5268 - val_loss: 0.6615 - val_accuracy: 0.7241\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6866 - accuracy: 0.4911 - val_loss: 0.6682 - val_accuracy: 0.7241\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6937 - accuracy: 0.5089 - val_loss: 0.6630 - val_accuracy: 0.7241\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6952 - accuracy: 0.5000 - val_loss: 0.6601 - val_accuracy: 0.7241\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6940 - accuracy: 0.5179 - val_loss: 0.6644 - val_accuracy: 0.7241\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6840 - accuracy: 0.5357 - val_loss: 0.6660 - val_accuracy: 0.7241\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6928 - accuracy: 0.5446 - val_loss: 0.6571 - val_accuracy: 0.7241\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6972 - accuracy: 0.4821 - val_loss: 0.6665 - val_accuracy: 0.7241\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.6917 - accuracy: 0.5357 - val_loss: 0.6674 - val_accuracy: 0.7241\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6899 - accuracy: 0.4911 - val_loss: 0.6748 - val_accuracy: 0.7241\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6933 - accuracy: 0.4821 - val_loss: 0.6713 - val_accuracy: 0.7241\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6915 - accuracy: 0.5268 - val_loss: 0.6605 - val_accuracy: 0.7241\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6961 - accuracy: 0.5446 - val_loss: 0.6583 - val_accuracy: 0.7241\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6882 - accuracy: 0.4821 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6965 - accuracy: 0.5357 - val_loss: 0.6648 - val_accuracy: 0.7241\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.6911 - accuracy: 0.4911 - val_loss: 0.6738 - val_accuracy: 0.7241\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 0.6900 - accuracy: 0.5268 - val_loss: 0.6736 - val_accuracy: 0.7241\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6897 - accuracy: 0.5536 - val_loss: 0.6603 - val_accuracy: 0.7241\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6915 - accuracy: 0.5625 - val_loss: 0.6498 - val_accuracy: 0.7241\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6869 - accuracy: 0.5625 - val_loss: 0.6451 - val_accuracy: 0.7241\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.6874 - accuracy: 0.5714 - val_loss: 0.6450 - val_accuracy: 0.7241\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Current batch size: 10\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Current batch size: 1\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Test Loss: 0.6850600506513174, Test Accuracy: 0.5877862681869332\n",
      "Actual labels vs. Predicted labels:\n",
      "Image 1: Actual: 0, Predicted: 0\n",
      "Image 2: Actual: 0, Predicted: 0\n",
      "Image 3: Actual: 0, Predicted: 0\n",
      "Image 4: Actual: 0, Predicted: 0\n",
      "Image 5: Actual: 0, Predicted: 0\n",
      "Image 6: Actual: 1, Predicted: 0\n",
      "Image 7: Actual: 0, Predicted: 0\n",
      "Image 8: Actual: 0, Predicted: 0\n",
      "Image 9: Actual: 1, Predicted: 0\n",
      "Image 10: Actual: 0, Predicted: 0\n",
      "Image 11: Actual: 0, Predicted: 0\n",
      "Image 12: Actual: 1, Predicted: 0\n",
      "Image 13: Actual: 1, Predicted: 0\n",
      "Image 14: Actual: 0, Predicted: 0\n",
      "Image 15: Actual: 0, Predicted: 0\n",
      "Image 16: Actual: 0, Predicted: 0\n",
      "Image 17: Actual: 0, Predicted: 0\n",
      "Image 18: Actual: 0, Predicted: 0\n",
      "Image 19: Actual: 1, Predicted: 0\n",
      "Image 20: Actual: 1, Predicted: 0\n",
      "Image 21: Actual: 0, Predicted: 0\n",
      "Image 22: Actual: 1, Predicted: 0\n",
      "Image 23: Actual: 0, Predicted: 0\n",
      "Image 24: Actual: 1, Predicted: 0\n",
      "Image 25: Actual: 0, Predicted: 0\n",
      "Image 26: Actual: 1, Predicted: 0\n",
      "Image 27: Actual: 0, Predicted: 0\n",
      "Image 28: Actual: 0, Predicted: 0\n",
      "Image 29: Actual: 1, Predicted: 0\n",
      "Image 30: Actual: 0, Predicted: 0\n",
      "Image 31: Actual: 0, Predicted: 0\n",
      "Image 32: Actual: 1, Predicted: 0\n",
      "Image 33: Actual: 0, Predicted: 0\n",
      "Image 34: Actual: 0, Predicted: 0\n",
      "Image 35: Actual: 1, Predicted: 0\n",
      "Image 36: Actual: 0, Predicted: 0\n",
      "Image 37: Actual: 1, Predicted: 0\n",
      "Image 38: Actual: 0, Predicted: 0\n",
      "Image 39: Actual: 0, Predicted: 0\n",
      "Image 40: Actual: 0, Predicted: 0\n",
      "Image 41: Actual: 0, Predicted: 0\n",
      "Image 42: Actual: 0, Predicted: 0\n",
      "Image 43: Actual: 1, Predicted: 0\n",
      "Image 44: Actual: 0, Predicted: 0\n",
      "Image 45: Actual: 1, Predicted: 0\n",
      "Image 46: Actual: 0, Predicted: 0\n",
      "Image 47: Actual: 1, Predicted: 0\n",
      "Image 48: Actual: 1, Predicted: 0\n",
      "Image 49: Actual: 1, Predicted: 0\n",
      "Image 50: Actual: 1, Predicted: 0\n",
      "Image 51: Actual: 1, Predicted: 0\n",
      "Image 52: Actual: 0, Predicted: 0\n",
      "Image 53: Actual: 1, Predicted: 0\n",
      "Image 54: Actual: 1, Predicted: 0\n",
      "Image 55: Actual: 1, Predicted: 0\n",
      "Image 56: Actual: 1, Predicted: 0\n",
      "Image 57: Actual: 0, Predicted: 0\n",
      "Image 58: Actual: 0, Predicted: 0\n",
      "Image 59: Actual: 1, Predicted: 0\n",
      "Image 60: Actual: 1, Predicted: 0\n",
      "Image 61: Actual: 1, Predicted: 0\n",
      "Image 62: Actual: 0, Predicted: 0\n",
      "Image 63: Actual: 0, Predicted: 0\n",
      "Image 64: Actual: 0, Predicted: 0\n",
      "Image 65: Actual: 1, Predicted: 0\n",
      "Image 66: Actual: 0, Predicted: 0\n",
      "Image 67: Actual: 0, Predicted: 0\n",
      "Image 68: Actual: 0, Predicted: 0\n",
      "Image 69: Actual: 1, Predicted: 0\n",
      "Image 70: Actual: 0, Predicted: 0\n",
      "Image 71: Actual: 0, Predicted: 0\n",
      "Image 72: Actual: 0, Predicted: 0\n",
      "Image 73: Actual: 1, Predicted: 0\n",
      "Image 74: Actual: 0, Predicted: 0\n",
      "Image 75: Actual: 0, Predicted: 0\n",
      "Image 76: Actual: 0, Predicted: 0\n",
      "Image 77: Actual: 0, Predicted: 0\n",
      "Image 78: Actual: 0, Predicted: 0\n",
      "Image 79: Actual: 1, Predicted: 0\n",
      "Image 80: Actual: 0, Predicted: 0\n",
      "Image 81: Actual: 1, Predicted: 0\n",
      "Image 82: Actual: 1, Predicted: 0\n",
      "Image 83: Actual: 1, Predicted: 0\n",
      "Image 84: Actual: 1, Predicted: 0\n",
      "Image 85: Actual: 0, Predicted: 0\n",
      "Image 86: Actual: 0, Predicted: 0\n",
      "Image 87: Actual: 0, Predicted: 0\n",
      "Image 88: Actual: 0, Predicted: 0\n",
      "Image 89: Actual: 0, Predicted: 0\n",
      "Image 90: Actual: 0, Predicted: 0\n",
      "Image 91: Actual: 1, Predicted: 0\n",
      "Image 92: Actual: 0, Predicted: 0\n",
      "Image 93: Actual: 0, Predicted: 0\n",
      "Image 94: Actual: 1, Predicted: 0\n",
      "Image 95: Actual: 1, Predicted: 0\n",
      "Image 96: Actual: 1, Predicted: 0\n",
      "Image 97: Actual: 1, Predicted: 0\n",
      "Image 98: Actual: 0, Predicted: 0\n",
      "Image 99: Actual: 0, Predicted: 0\n",
      "Image 100: Actual: 1, Predicted: 0\n",
      "Image 101: Actual: 1, Predicted: 0\n",
      "Image 102: Actual: 0, Predicted: 0\n",
      "Image 103: Actual: 1, Predicted: 0\n",
      "Image 104: Actual: 0, Predicted: 0\n",
      "Image 105: Actual: 1, Predicted: 0\n",
      "Image 106: Actual: 0, Predicted: 0\n",
      "Image 107: Actual: 0, Predicted: 0\n",
      "Image 108: Actual: 1, Predicted: 0\n",
      "Image 109: Actual: 1, Predicted: 0\n",
      "Image 110: Actual: 1, Predicted: 0\n",
      "Image 111: Actual: 1, Predicted: 0\n",
      "Image 112: Actual: 0, Predicted: 0\n",
      "Image 113: Actual: 0, Predicted: 0\n",
      "Image 114: Actual: 1, Predicted: 0\n",
      "Image 115: Actual: 0, Predicted: 0\n",
      "Image 116: Actual: 0, Predicted: 0\n",
      "Image 117: Actual: 0, Predicted: 0\n",
      "Image 118: Actual: 0, Predicted: 0\n",
      "Image 119: Actual: 0, Predicted: 0\n",
      "Image 120: Actual: 0, Predicted: 0\n",
      "Image 121: Actual: 1, Predicted: 0\n",
      "Image 122: Actual: 0, Predicted: 0\n",
      "Image 123: Actual: 1, Predicted: 0\n",
      "Image 124: Actual: 0, Predicted: 0\n",
      "Image 125: Actual: 1, Predicted: 0\n",
      "Image 126: Actual: 0, Predicted: 0\n",
      "Image 127: Actual: 0, Predicted: 0\n",
      "Image 128: Actual: 1, Predicted: 0\n",
      "Image 129: Actual: 1, Predicted: 0\n",
      "Image 130: Actual: 0, Predicted: 0\n",
      "Image 131: Actual: 0, Predicted: 0\n",
      "\n",
      "Average Test Loss over 1 iterations: 0.6850600506513174\n",
      "Average Test Accuracy over 1 iterations: 0.5877862681869332\n"
     ]
    }
   ],
   "source": [
    "total_accuracy = 0\n",
    "total_loss = 0\n",
    "num_iterations = 1\n",
    "\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    ''' data training for GAN '''\n",
    "    ''' Choosing 50 random schizphrenia samples and store remaining 9 test'''\n",
    "    ''' Since we are training a separate GAN for control, also choose 50 random control samples and store remaining 9 test '''\n",
    "\n",
    "    # GAN Training Data Selection\n",
    "    gan_train_ids_schiz = random.sample(met_requirement_schizophrenia_ids, 5)\n",
    "    gan_test_ids_schiz = [id for id in met_requirement_schizophrenia_ids if id not in gan_train_ids_schiz]\n",
    "\n",
    "    gan_train_ids_control = random.sample(met_requirement_control_ids, 5)\n",
    "    gan_test_ids_control = [id for id in met_requirement_control_ids if id not in gan_train_ids_control]\n",
    "\n",
    "\n",
    "    ''' data training for classifier '''\n",
    "    ''' just use the same train set as GAN above '''\n",
    "\n",
    "    # Classifier Training Data Selection\n",
    "    classifier_train_ids = gan_train_ids_control + gan_train_ids_schiz\n",
    "\n",
    "    # Classifier Test Data Selection\n",
    "    classifier_test_ids = gan_test_ids_schiz + gan_test_ids_control\n",
    "\n",
    "    ''' File loading '''\n",
    "    # Specify the directory and file pattern\n",
    "    directory_path = '../4D/'\n",
    "    file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "    # Construct the full path pattern\n",
    "    path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "    # Use glob to find all matching files\n",
    "    matching_files = glob.glob(path_pattern)\n",
    "\n",
    "    ''' File loading for GAN Training and classifer '''\n",
    "    ''' But this time we have 2 separate GANs, 1 train on schizoprenia and 1 train on control'''\n",
    "    \n",
    "    classifier_image_data = []\n",
    "    classifier_labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "    gan_image_data_schiz = []\n",
    "    gan_image_data_control = []\n",
    "\n",
    "    for file_path in matching_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        file_id = filename.split('_')[0]\n",
    "        \n",
    "        if file_id in gan_train_ids_schiz:\n",
    "            t1_img = nib.load(file_path)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "\n",
    "            if t1_data.shape[3] < 90:\n",
    "                continue\n",
    "\n",
    "            t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "            gan_image_data_schiz.append(t1_data_collapsed)\n",
    "\n",
    "        if file_id in gan_train_ids_control:\n",
    "            t1_img = nib.load(file_path)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "\n",
    "            if t1_data.shape[3] < 90:\n",
    "                continue\n",
    "\n",
    "            t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "            gan_image_data_control.append(t1_data_collapsed)\n",
    "\n",
    "        if file_id in classifier_train_ids or file_id in classifier_test_ids:\n",
    "            t1_img = nib.load(file_path)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "\n",
    "            if t1_data.shape[3] < 90:\n",
    "                continue\n",
    "\n",
    "            label = 1 if file_id in met_requirement_schizophrenia_ids else 0\n",
    "            t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "\n",
    "            classifier_image_data.append(t1_data_collapsed)\n",
    "            classifier_labels.append(label)\n",
    "\n",
    "    print(f\"Total GAN training files processed: {len(gan_image_data_control+gan_image_data_schiz)}\")\n",
    "    print(f\"Total classifier training/testing files processed: {len(classifier_image_data)}\")\n",
    "    print(f\"Total labels processed: {len(classifier_labels)}\")\n",
    "  \n",
    "\n",
    "    '''Determine the maximum z-dimension size '''\n",
    "    max_z_size_schiz = max(img.shape[2] for img in gan_image_data_schiz)\n",
    "    max_z_size_control = max(img.shape[2] for img in gan_image_data_control)\n",
    "    max_z_size_classifier = max(img.shape[2] for img in classifier_image_data)\n",
    "\n",
    "    ''' normalization '''\n",
    "    image_data_normalized_schiz = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in gan_image_data_schiz]\n",
    "    image_data_normalized_control = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in gan_image_data_control]\n",
    "    image_data_normalized_classifier = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in classifier_image_data]\n",
    "\n",
    "    ''' padding of images data '''\n",
    "    # Pad each image to have a consistent z-dimension size\n",
    "    padded_data_schiz = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size_schiz - img.shape[2])), mode='constant') for img in image_data_normalized_schiz]\n",
    "    padded_data_control = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size_control - img.shape[2])), mode='constant') for img in image_data_normalized_control]\n",
    "    padded_data_classifier = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size_classifier - img.shape[2])), mode='constant') for img in image_data_normalized_classifier]\n",
    "    \n",
    "    # Now convert the padded data list to a numpy array\n",
    "    padded_data_array_schiz = np.array(padded_data_schiz)\n",
    "    padded_data_array_control = np.array(padded_data_control)\n",
    "    padded_data_array_classifier = np.array(padded_data_classifier)\n",
    "\n",
    "    ''' loading the data for WGAN training '''\n",
    "    train_images_schiz = padded_data_array_schiz\n",
    "    train_images_control = padded_data_array_control\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 10\n",
    "\n",
    "\n",
    "    train_dataset_schiz = tf.data.Dataset.from_tensor_slices((train_images_schiz)).shuffle(len(train_images_schiz)).batch(batch_size)\n",
    "    train_dataset_control = tf.data.Dataset.from_tensor_slices((train_images_control)).shuffle(len(train_images_control)).batch(batch_size)\n",
    "    \n",
    "    ''' setting up parameters'''\n",
    "    # Image shape and other parameters\n",
    "    img_shape = (84, 84, 72, 1)\n",
    "    z_dim = 100\n",
    "\n",
    "    # Create the generator and critic\n",
    "    generator = build_wgan_generator(z_dim)\n",
    "    critic = build_wgan_critic(img_shape)\n",
    "\n",
    "    critic_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "    generator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "    epochs = 10\n",
    "    lambda_gp = 10  # Gradient penalty coefficient\n",
    "\n",
    "    '''Train the WGAN-GP for schizophrenic'''\n",
    "\n",
    "    critic_losses, generator_losses = train_wgan_gp(\n",
    "        generator, \n",
    "        critic, \n",
    "        train_dataset_schiz, \n",
    "        epochs, \n",
    "        z_dim,\n",
    "        lambda_gp, \n",
    "        critic_optimizer, \n",
    "        generator_optimizer,\n",
    "        type=0\n",
    "    )\n",
    "    \n",
    "\n",
    "    ''' Train WGAN for control '''\n",
    "    critic_losses, generator_losses = train_wgan_gp(\n",
    "        generator, \n",
    "        critic, \n",
    "        train_dataset_control, \n",
    "        epochs, \n",
    "        z_dim,\n",
    "        lambda_gp, \n",
    "        critic_optimizer, \n",
    "        generator_optimizer,\n",
    "        type=1\n",
    "    )\n",
    "    \n",
    "\n",
    "    ''' after training, retrieve the weights of the critic for schizophrenic'''\n",
    "    # Initialize lists to hold the layers of each critic model\n",
    "    critic_schiz_layers = []\n",
    "    critic_control_layers = []\n",
    "\n",
    "    checkpoint_dir_schiz = '/wgan_gp_checkpoints_schiz'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir_schiz, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                    discriminator_optimizer=critic_optimizer,\n",
    "                                    generator=generator,\n",
    "                                    discriminator=critic)\n",
    "    \n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir_schiz))\n",
    "\n",
    "    for i in range(len(critic.layers)-1):  # Excluding the last layer\n",
    "        layer = critic.layers[i]\n",
    "        layer.trainable = False  # Freeze the layer\n",
    "        critic_schiz_layers.append(layer)\n",
    "\n",
    "    \n",
    "    ''' Then retrieve the weights of the critic for control'''\n",
    "\n",
    "    checkpoint_dir_control = '/wgan_gp_checkpoints_control'\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir_control, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                    discriminator_optimizer=critic_optimizer,\n",
    "                                    generator=generator,\n",
    "                                    discriminator=critic)\n",
    "    \n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir_control))\n",
    "\n",
    "    for i in range(len(critic.layers)-1):  # Excluding the last layer\n",
    "        layer = critic.layers[i]\n",
    "        layer.trainable = False\n",
    "        critic_control_layers.append(layer)\n",
    "\n",
    "\n",
    "    ''' transfer learning '''\n",
    "    \n",
    "    # Define an input layer\n",
    "    input_shape = (84, 84, 72, 1)  \n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # extracting the GAN layers\n",
    "    x_schiz = input_layer\n",
    "    for layer in critic_schiz_layers:\n",
    "        x_schiz = layer(x_schiz)\n",
    "\n",
    "    # Apply the control critic layers to the same input\n",
    "    x_control = input_layer\n",
    "    for layer in critic_control_layers:\n",
    "        x_control = layer(x_control)\n",
    "\n",
    "    # Concatenate the outputs from both critics\n",
    "    concatenated = Concatenate()([x_schiz, x_control])\n",
    "    merged = Flatten()(concatenated)\n",
    "    \n",
    "    feature = Dense(256, activation='relu', name='dense_class')(merged)\n",
    "    x = Dropout(0.3)(feature)\n",
    "    output_layer = Dense(1, activation='sigmoid', name='dense_class_2')(x)\n",
    "\n",
    "    # Create the model\n",
    "    classifier_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "    ''' Prepare data before training the classifer model, 2nd time train '''\n",
    "\n",
    "    # Resize each image in the padded data array\n",
    "    resized_images = [resize_image(img, (84, 84, 72)) for img in padded_data_array_classifier]\n",
    "\n",
    "    # Convert the resized data to a numpy array\n",
    "    resized_images_array = np.array(resized_images)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 10\n",
    "\n",
    "    # labels array corresponding to the images\n",
    "    labels_array = np.array(classifier_labels)\n",
    "    \n",
    "    ''' train classifier normally like in transfer-learning v2'''\n",
    "    # Split the data into training and evaluation sets (80% train, 20% eval)\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(resized_images_array, labels_array, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert to TensorFlow datasets with labels\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "    eval_dataset = tf.data.Dataset.from_tensor_slices((X_eval, y_eval)).batch(batch_size)\n",
    "\n",
    "    \n",
    "    classifier_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = classifier_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=100,\n",
    "        validation_data=eval_dataset\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    ''' load test images to make test set'''\n",
    "    # Now proceed with loading and preprocessing the images for these IDs\n",
    "    test_image_data = []\n",
    "    test_labels = []\n",
    "    \n",
    "    test_ids = classifier_test_ids\n",
    "\n",
    "    # Loop through the matching files and filter based on test IDs\n",
    "    for file_path in matching_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        file_id = filename.split('_')[0]\n",
    "\n",
    "        # Process only if the ID is in the test set\n",
    "        if file_id in test_ids:\n",
    "            t1_img = nib.load(file_path)\n",
    "            t1_data = t1_img.get_fdata()\n",
    "\n",
    "            # Ensure sufficient time dimension\n",
    "            if t1_data.shape[3] < 90:\n",
    "                continue\n",
    "\n",
    "            # Collapse one of the axes by summing\n",
    "            t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "\n",
    "            # Resize, normalize, and add dimension as done in the training data preparation\n",
    "            processed_image = resize_image(t1_data_collapsed, (84, 84, 72))\n",
    "            processed_image_normalized = (processed_image - np.min(processed_image)) / (np.max(processed_image) - np.min(processed_image)) * 2 - 1\n",
    "            processed_image_final = np.expand_dims(processed_image_normalized, axis=-1)\n",
    "\n",
    "            test_image_data.append(processed_image_final)\n",
    "            label = 1 if file_id in met_requirement_schizophrenia_ids else 0\n",
    "            test_labels.append(label)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    test_images_array = np.array(test_image_data)\n",
    "    test_labels_array = np.array(test_labels)\n",
    "\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images_array, test_labels_array)).batch(batch_size)\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    total_samples = 0\n",
    "    actual_labels = []\n",
    "    predicted_labels_list = []\n",
    "    # Manually iterate over the test dataset\n",
    "    for images, labels in test_dataset:\n",
    "\n",
    "        print(f\"Current batch size: {len(images)}\")\n",
    "        # so our batch size is not consistent, use weighted average\n",
    "        batch_size = len(images)\n",
    "        total_samples += batch_size\n",
    "        # Make predictions\n",
    "        predictions = classifier_model.predict(images)\n",
    "\n",
    "        # Calculate loss for the batch\n",
    "        loss = tf.keras.losses.binary_crossentropy(labels, predictions)\n",
    "        #test_loss += tf.reduce_mean(loss).numpy()\n",
    "        test_loss += tf.reduce_mean(loss).numpy() * batch_size\n",
    "\n",
    "        # Process predictions\n",
    "        predicted_labels_batch = tf.cast(tf.round(predictions), dtype=tf.int64)\n",
    "        predicted_labels_list.extend(predicted_labels_batch.numpy().flatten())\n",
    "        actual_labels.extend(labels.numpy().flatten())\n",
    "\n",
    "        # Calculate accuracy for the batch\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(labels, predicted_labels_batch), dtype=tf.float32))\n",
    "        test_accuracy += accuracy.numpy() *batch_size\n",
    "\n",
    "\n",
    "    iteration_avg_loss = test_loss / total_samples\n",
    "    iteration_avg_accuracy = test_accuracy / total_samples\n",
    "\n",
    "    total_loss += iteration_avg_loss\n",
    "    total_accuracy += iteration_avg_accuracy\n",
    "    \n",
    "    # Print test results\n",
    "    print(f\"Test Loss: {iteration_avg_loss}, Test Accuracy: {iteration_avg_accuracy}\")\n",
    "    print(\"Actual labels vs. Predicted labels:\")\n",
    "    for i in range(len(actual_labels)):\n",
    "        print(f\"Image {i+1}: Actual: {actual_labels[i]}, Predicted: {predicted_labels_list[i]}\")\n",
    "\n",
    "# Calculate and print the average loss and accuracy over all iterations\n",
    "average_test_loss = total_loss / num_iterations\n",
    "average_test_accuracy = total_accuracy / num_iterations\n",
    "print(f\"\\nAverage Test Loss over {num_iterations} iterations: {average_test_loss}\")\n",
    "print(f\"Average Test Accuracy over {num_iterations} iterations: {average_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Generate a single fake image\\nz = np.random.normal(0, 1, (1, z_dim))\\ngenerated_image = generator.predict(z)[0]  # [0] to get the single image from the batch\\n\\n# Get a single real image from the dataset\\nreal_images = next(iter(train_dataset))[0]  # Assuming the dataset yields only images\\n\\n# Take the first real image from the batch for comparison\\nreal_image = real_images[0]\\n\\n# Plot the real and fake images side by side\\nplt.figure(figsize=(10, 5))\\n\\n# Plot real image\\nplt.subplot(1, 2, 1)\\nplt.imshow(real_image[:, :, 10, 0])  # Adjust indexing and color map as needed\\nplt.title('Real Image')\\nplt.axis('off')\\n\\n# Plot fake image\\nplt.subplot(1, 2, 2)\\nplt.imshow(generated_image[:, :, 10, 0])  # Adjust indexing and color map as needed\\nplt.title('Generated Image')\\nplt.axis('off')\\n\\nplt.tight_layout()\\nplt.show() \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Generate a single fake image\n",
    "z = np.random.normal(0, 1, (1, z_dim))\n",
    "generated_image = generator.predict(z)[0]  # [0] to get the single image from the batch\n",
    "\n",
    "# Get a single real image from the dataset\n",
    "real_images = next(iter(train_dataset))[0]  # Assuming the dataset yields only images\n",
    "\n",
    "# Take the first real image from the batch for comparison\n",
    "real_image = real_images[0]\n",
    "\n",
    "# Plot the real and fake images side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot real image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(real_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Real Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot fake image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image[:, :, 10, 0])  # Adjust indexing and color map as needed\n",
    "plt.title('Generated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "863005fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.save('wgan_generator_model_v3.h5')\n",
    "#critic.save('wgan_critic_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b815ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
