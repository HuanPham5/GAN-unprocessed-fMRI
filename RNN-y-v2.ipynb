{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN test v2\n",
    "\n",
    "## ref: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes to remind myself:\n",
    "\n",
    "treating the 3D data as a series of 2D images over time, collapsing the third spatial dimension and treating it as a sequence of 2D images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josep\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import random\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from functools import partial\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN layers for spatial feature extraction, \n",
    "# Bidirectional LSTM for better sequence learning, \n",
    "# Dropout for regularization.\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Bidirectional, AdditiveAttention, LayerNormalization\n",
    "\n",
    "def build_rnn_model():\n",
    "    time_steps = 146  # Number of images per sequence\n",
    "    features_per_image = 91 * 91  # Each image is flattened into a vector of this size\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = Input(shape=(time_steps, features_per_image))\n",
    "    \n",
    "    # Bidirectional LSTM layers\n",
    "    x = Bidirectional(layers.LSTM(256, return_sequences=True))(inputs)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    attention = AdditiveAttention()([x, x])  # Use LSTM output as both query and key/value\n",
    "    \n",
    "    # Combine attention output with LSTM output\n",
    "    x = layers.Concatenate()([x, attention])\n",
    "    \n",
    "    # Another Bidirectional LSTM layer\n",
    "    x = Bidirectional(layers.LSTM(128))(x)\n",
    "    \n",
    "    # Dropout for regularization\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Dense output layer\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Build the model\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 146, 8281)]  0           []                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 146, 512)     17485824    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 146, 512)    1024        ['bidirectional[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 146, 512)    1574912     ['layer_normalization[0][0]']    \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " additive_attention (AdditiveAt  (None, 146, 512)    512         ['bidirectional_1[0][0]',        \n",
      " tention)                                                         'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 146, 1024)    0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'additive_attention[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 256)         1180672     ['concatenate[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            257         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,243,201\n",
      "Trainable params: 20,243,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = build_rnn_model()\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "# schizohrenia_id that satisfy t>90, 59 in total\n",
    "met_requirement_schizophrenia_ids = [\n",
    "    'A00000368', 'A00000456', 'A00000541', 'A00000838', 'A00001251', 'A00001452', 'A00004507',\n",
    "    'A00006754', 'A00009280', 'A00012767', 'A00013216', 'A00014607', 'A00014719', 'A00014804',\n",
    "    'A00014830', 'A00015201', 'A00015648', 'A00016197', 'A00016720', 'A00016723', 'A00017147',\n",
    "    'A00018317', 'A00018403', 'A00018434', 'A00018979', 'A00019293', 'A00020414', 'A00020602', \n",
    "    'A00020787', 'A00021591', 'A00021598', 'A00023158', 'A00023246', 'A00023590', 'A00023750', \n",
    "    'A00024198', 'A00024228', 'A00024568', 'A00024684', 'A00024953', 'A00024959', 'A00027410', \n",
    "    'A00027537', 'A00028303', 'A00028404', 'A00028408', 'A00028805', 'A00028806', 'A00031186', \n",
    "    'A00031597', 'A00034273', 'A00035003', 'A00035485', 'A00037034', 'A00037224', 'A00037619', \n",
    "    'A00037649', 'A00038441', 'A00038624']\n",
    "\n",
    "full_control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "]\n",
    "\n",
    " # 82 controls that met requirement\n",
    "met_requirement_control_ids = [\n",
    "    'A00000300', 'A00002198', 'A00003150', 'A00004087', 'A00007409', 'A00010684', 'A00011265', 'A00011725',\n",
    "    'A00012995', 'A00013140', 'A00013816', 'A00014839', 'A00014898', 'A00015759', 'A00015826', 'A00018553',\n",
    "    'A00018716', 'A00019888', 'A00020805', 'A00020895', 'A00020968', 'A00020984', 'A00021058', 'A00021072',\n",
    "    'A00021081', 'A00021085', 'A00022400', 'A00022490', 'A00022509', 'A00022592', 'A00022619', 'A00022653',\n",
    "    'A00022687', 'A00022727', 'A00022729', 'A00022773', 'A00022810', 'A00022835', 'A00022837', 'A00022915',\n",
    "    'A00023095', 'A00023120', 'A00023131', 'A00023143', 'A00023330', 'A00023337', 'A00023730', 'A00023800',\n",
    "    'A00023848', 'A00023866', 'A00024160', 'A00024301', 'A00024372', 'A00024446', 'A00024535', 'A00024546', \n",
    "    'A00024663', 'A00024820', 'A00024932', 'A00024955', 'A00025969', 'A00026945', 'A00027487', 'A00027787', \n",
    "    'A00028052', 'A00028406', 'A00028409', 'A00029226', 'A00029452', 'A00031478', 'A00031764', 'A00033214', \n",
    "    'A00035751', 'A00036049', 'A00036555', 'A00036844', 'A00037007', 'A00037238', 'A00037318', 'A00037495', \n",
    "    'A00037564', 'A00037665'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image after collapsed:  (91, 91, 141)\n",
      "shape of image after collapsed:  (91, 91, 123)\n",
      "shape of image after collapsed:  (91, 91, 145)\n",
      "shape of image after collapsed:  (91, 91, 124)\n",
      "Total GAN control loaded: 4\n",
      "Total GAN schiz loaded: 4\n"
     ]
    }
   ],
   "source": [
    "# GAN Training Data Selection\n",
    "gan_train_ids_schiz = random.sample(met_requirement_schizophrenia_ids, 4)\n",
    "gan_test_ids_schiz = [id for id in met_requirement_schizophrenia_ids if id not in gan_train_ids_schiz]\n",
    "\n",
    "gan_train_ids_control = random.sample(met_requirement_control_ids, 4)\n",
    "gan_test_ids_control = [id for id in met_requirement_control_ids if id not in gan_train_ids_control]\n",
    "gan_test_ids_control = random.sample(gan_test_ids_control,4)\n",
    "\n",
    "''' data training for classifier '''\n",
    "''' just use the same train set as GAN above '''\n",
    "\n",
    "# Classifier Test Data Selection\n",
    "classifier_test_ids = gan_test_ids_schiz + gan_test_ids_control\n",
    "\n",
    "''' File loading '''\n",
    "# Specify the directory and file pattern\n",
    "directory_path = '4D/'\n",
    "file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "# Construct the full path pattern\n",
    "path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "matching_files = glob.glob(path_pattern)\n",
    "\n",
    "''' File loading for GAN Training and classifer '''\n",
    "''' But this time we have 2 separate GANs, 1 train on schizoprenia and 1 train on control'''\n",
    "\n",
    "#classifier_image_data = []\n",
    "#classifier_labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "gan_image_data_schiz = []\n",
    "gan_image_data_control = []\n",
    "\n",
    "for file_path in matching_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    if file_id in gan_train_ids_schiz:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "        \n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "\n",
    "        t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "        print('shape of image after collapsed: ', t1_data_collapsed.shape)\n",
    "        gan_image_data_schiz.append(t1_data_collapsed)\n",
    "\n",
    "    if file_id in gan_train_ids_control:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "\n",
    "        t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "        gan_image_data_control.append(t1_data_collapsed)\n",
    "\n",
    "\n",
    "print(f\"Total GAN control loaded: {len(gan_image_data_control)}\")\n",
    "print(f\"Total GAN schiz loaded: {len(gan_image_data_schiz)}\")\n",
    "\n",
    "\n",
    "\n",
    "'''Determine the maximum 3rd-dimension size '''\n",
    "max_z_size_schiz = max(img.shape[2] for img in gan_image_data_schiz)\n",
    "max_z_size_control = max(img.shape[2] for img in gan_image_data_control)\n",
    "\n",
    "max_z_size = max(max_z_size_schiz,max_z_size_control)\n",
    "\n",
    "''' normalization '''\n",
    "image_data_normalized_schiz = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in gan_image_data_schiz]\n",
    "image_data_normalized_control = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in gan_image_data_control]\n",
    "\n",
    "\n",
    "''' padding of images data '''\n",
    "# Pad each image to have a consistent z-dimension size\n",
    "padded_data_schiz = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized_schiz]\n",
    "padded_data_control = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized_control]\n",
    "\n",
    "\n",
    "# Now convert the padded data list to a numpy array\n",
    "padded_data_array_schiz = np.array(padded_data_schiz)\n",
    "padded_data_array_control = np.array(padded_data_control)\n",
    "\n",
    "\n",
    "''' loading the data for WGAN training '''\n",
    "train_images_schiz = padded_data_array_schiz\n",
    "train_images_control = padded_data_array_control\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "train_dataset_schiz = tf.data.Dataset.from_tensor_slices((train_images_schiz)).shuffle(len(train_images_schiz)).batch(batch_size)\n",
    "train_dataset_control = tf.data.Dataset.from_tensor_slices((train_images_control)).shuffle(len(train_images_control)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each 2D image slice and prepare it for RNN input\n",
    "train_images_schiz = np.reshape(padded_data_array_schiz, (len(padded_data_array_schiz), 146, 91*91))\n",
    "train_images_control = np.reshape(padded_data_array_control, (len(padded_data_array_control), 146, 91*91))\n",
    "\n",
    "# Create labels\n",
    "labels_schiz = np.ones(len(train_images_schiz))\n",
    "labels_control = np.zeros(len(train_images_control))\n",
    "\n",
    "# Combine the datasets\n",
    "train_images = np.concatenate((train_images_schiz, train_images_control), axis=0)\n",
    "train_labels = np.concatenate((labels_schiz, labels_control), axis=0)\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_images = train_images[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6389578580856323, Training Accuracy: 0.625\n",
      "Epoch 2, Loss: 0.6340192556381226, Training Accuracy: 0.5\n",
      "Epoch 3, Loss: 0.8936426639556885, Training Accuracy: 0.625\n",
      "Epoch 4, Loss: 0.7858017683029175, Training Accuracy: 0.25\n",
      "Epoch 5, Loss: 0.6199522018432617, Training Accuracy: 0.5\n",
      "Epoch 6, Loss: 0.526227593421936, Training Accuracy: 0.625\n",
      "Epoch 7, Loss: 0.5648474097251892, Training Accuracy: 0.5\n",
      "Epoch 8, Loss: 0.5173529386520386, Training Accuracy: 0.75\n",
      "Epoch 9, Loss: 0.4888719916343689, Training Accuracy: 0.625\n",
      "Epoch 10, Loss: 0.33151063323020935, Training Accuracy: 1.0\n",
      "Epoch 11, Loss: 0.5690021514892578, Training Accuracy: 0.75\n",
      "Epoch 12, Loss: 0.5714426040649414, Training Accuracy: 0.75\n",
      "Epoch 13, Loss: 0.5867455005645752, Training Accuracy: 0.625\n",
      "Epoch 14, Loss: 0.4800736904144287, Training Accuracy: 0.75\n",
      "Epoch 15, Loss: 0.45470190048217773, Training Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "\n",
    "# Define number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = rnn_model(images, training=True)\n",
    "            loss = tf.keras.losses.binary_crossentropy(labels, tf.squeeze(predictions, axis=1))\n",
    "        \n",
    "        gradients = tape.gradient(loss, rnn_model.trainable_variables)\n",
    "        rnn_model.optimizer.apply_gradients(zip(gradients, rnn_model.trainable_variables))\n",
    "        \n",
    "        # Update the metrics\n",
    "        train_loss.update_state(loss)\n",
    "        train_accuracy.update_state(labels, tf.squeeze(predictions, axis=1))\n",
    "    \n",
    "    # Print the loss and accuracy for the current epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {train_loss.result().numpy()}, Training Accuracy: {train_accuracy.result().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0] / image.shape[0],\n",
    "        new_shape[1] / image.shape[1],\n",
    "        new_shape[2] / image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation\n",
    "\n",
    "\n",
    "test_image_data = []\n",
    "test_labels = []\n",
    "\n",
    "test_ids = classifier_test_ids  # List of IDs to filter test data\n",
    "\n",
    "for file_path in matching_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    if file_id in test_ids:\n",
    "        t1_img = nib.load(file_path)\n",
    "        t1_data = t1_img.get_fdata()\n",
    "\n",
    "        if t1_data.shape[3] < 90:\n",
    "            continue\n",
    "        \n",
    "        t1_data_collapsed = np.sum(t1_data, axis=1)  # Summing over one axis\n",
    "\n",
    "        # Resize the collapsed data\n",
    "        processed_image = resize_image(t1_data_collapsed, (91, 91, 146))\n",
    "\n",
    "        # Normalize the processed image\n",
    "        processed_image_normalized = (processed_image - np.min(processed_image)) / (np.max(processed_image) - np.min(processed_image)) * 2 - 1\n",
    "\n",
    "        # Reshape for RNN input: Flatten each 91x91 image to a single vector and treat each as a timestep\n",
    "        processed_image_flattened = np.reshape(processed_image_normalized, (146, 91*91))\n",
    "\n",
    "        test_image_data.append(processed_image_flattened)\n",
    "        label = 1 if file_id in met_requirement_schizophrenia_ids else 0\n",
    "        test_labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays for easier handling in TensorFlow\n",
    "test_images_array = np.array(test_image_data)\n",
    "test_labels_array = np.array(test_labels)\n",
    "\n",
    "# Create a TensorFlow dataset from the numpy arrays\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images_array, test_labels_array)).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 92ms/step - loss: 2.1895 - accuracy: 0.2203\n",
      "Test loss: 2.1895229816436768, Test accuracy: 0.22033898532390594\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = rnn_model.evaluate(test_dataset)\n",
    "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 86ms/step\n",
      "[[ 4  0]\n",
      " [46  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      1.00      0.15         4\n",
      "           1       1.00      0.16      0.28        55\n",
      "\n",
      "    accuracy                           0.22        59\n",
      "   macro avg       0.54      0.58      0.21        59\n",
      "weighted avg       0.94      0.22      0.27        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the probabilities\n",
    "predictions = rnn_model.predict(test_dataset)\n",
    "# Convert probabilities to class labels\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Assuming test_labels_array contains your actual labels\n",
    "actual_labels = test_labels_array\n",
    "\n",
    "# Now you might want to compare these predicted_labels with the actual labels (test_labels)\n",
    "# to compute the confusion matrix, classification report, etc.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(actual_labels, predicted_labels.flatten()))\n",
    "print(classification_report(actual_labels, predicted_labels.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [1]\n",
      "Actual: 0, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n",
      "Actual: 1, Predicted: [0]\n"
     ]
    }
   ],
   "source": [
    "for actual, predicted in zip(actual_labels, predicted_labels):\n",
    "    print(f'Actual: {actual}, Predicted: {predicted}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
