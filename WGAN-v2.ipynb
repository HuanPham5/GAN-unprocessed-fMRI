{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN version v2\n",
    "\n",
    "## only schizophrenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv3D, Conv3DTranspose, LeakyReLU, Input, Embedding, multiply, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# List all physical devices of type 'GPU'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f'Number of GPUs available: {len(gpus)}')\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f'GPU {i}: {gpu}')\n",
    "else:\n",
    "    print('No GPU detected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0df35",
   "metadata": {},
   "source": [
    "# Matching fMRI files with IDs from demographic csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "077ff26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncontrol_ids = [\\n    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\\n    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\\n    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\\n    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\\n    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\\n    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\\n    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\\n    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\\n    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\\n    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\\n    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\\n    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\\n    'A00022727', 'A00011265', 'A00024546'\\n] \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the directory and file pattern\n",
    "directory_path = '4D'\n",
    "file_pattern = 'A*_????_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz'\n",
    "\n",
    "# Construct the full path pattern\n",
    "path_pattern = f'{directory_path}/{file_pattern}'\n",
    "\n",
    "# Use glob to find all matching files\n",
    "matching_files = glob.glob(path_pattern)\n",
    "\n",
    "# Define the list of schizophrenia IDs\n",
    "\n",
    "schizophrenia_ids = [\n",
    "    'A00009280', 'A00028806', 'A00023132', 'A00014804', 'A00016859', 'A00021598', 'A00001181', 'A00023158',\n",
    "    'A00024568', 'A00028405', 'A00001251', 'A00000456', 'A00015648', 'A00002405', 'A00027391', 'A00016720',\n",
    "    'A00018434', 'A00016197', 'A00027119', 'A00006754', 'A00009656', 'A00038441', 'A00012767', 'A00034273',\n",
    "    'A00028404', 'A00035485', 'A00024684', 'A00018979', 'A00027537', 'A00004507', 'A00001452', 'A00023246',\n",
    "    'A00027410', 'A00014719', 'A00024510', 'A00000368', 'A00019293', 'A00014830', 'A00015201', 'A00018403',\n",
    "    'A00037854', 'A00024198', 'A00001243', 'A00014590', 'A00002337', 'A00024953', 'A00037224', 'A00027616',\n",
    "    'A00001856', 'A00037619', 'A00024228', 'A00038624', 'A00037034', 'A00037649', 'A00022500', 'A00013216',\n",
    "    'A00020787', 'A00028410', 'A00002480', 'A00028303', 'A00020602', 'A00024959', 'A00018598', 'A00014636',\n",
    "    'A00019349', 'A00017147', 'A00023590', 'A00023750', 'A00031597', 'A00015518', 'A00018317', 'A00016723',\n",
    "    'A00021591', 'A00023243', 'A00017943', 'A00023366', 'A00014607', 'A00020414', 'A00035003', 'A00028805',\n",
    "    'A00029486', 'A00000541', 'A00028408', 'A00000909', 'A00031186', 'A00000838' ]\n",
    "\n",
    "\n",
    "# Define the list of IDs of individuals with non-schizophrenia - control only\n",
    "\n",
    "control_ids = []\n",
    "'''\n",
    "control_ids = [\n",
    "    'A00007409', 'A00013140', 'A00021145', 'A00036049', 'A00022810', 'A00002198', 'A00020895', 'A00004667',\n",
    "    'A00015826', 'A00023120', 'A00022837', 'A00010684', 'A00009946', 'A00037318', 'A00033214', 'A00022490',\n",
    "    'A00023848', 'A00029452', 'A00037564', 'A00036555', 'A00023095', 'A00022729', 'A00024955', 'A00024160',\n",
    "    'A00011725', 'A00027487', 'A00024446', 'A00014898', 'A00015759', 'A00028409', 'A00017294', 'A00014522',\n",
    "    'A00012995', 'A00031764', 'A00025969', 'A00033147', 'A00018553', 'A00023143', 'A00036916', 'A00028052',\n",
    "    'A00023337', 'A00023730', 'A00020805', 'A00020984', 'A00000300', 'A00010150', 'A00024932', 'A00035537',\n",
    "    'A00022509', 'A00028406', 'A00004087', 'A00035751', 'A00023800', 'A00027787', 'A00022687', 'A00023866',\n",
    "    'A00021085', 'A00022619', 'A00036897', 'A00019888', 'A00021058', 'A00022835', 'A00037495', 'A00026945',\n",
    "    'A00018716', 'A00026907', 'A00023330', 'A00016199', 'A00037238', 'A00023131', 'A00014120', 'A00021072',\n",
    "    'A00037665', 'A00022400', 'A00003150', 'A00024372', 'A00021081', 'A00022592', 'A00022653', 'A00013816',\n",
    "    'A00014839', 'A00031478', 'A00014225', 'A00013363', 'A00037007', 'A00020968', 'A00024301', 'A00024820',\n",
    "    'A00035469', 'A00029226', 'A00022915', 'A00022773', 'A00024663', 'A00036844', 'A00009207', 'A00024535',\n",
    "    'A00022727', 'A00011265', 'A00024546'\n",
    "] '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files successfully processed: 59\n",
      "Total number of schizophrenia files: 59\n",
      "Schizophrenia files: ['A00000368_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000456_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000541_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00000838_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001251_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00001452_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00004507_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00006754_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00009280_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00012767_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00013216_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014607_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014719_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014804_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00014830_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015201_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00015648_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016197_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016720_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00016723_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00017147_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018317_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018403_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018434_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00018979_0020_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00019293_0015_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020414_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020602_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00020787_0017_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021591_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00021598_0010_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023158_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023246_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023590_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00023750_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024198_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024228_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024568_0008_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024684_0011_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024953_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00024959_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027410_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00027537_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028303_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028404_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028408_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028805_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00028806_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031186_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00031597_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00034273_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035003_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00035485_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037034_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037224_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037619_0013_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00037649_0014_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00038441_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz', 'A00038624_0012_func_FL_FD_RPI_DSP_MCF_SS_SM_Nui_CS_InStandard.nii.gz']\n",
      "Total number of non-schizophrenia files: 0\n",
      "Non-Schizophrenia files: []\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the processed image data, corresponding labels, and filenames\n",
    "image_data = []\n",
    "labels = []  # 1 for schizophrenia, 0 for non-schizophrenia\n",
    "schizophrenia_files = []\n",
    "non_schizophrenia_files = []\n",
    "\n",
    "# Lists for files with insufficient time dimensions\n",
    "insufficient_time_files = []\n",
    "insufficient_time_ids = []\n",
    "\n",
    "# Counters for each category\n",
    "schizophrenia_count = 0\n",
    "non_schizophrenia_count = 0\n",
    "processed_files_count = 0\n",
    "\n",
    "# Loop through the matching files\n",
    "for file_path in matching_files:\n",
    "    # Extract the filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract the ID from the filename\n",
    "    file_id = filename.split('_')[0]\n",
    "    \n",
    "    # Load the file\n",
    "    t1_img = nib.load(file_path)\n",
    "    t1_data = t1_img.get_fdata()\n",
    "\n",
    "    # Check if the time dimension is at least 90\n",
    "    if t1_data.shape[3] < 90:\n",
    "        insufficient_time_files.append(filename)\n",
    "        insufficient_time_ids.append(file_id)\n",
    "        continue  # Skip this file\n",
    "\n",
    "    # Determine the label based on the ID and increment counters\n",
    "    if file_id in schizophrenia_ids:\n",
    "        label = 1  # Schizophrenia\n",
    "        schizophrenia_count += 1\n",
    "        schizophrenia_files.append(filename)\n",
    "    elif file_id in control_ids:\n",
    "        label = 0  # Non-Schizophrenia\n",
    "        non_schizophrenia_count += 1\n",
    "        non_schizophrenia_files.append(filename)\n",
    "    else:\n",
    "        continue  # Skip files with IDs not in the provided lists\n",
    "    \n",
    "    # Collapse one of the axes by summing\n",
    "    t1_data_collapsed = np.sum(t1_data, axis=1)\n",
    "    \n",
    "    # Append the collapsed image data and label to the respective lists\n",
    "    image_data.append(t1_data_collapsed)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Increment the counter\n",
    "    processed_files_count += 1\n",
    "\n",
    "# Print the total number of files processed for each category and their filenames\n",
    "print(f\"Total number of files successfully processed: {processed_files_count}\")\n",
    "print(f\"Total number of schizophrenia files: {schizophrenia_count}\")\n",
    "print(\"Schizophrenia files:\", schizophrenia_files)\n",
    "print(f\"Total number of non-schizophrenia files: {non_schizophrenia_count}\")\n",
    "print(\"Non-Schizophrenia files:\", non_schizophrenia_files)\n",
    "\n",
    "# Print files with insufficient time dimension\n",
    "#print(f\"Total number of files with insufficient time dimension: {len(insufficient_time_files)}\")\n",
    "#print(\"Files with insufficient time dimension:\", insufficient_time_files)\n",
    "#print(\"IDs of files with insufficient time dimension:\", insufficient_time_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e63949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the maximum z-dimension size\n",
    "max_z_size = max(img.shape[2] for img in image_data)\n",
    "max_z_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98267a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_normalized = [(img - np.min(img)) / (np.max(img) - np.min(img)) * 2 - 1 for img in image_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679d20c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]],\n",
       "\n",
       "       [[-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        ...,\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416],\n",
       "        [-0.02207416, -0.02207416, -0.02207416, ..., -0.02207416,\n",
       "         -0.02207416, -0.02207416]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7939a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each image to have a consistent z-dimension size\n",
    "padded_data = [np.pad(img, ((0, 0), (0, 0), (0, max_z_size - img.shape[2])), mode='constant') for img in image_data_normalized]\n",
    "\n",
    "# Now convert the padded data list to a numpy array\n",
    "padded_data_array = np.array(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596fee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf3cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = padded_data_array\n",
    "# Define batch size\n",
    "batch_size = 10\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, labels)).shuffle(len(train_images)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1c8b2",
   "metadata": {},
   "source": [
    "The primary differences between a WGAN and a regular GAN (including cGAN) lie in the discriminator (or critic in WGAN terms) and the loss functions, rather than the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bbda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wgan_generator(z_dim):\n",
    "    # Noise input\n",
    "    z_input = Input(shape=(z_dim,))\n",
    "\n",
    "    # Generator network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Start with a Dense layer to an initial shape that's smaller than the final target\n",
    "    model.add(Dense(128 * 7 * 7 * 9, input_dim=z_dim))  # Adjust to match an initial volume\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Reshape((7, 7, 9, 128)))  # This is the initial volume\n",
    "    \n",
    "    # Begin upsampling to the desired size\n",
    "    model.add(Conv3DTranspose(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Continue upsampling\n",
    "    model.add(Conv3DTranspose(32, kernel_size=3, strides=(3, 3, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    \n",
    "    # Final upsampling step to reach just under the target size\n",
    "    model.add(Conv3DTranspose(1, kernel_size=3, strides=(2, 2, 2), padding='same', activation='tanh'))\n",
    "\n",
    "    # Output tensor\n",
    "    output = model(z_input)\n",
    "\n",
    "    return Model(z_input, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770677f",
   "metadata": {},
   "source": [
    "Changes in discriminator\n",
    "\n",
    "Remove the Sigmoid Activation: In WGAN, the critic does not classify inputs as real or fake, but instead scores them. Therefore, the sigmoid activation in the output layer should be removed.\n",
    "\n",
    "No Classification Layer: The critic in a WGAN does not need a dense layer for classification. It simply needs to output a score for the realness of the input.\n",
    "\n",
    "Weight Clipping: If we are using weight clipping to enforce the Lipschitz constraint (common in original WGAN), we need to clip the weights of the critic within a certain range after each update. However, this is often replaced by gradient penalty in WGAN-GP (Wasserstein GAN with Gradient Penalty) for improved training stability and performance.\n",
    "\n",
    "So I use Gradient Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac89dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv3D, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_wgan_critic(img_shape):\n",
    "    # Image input\n",
    "    img_input = Input(shape=img_shape)\n",
    "\n",
    "    # Critic network\n",
    "    x = Conv3D(64, kernel_size=3, strides=2, padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "\n",
    "    x = Conv3D(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    \n",
    "    # Output a score for realness (no sigmoid activation)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    return Model(img_input, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e906057",
   "metadata": {},
   "source": [
    "### GP is calculated by\n",
    "### Interpolating between real and fake images.\n",
    "### Computing the gradient of the critic's scores with respect to this interpolation.\n",
    "### Penalizing the deviation of these gradients from the norm value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a7ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_images, fake_images, critic):\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "    # Alpha for interpolation - shape: (batch_size, 1, 1, 1, 1)\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0., 1.)\n",
    "\n",
    "    # Interpolated images - shape: (batch_size, 84, 84, 72, 1)\n",
    "    interpolated_images = (real_images * alpha) + (fake_images * (1 - alpha))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated_images)\n",
    "        # Critic now only takes the images as input\n",
    "        predictions = critic(interpolated_images, training=True)\n",
    "\n",
    "    # Calculate the gradients with respect to the interpolated images\n",
    "    gradients = tape.gradient(predictions, [interpolated_images])[0]\n",
    "\n",
    "    # Compute the norm of the gradients - reduce over all dimensions except the batch dimension\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3, 4]))\n",
    "\n",
    "    # Penalize the gradient norm deviation from 1\n",
    "    gp = tf.reduce_mean((gradients_norm - 1.) ** 2)\n",
    "    return gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbecdc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape and other parameters\n",
    "img_shape = (84, 84, 72, 1)\n",
    "z_dim = 100\n",
    "\n",
    "# Create the generator and critic\n",
    "generator = build_wgan_generator(z_dim)\n",
    "critic = build_wgan_critic(img_shape)\n",
    "\n",
    "# RMSprop optimizers, from the paper, but we might try Adam optimizer?\n",
    "\n",
    "#critic_optimizer = RMSprop(learning_rate=0.00005)\n",
    "#generator_optimizer = RMSprop(learning_rate=0.00005)\n",
    "\n",
    "# from paper as well\n",
    "critic_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "generator_optimizer = Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "# Note: No need to compile the models with loss functions here\n",
    "# as the loss will be calculated manually during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e1b65f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_shape):\n",
    "    factors = (\n",
    "        new_shape[0]/image.shape[0],\n",
    "        new_shape[1]/image.shape[1],\n",
    "        new_shape[2]/image.shape[2]\n",
    "    )\n",
    "    return scipy.ndimage.zoom(image, factors, order=1)  # order=1 is bilinear interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "147cc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_gp(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer):\n",
    "    # Lists to keep track of losses\n",
    "    critic_losses = []\n",
    "    generator_losses = []\n",
    "\n",
    "    # Directory for saving checkpoints\n",
    "    checkpoint_dir = \"wgan_gp_checkpoints\"\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_critic_loss = 0.0\n",
    "        epoch_generator_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in dataset:\n",
    "            # Assuming dataset yields only images\n",
    "            real_imgs = batch[0]\n",
    "\n",
    "            num_batches += 1\n",
    "            batch_size = real_imgs.shape[0]\n",
    "\n",
    "            # Resize real images to match the expected dimensions of the critic\n",
    "            real_imgs_resized = np.array([resize_image(img, (84, 84, 72)) for img in real_imgs])\n",
    "            real_imgs_resized = np.expand_dims(real_imgs_resized, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Train the critic\n",
    "            for _ in range(5):  # Critic is often trained more frequently\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generate fake images\n",
    "                    z = tf.random.normal([batch_size, z_dim])\n",
    "                    fake_imgs = generator(z, training=True)\n",
    "\n",
    "                    # Get critic scores for real and fake images\n",
    "                    real_output = critic(real_imgs_resized, training=True)\n",
    "                    fake_output = critic(fake_imgs, training=True)\n",
    "\n",
    "                    # Calculate critic loss\n",
    "                    critic_cost = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "                    gp = gradient_penalty(real_imgs_resized, fake_imgs, critic)\n",
    "                    critic_loss = critic_cost + lambda_gp * gp\n",
    "\n",
    "                # Update critic weights\n",
    "                critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "                critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "                epoch_critic_loss += critic_loss\n",
    "\n",
    "            # Train the generator\n",
    "            z = tf.random.normal([batch_size, z_dim])\n",
    "            misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_imgs = generator(z, training=True)\n",
    "                fake_output = critic(fake_imgs, training=True)\n",
    "                generator_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "            # Update generator weights\n",
    "            generator_grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n",
    "            epoch_generator_loss += generator_loss\n",
    "\n",
    "            # print the losses for each batch\n",
    "            print(f'Epoch: {epoch}, Batch: {num_batches}, Critic Loss: {critic_loss}, Generator Loss: {generator_loss}')\n",
    "\n",
    "        # Checkpointing every n epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            generator.save_weights(os.path.join(checkpoint_dir, f\"generator_epoch_{epoch+1}.h5\"))\n",
    "            critic.save_weights(os.path.join(checkpoint_dir, f\"critic_epoch_{epoch+1}.h5\"))\n",
    "            print(f\"Checkpoint: Saved model weights at epoch {epoch+1}\")\n",
    "            \n",
    "        # Record the average losses for this epoch\n",
    "        critic_losses.append(epoch_critic_loss / num_batches)\n",
    "        generator_losses.append(epoch_generator_loss / num_batches)\n",
    "\n",
    "    return critic_losses, generator_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddN_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1016064,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m lambda_gp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Gradient penalty coefficient\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the WGAN-GP\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m critic_losses, generator_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_wgan_gp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlambda_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcritic_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 44\u001b[0m, in \u001b[0;36mtrain_wgan_gp\u001b[1;34m(generator, critic, dataset, epochs, z_dim, lambda_gp, critic_optimizer, generator_optimizer)\u001b[0m\n\u001b[0;32m     41\u001b[0m     critic_loss \u001b[38;5;241m=\u001b[39m critic_cost \u001b[38;5;241m+\u001b[39m lambda_gp \u001b[38;5;241m*\u001b[39m gp\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Update critic weights\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m critic_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcritic_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m critic_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(critic_grads, critic\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m     46\u001b[0m epoch_critic_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m critic_loss\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:650\u001b[0m, in \u001b[0;36m_aggregate_grads\u001b[1;34m(gradients)\u001b[0m\n\u001b[0;32m    648\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gradients[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(g, ops\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gradients):\n\u001b[1;32m--> 650\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    653\u001b[0m       \u001b[38;5;28misinstance\u001b[39m(g, (ops\u001b[38;5;241m.\u001b[39mTensor, indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices))\n\u001b[0;32m    654\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gradients)\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:397\u001b[0m, in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m    395\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 397\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    399\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddN_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1016064,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:AddN]"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "z_dim = 100\n",
    "epochs = 10\n",
    "lambda_gp = 10  # Gradient penalty coefficient\n",
    "\n",
    "# Train the WGAN-GP\n",
    "critic_losses, generator_losses = train_wgan_gp(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_dataset, \n",
    "    epochs, \n",
    "    z_dim,\n",
    "    lambda_gp, \n",
    "    critic_optimizer, \n",
    "    generator_optimizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single fake image\n",
    "z = np.random.normal(0, 1, (1, z_dim))\n",
    "generated_image = generator.predict(z)[0]  # [0] to get the single image from the batch\n",
    "\n",
    "# Get a single real image from the dataset\n",
    "real_images = next(iter(train_dataset))[0]  # Assuming the dataset yields only images\n",
    "\n",
    "# Take the first real image from the batch for comparison\n",
    "real_image = real_images[0]\n",
    "\n",
    "# Plot the real and fake images side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot real image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(real_image[:, :, 10, 0], cmap='gray')  # Adjust indexing and color map as needed\n",
    "plt.title('Real Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Plot fake image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image[:, :, 10, 0], cmap='gray')  # Adjust indexing and color map as needed\n",
    "plt.title('Generated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863005fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('wgan_generator_model_v2.h5')\n",
    "critic.save('wgan_critic_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b815ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96a4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
